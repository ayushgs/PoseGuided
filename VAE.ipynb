{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#importing dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "#import _pickle as cpickle #to store model histories in a file\n",
    "import os\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "use_cuda = False\n",
    "device   = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "    device   = torch.device('cuda')\n",
    "print(use_cuda)    \n",
    "    \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying parameters\n",
    "image_size = 64 #HACK to use MNIST architecture\n",
    "G_input_dim = 100\n",
    "G_output_dim = 3\n",
    "D_input_dim = 3\n",
    "D_output_dim = 1\n",
    "num_filters = [1024, 512, 256, 128]\n",
    "\n",
    "learning_rate = 0.0002\n",
    "betas = (0.5, 0.999)\n",
    "batch_size = 128\n",
    "num_epochs = 1000\n",
    "\n",
    "data_dir = './Train_data'\n",
    "save_dir = './DCGAN_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shreyashpandey/PoseGuided\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                 #Hack to make MNIST code work\n",
    "                                transforms.ToTensor(),\n",
    "                                #transforms.Normalize(mean=(214.0466981, 206.55220904, 203.99178198), std=(54.34939265, 55.62690195, 58.85794001))\n",
    "                               ])\n",
    "                                \n",
    "\n",
    "df_data = dsets.ImageFolder(data_dir, transform = transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=df_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(64*64*3, 4096)\n",
    "        self.fc2 = nn.Linear(4096,1000)\n",
    "        self.fc3 = nn.Linear(1000,400)\n",
    "        self.fc31 = nn.Linear(400, 60)\n",
    "        self.fc32 = nn.Linear(400, 60)\n",
    "        self.fc4 = nn.Linear(60, 400)\n",
    "        self.fc5 = nn.Linear(400,1000)\n",
    "        self.fc6 = nn.Linear(1000,4096)\n",
    "        self.fc7 = nn.Linear(4096, 64*64*3)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        h3 = F.relu(self.fc3(h2))\n",
    "        return self.fc31(h3), self.fc32(h3)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h4 = F.relu(self.fc4(z))\n",
    "        h5 = F.relu(self.fc5(h4))\n",
    "        h6 = F.relu(self.fc6(h5))\n",
    "        #out = F.sigmoid(self.fc7(h6))\n",
    "        out = self.fc7(h6)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 64*64*3))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.mse_loss(recon_x, x.view(-1, 64*64*3), size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model.forward(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(data_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(data_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0 and epoch%1 == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(-1, 3, 64, 64)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/32031 (0%)]\tLoss: 8949.535156\n",
      "Train Epoch: 1 [1280/32031 (4%)]\tLoss: 8865.382812\n",
      "Train Epoch: 1 [2560/32031 (8%)]\tLoss: 21178.947266\n",
      "Train Epoch: 1 [3840/32031 (12%)]\tLoss: 6802.149902\n",
      "Train Epoch: 1 [5120/32031 (16%)]\tLoss: 1289.246094\n",
      "Train Epoch: 1 [6400/32031 (20%)]\tLoss: 917.844910\n",
      "Train Epoch: 1 [7680/32031 (24%)]\tLoss: 670.380005\n",
      "Train Epoch: 1 [8960/32031 (28%)]\tLoss: 602.376465\n",
      "Train Epoch: 1 [10240/32031 (32%)]\tLoss: 562.315796\n",
      "Train Epoch: 1 [11520/32031 (36%)]\tLoss: 509.550293\n",
      "Train Epoch: 1 [12800/32031 (40%)]\tLoss: 521.720459\n",
      "Train Epoch: 1 [14080/32031 (44%)]\tLoss: 537.670349\n",
      "Train Epoch: 1 [15360/32031 (48%)]\tLoss: 518.485291\n",
      "Train Epoch: 1 [16640/32031 (52%)]\tLoss: 484.445862\n",
      "Train Epoch: 1 [17920/32031 (56%)]\tLoss: 513.425903\n",
      "Train Epoch: 1 [19200/32031 (60%)]\tLoss: 504.212189\n",
      "Train Epoch: 1 [20480/32031 (64%)]\tLoss: 481.350250\n",
      "Train Epoch: 1 [21760/32031 (68%)]\tLoss: 493.680145\n",
      "Train Epoch: 1 [23040/32031 (72%)]\tLoss: 501.151184\n",
      "Train Epoch: 1 [24320/32031 (76%)]\tLoss: 512.038391\n",
      "Train Epoch: 1 [25600/32031 (80%)]\tLoss: 478.045776\n",
      "Train Epoch: 1 [26880/32031 (84%)]\tLoss: 491.855133\n",
      "Train Epoch: 1 [28160/32031 (88%)]\tLoss: 470.245422\n",
      "Train Epoch: 1 [29440/32031 (92%)]\tLoss: 461.837799\n",
      "Train Epoch: 1 [30720/32031 (96%)]\tLoss: 423.603027\n",
      "Train Epoch: 1 [7750/32031 (100%)]\tLoss: 489.393334\n",
      "====> Epoch: 1 Average loss: 7969.7299\n",
      "====> Test set loss: 491.9377\n",
      "Train Epoch: 2 [0/32031 (0%)]\tLoss: 471.983765\n",
      "Train Epoch: 2 [1280/32031 (4%)]\tLoss: 483.898193\n",
      "Train Epoch: 2 [2560/32031 (8%)]\tLoss: 447.775360\n",
      "Train Epoch: 2 [3840/32031 (12%)]\tLoss: 467.378479\n",
      "Train Epoch: 2 [5120/32031 (16%)]\tLoss: 429.843567\n",
      "Train Epoch: 2 [6400/32031 (20%)]\tLoss: 426.701141\n",
      "Train Epoch: 2 [7680/32031 (24%)]\tLoss: 438.602631\n",
      "Train Epoch: 2 [8960/32031 (28%)]\tLoss: 397.862396\n",
      "Train Epoch: 2 [10240/32031 (32%)]\tLoss: 440.783997\n",
      "Train Epoch: 2 [11520/32031 (36%)]\tLoss: 433.450562\n",
      "Train Epoch: 2 [12800/32031 (40%)]\tLoss: 429.103333\n",
      "Train Epoch: 2 [14080/32031 (44%)]\tLoss: 409.794220\n",
      "Train Epoch: 2 [15360/32031 (48%)]\tLoss: 436.550964\n",
      "Train Epoch: 2 [16640/32031 (52%)]\tLoss: 408.152954\n",
      "Train Epoch: 2 [17920/32031 (56%)]\tLoss: 419.970673\n",
      "Train Epoch: 2 [19200/32031 (60%)]\tLoss: 403.602020\n",
      "Train Epoch: 2 [20480/32031 (64%)]\tLoss: 394.254456\n",
      "Train Epoch: 2 [21760/32031 (68%)]\tLoss: 393.733185\n",
      "Train Epoch: 2 [23040/32031 (72%)]\tLoss: 396.710327\n",
      "Train Epoch: 2 [24320/32031 (76%)]\tLoss: 397.288574\n",
      "Train Epoch: 2 [25600/32031 (80%)]\tLoss: 392.075867\n",
      "Train Epoch: 2 [26880/32031 (84%)]\tLoss: 418.667023\n",
      "Train Epoch: 2 [28160/32031 (88%)]\tLoss: 391.525482\n",
      "Train Epoch: 2 [29440/32031 (92%)]\tLoss: 399.711792\n",
      "Train Epoch: 2 [30720/32031 (96%)]\tLoss: 403.304169\n",
      "Train Epoch: 2 [7750/32031 (100%)]\tLoss: 426.318643\n",
      "====> Epoch: 2 Average loss: 419.7873\n",
      "====> Test set loss: 447.6332\n",
      "Train Epoch: 3 [0/32031 (0%)]\tLoss: 403.759460\n",
      "Train Epoch: 3 [1280/32031 (4%)]\tLoss: 387.111450\n",
      "Train Epoch: 3 [2560/32031 (8%)]\tLoss: 376.473969\n",
      "Train Epoch: 3 [3840/32031 (12%)]\tLoss: 408.981964\n",
      "Train Epoch: 3 [5120/32031 (16%)]\tLoss: 399.116547\n",
      "Train Epoch: 3 [6400/32031 (20%)]\tLoss: 365.378296\n",
      "Train Epoch: 3 [7680/32031 (24%)]\tLoss: 418.470245\n",
      "Train Epoch: 3 [8960/32031 (28%)]\tLoss: 365.644043\n",
      "Train Epoch: 3 [10240/32031 (32%)]\tLoss: 395.371368\n",
      "Train Epoch: 3 [11520/32031 (36%)]\tLoss: 393.448761\n",
      "Train Epoch: 3 [12800/32031 (40%)]\tLoss: 351.902771\n",
      "Train Epoch: 3 [14080/32031 (44%)]\tLoss: 388.711121\n",
      "Train Epoch: 3 [15360/32031 (48%)]\tLoss: 369.318542\n",
      "Train Epoch: 3 [16640/32031 (52%)]\tLoss: 388.559265\n",
      "Train Epoch: 3 [17920/32031 (56%)]\tLoss: 368.661346\n",
      "Train Epoch: 3 [19200/32031 (60%)]\tLoss: 371.958008\n",
      "Train Epoch: 3 [20480/32031 (64%)]\tLoss: 391.464233\n",
      "Train Epoch: 3 [21760/32031 (68%)]\tLoss: 392.118469\n",
      "Train Epoch: 3 [23040/32031 (72%)]\tLoss: 383.000824\n",
      "Train Epoch: 3 [24320/32031 (76%)]\tLoss: 391.123413\n",
      "Train Epoch: 3 [25600/32031 (80%)]\tLoss: 369.219238\n",
      "Train Epoch: 3 [26880/32031 (84%)]\tLoss: 391.396118\n",
      "Train Epoch: 3 [28160/32031 (88%)]\tLoss: 380.576385\n",
      "Train Epoch: 3 [29440/32031 (92%)]\tLoss: 386.923431\n",
      "Train Epoch: 3 [30720/32031 (96%)]\tLoss: 377.355347\n",
      "Train Epoch: 3 [7750/32031 (100%)]\tLoss: 384.624496\n",
      "====> Epoch: 3 Average loss: 385.3027\n",
      "====> Test set loss: 385.8177\n",
      "Train Epoch: 4 [0/32031 (0%)]\tLoss: 383.133667\n",
      "Train Epoch: 4 [1280/32031 (4%)]\tLoss: 357.728027\n",
      "Train Epoch: 4 [2560/32031 (8%)]\tLoss: 369.682159\n",
      "Train Epoch: 4 [3840/32031 (12%)]\tLoss: 387.895935\n",
      "Train Epoch: 4 [5120/32031 (16%)]\tLoss: 353.023804\n",
      "Train Epoch: 4 [6400/32031 (20%)]\tLoss: 370.719452\n",
      "Train Epoch: 4 [7680/32031 (24%)]\tLoss: 364.460602\n",
      "Train Epoch: 4 [8960/32031 (28%)]\tLoss: 386.825897\n",
      "Train Epoch: 4 [10240/32031 (32%)]\tLoss: 368.753265\n",
      "Train Epoch: 4 [11520/32031 (36%)]\tLoss: 374.528687\n",
      "Train Epoch: 4 [12800/32031 (40%)]\tLoss: 385.948669\n",
      "Train Epoch: 4 [14080/32031 (44%)]\tLoss: 362.264923\n",
      "Train Epoch: 4 [15360/32031 (48%)]\tLoss: 366.867584\n",
      "Train Epoch: 4 [16640/32031 (52%)]\tLoss: 360.647156\n",
      "Train Epoch: 4 [17920/32031 (56%)]\tLoss: 343.262512\n",
      "Train Epoch: 4 [19200/32031 (60%)]\tLoss: 349.986115\n",
      "Train Epoch: 4 [20480/32031 (64%)]\tLoss: 358.231934\n",
      "Train Epoch: 4 [21760/32031 (68%)]\tLoss: 340.110779\n",
      "Train Epoch: 4 [23040/32031 (72%)]\tLoss: 374.727325\n",
      "Train Epoch: 4 [24320/32031 (76%)]\tLoss: 353.275726\n",
      "Train Epoch: 4 [25600/32031 (80%)]\tLoss: 350.682129\n",
      "Train Epoch: 4 [26880/32031 (84%)]\tLoss: 382.761444\n",
      "Train Epoch: 4 [28160/32031 (88%)]\tLoss: 359.275848\n",
      "Train Epoch: 4 [29440/32031 (92%)]\tLoss: 352.876892\n",
      "Train Epoch: 4 [30720/32031 (96%)]\tLoss: 370.933563\n",
      "Train Epoch: 4 [7750/32031 (100%)]\tLoss: 371.799238\n",
      "====> Epoch: 4 Average loss: 365.8480\n",
      "====> Test set loss: 370.3429\n",
      "Train Epoch: 5 [0/32031 (0%)]\tLoss: 381.145630\n",
      "Train Epoch: 5 [1280/32031 (4%)]\tLoss: 353.514252\n",
      "Train Epoch: 5 [2560/32031 (8%)]\tLoss: 354.470795\n",
      "Train Epoch: 5 [3840/32031 (12%)]\tLoss: 371.486877\n",
      "Train Epoch: 5 [5120/32031 (16%)]\tLoss: 363.261688\n",
      "Train Epoch: 5 [6400/32031 (20%)]\tLoss: 343.678467\n",
      "Train Epoch: 5 [7680/32031 (24%)]\tLoss: 354.515930\n",
      "Train Epoch: 5 [8960/32031 (28%)]\tLoss: 355.033936\n",
      "Train Epoch: 5 [10240/32031 (32%)]\tLoss: 399.935547\n",
      "Train Epoch: 5 [11520/32031 (36%)]\tLoss: 358.819275\n",
      "Train Epoch: 5 [12800/32031 (40%)]\tLoss: 354.227112\n",
      "Train Epoch: 5 [14080/32031 (44%)]\tLoss: 336.859131\n",
      "Train Epoch: 5 [15360/32031 (48%)]\tLoss: 316.557190\n",
      "Train Epoch: 5 [16640/32031 (52%)]\tLoss: 339.946625\n",
      "Train Epoch: 5 [17920/32031 (56%)]\tLoss: 350.948029\n",
      "Train Epoch: 5 [19200/32031 (60%)]\tLoss: 328.019562\n",
      "Train Epoch: 5 [20480/32031 (64%)]\tLoss: 343.923218\n",
      "Train Epoch: 5 [21760/32031 (68%)]\tLoss: 332.970581\n",
      "Train Epoch: 5 [23040/32031 (72%)]\tLoss: 337.079193\n",
      "Train Epoch: 5 [24320/32031 (76%)]\tLoss: 340.605896\n",
      "Train Epoch: 5 [25600/32031 (80%)]\tLoss: 326.453461\n",
      "Train Epoch: 5 [26880/32031 (84%)]\tLoss: 342.545197\n",
      "Train Epoch: 5 [28160/32031 (88%)]\tLoss: 325.284821\n",
      "Train Epoch: 5 [29440/32031 (92%)]\tLoss: 332.047455\n",
      "Train Epoch: 5 [30720/32031 (96%)]\tLoss: 331.537476\n",
      "Train Epoch: 5 [7750/32031 (100%)]\tLoss: 368.625252\n",
      "====> Epoch: 5 Average loss: 342.7465\n",
      "====> Test set loss: 331.3101\n",
      "Train Epoch: 6 [0/32031 (0%)]\tLoss: 350.080048\n",
      "Train Epoch: 6 [1280/32031 (4%)]\tLoss: 336.999573\n",
      "Train Epoch: 6 [2560/32031 (8%)]\tLoss: 328.628998\n",
      "Train Epoch: 6 [3840/32031 (12%)]\tLoss: 338.259552\n",
      "Train Epoch: 6 [5120/32031 (16%)]\tLoss: 356.518707\n",
      "Train Epoch: 6 [6400/32031 (20%)]\tLoss: 342.668945\n",
      "Train Epoch: 6 [7680/32031 (24%)]\tLoss: 337.583740\n",
      "Train Epoch: 6 [8960/32031 (28%)]\tLoss: 342.684204\n",
      "Train Epoch: 6 [10240/32031 (32%)]\tLoss: 334.505493\n",
      "Train Epoch: 6 [11520/32031 (36%)]\tLoss: 323.187317\n",
      "Train Epoch: 6 [12800/32031 (40%)]\tLoss: 348.725494\n",
      "Train Epoch: 6 [14080/32031 (44%)]\tLoss: 330.299744\n",
      "Train Epoch: 6 [15360/32031 (48%)]\tLoss: 337.461151\n",
      "Train Epoch: 6 [16640/32031 (52%)]\tLoss: 324.060699\n",
      "Train Epoch: 6 [17920/32031 (56%)]\tLoss: 319.068573\n",
      "Train Epoch: 6 [19200/32031 (60%)]\tLoss: 325.254913\n",
      "Train Epoch: 6 [20480/32031 (64%)]\tLoss: 323.844849\n",
      "Train Epoch: 6 [21760/32031 (68%)]\tLoss: 310.920380\n",
      "Train Epoch: 6 [23040/32031 (72%)]\tLoss: 309.973877\n",
      "Train Epoch: 6 [24320/32031 (76%)]\tLoss: 353.497681\n",
      "Train Epoch: 6 [25600/32031 (80%)]\tLoss: 327.044739\n",
      "Train Epoch: 6 [26880/32031 (84%)]\tLoss: 309.320007\n",
      "Train Epoch: 6 [28160/32031 (88%)]\tLoss: 334.078247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [29440/32031 (92%)]\tLoss: 325.621277\n",
      "Train Epoch: 6 [30720/32031 (96%)]\tLoss: 320.515991\n",
      "Train Epoch: 6 [7750/32031 (100%)]\tLoss: 330.263168\n",
      "====> Epoch: 6 Average loss: 330.9819\n",
      "====> Test set loss: 344.5012\n",
      "Train Epoch: 7 [0/32031 (0%)]\tLoss: 355.120483\n",
      "Train Epoch: 7 [1280/32031 (4%)]\tLoss: 333.705780\n",
      "Train Epoch: 7 [2560/32031 (8%)]\tLoss: 313.381439\n",
      "Train Epoch: 7 [3840/32031 (12%)]\tLoss: 305.490601\n",
      "Train Epoch: 7 [5120/32031 (16%)]\tLoss: 318.341919\n",
      "Train Epoch: 7 [6400/32031 (20%)]\tLoss: 327.258453\n",
      "Train Epoch: 7 [7680/32031 (24%)]\tLoss: 319.084869\n",
      "Train Epoch: 7 [8960/32031 (28%)]\tLoss: 316.919434\n",
      "Train Epoch: 7 [10240/32031 (32%)]\tLoss: 320.431824\n",
      "Train Epoch: 7 [11520/32031 (36%)]\tLoss: 332.674255\n",
      "Train Epoch: 7 [12800/32031 (40%)]\tLoss: 324.125946\n",
      "Train Epoch: 7 [14080/32031 (44%)]\tLoss: 323.433685\n",
      "Train Epoch: 7 [15360/32031 (48%)]\tLoss: 319.446747\n",
      "Train Epoch: 7 [16640/32031 (52%)]\tLoss: 328.718292\n",
      "Train Epoch: 7 [17920/32031 (56%)]\tLoss: 328.876404\n",
      "Train Epoch: 7 [19200/32031 (60%)]\tLoss: 304.135712\n",
      "Train Epoch: 7 [20480/32031 (64%)]\tLoss: 305.848114\n",
      "Train Epoch: 7 [21760/32031 (68%)]\tLoss: 327.662842\n",
      "Train Epoch: 7 [23040/32031 (72%)]\tLoss: 323.292938\n",
      "Train Epoch: 7 [24320/32031 (76%)]\tLoss: 312.811920\n",
      "Train Epoch: 7 [25600/32031 (80%)]\tLoss: 344.428009\n",
      "Train Epoch: 7 [26880/32031 (84%)]\tLoss: 303.675171\n",
      "Train Epoch: 7 [28160/32031 (88%)]\tLoss: 326.624023\n",
      "Train Epoch: 7 [29440/32031 (92%)]\tLoss: 291.772461\n",
      "Train Epoch: 7 [30720/32031 (96%)]\tLoss: 342.352844\n",
      "Train Epoch: 7 [7750/32031 (100%)]\tLoss: 319.689390\n",
      "====> Epoch: 7 Average loss: 319.7732\n",
      "====> Test set loss: 326.9131\n",
      "Train Epoch: 8 [0/32031 (0%)]\tLoss: 351.685211\n",
      "Train Epoch: 8 [1280/32031 (4%)]\tLoss: 326.907288\n",
      "Train Epoch: 8 [2560/32031 (8%)]\tLoss: 302.802643\n",
      "Train Epoch: 8 [3840/32031 (12%)]\tLoss: 311.695892\n",
      "Train Epoch: 8 [5120/32031 (16%)]\tLoss: 330.527771\n",
      "Train Epoch: 8 [6400/32031 (20%)]\tLoss: 304.215698\n",
      "Train Epoch: 8 [7680/32031 (24%)]\tLoss: 310.103790\n",
      "Train Epoch: 8 [8960/32031 (28%)]\tLoss: 314.088440\n",
      "Train Epoch: 8 [10240/32031 (32%)]\tLoss: 323.268341\n",
      "Train Epoch: 8 [11520/32031 (36%)]\tLoss: 303.622894\n",
      "Train Epoch: 8 [12800/32031 (40%)]\tLoss: 305.376587\n",
      "Train Epoch: 8 [14080/32031 (44%)]\tLoss: 301.104828\n",
      "Train Epoch: 8 [15360/32031 (48%)]\tLoss: 294.475372\n",
      "Train Epoch: 8 [16640/32031 (52%)]\tLoss: 320.106537\n",
      "Train Epoch: 8 [17920/32031 (56%)]\tLoss: 305.299255\n",
      "Train Epoch: 8 [19200/32031 (60%)]\tLoss: 304.947113\n",
      "Train Epoch: 8 [20480/32031 (64%)]\tLoss: 293.158112\n",
      "Train Epoch: 8 [21760/32031 (68%)]\tLoss: 302.296356\n",
      "Train Epoch: 8 [23040/32031 (72%)]\tLoss: 309.279236\n",
      "Train Epoch: 8 [24320/32031 (76%)]\tLoss: 306.856689\n",
      "Train Epoch: 8 [25600/32031 (80%)]\tLoss: 314.570099\n",
      "Train Epoch: 8 [26880/32031 (84%)]\tLoss: 328.859711\n",
      "Train Epoch: 8 [28160/32031 (88%)]\tLoss: 328.930542\n",
      "Train Epoch: 8 [29440/32031 (92%)]\tLoss: 312.278839\n",
      "Train Epoch: 8 [30720/32031 (96%)]\tLoss: 313.518921\n",
      "Train Epoch: 8 [7750/32031 (100%)]\tLoss: 290.639711\n",
      "====> Epoch: 8 Average loss: 312.3764\n",
      "====> Test set loss: 304.6423\n",
      "Train Epoch: 9 [0/32031 (0%)]\tLoss: 296.920959\n",
      "Train Epoch: 9 [1280/32031 (4%)]\tLoss: 292.759247\n",
      "Train Epoch: 9 [2560/32031 (8%)]\tLoss: 312.292786\n",
      "Train Epoch: 9 [3840/32031 (12%)]\tLoss: 308.220886\n",
      "Train Epoch: 9 [5120/32031 (16%)]\tLoss: 337.811707\n",
      "Train Epoch: 9 [6400/32031 (20%)]\tLoss: 313.690826\n",
      "Train Epoch: 9 [7680/32031 (24%)]\tLoss: 316.227661\n",
      "Train Epoch: 9 [8960/32031 (28%)]\tLoss: 302.660065\n",
      "Train Epoch: 9 [10240/32031 (32%)]\tLoss: 306.346375\n",
      "Train Epoch: 9 [11520/32031 (36%)]\tLoss: 295.062164\n",
      "Train Epoch: 9 [12800/32031 (40%)]\tLoss: 310.474457\n",
      "Train Epoch: 9 [14080/32031 (44%)]\tLoss: 308.189484\n",
      "Train Epoch: 9 [15360/32031 (48%)]\tLoss: 296.355164\n",
      "Train Epoch: 9 [16640/32031 (52%)]\tLoss: 331.509552\n",
      "Train Epoch: 9 [17920/32031 (56%)]\tLoss: 306.563721\n",
      "Train Epoch: 9 [19200/32031 (60%)]\tLoss: 312.861816\n",
      "Train Epoch: 9 [20480/32031 (64%)]\tLoss: 285.678101\n",
      "Train Epoch: 9 [21760/32031 (68%)]\tLoss: 311.984436\n",
      "Train Epoch: 9 [23040/32031 (72%)]\tLoss: 333.386749\n",
      "Train Epoch: 9 [24320/32031 (76%)]\tLoss: 304.007751\n",
      "Train Epoch: 9 [25600/32031 (80%)]\tLoss: 290.260254\n",
      "Train Epoch: 9 [26880/32031 (84%)]\tLoss: 291.533691\n",
      "Train Epoch: 9 [28160/32031 (88%)]\tLoss: 308.236603\n",
      "Train Epoch: 9 [29440/32031 (92%)]\tLoss: 277.506775\n",
      "Train Epoch: 9 [30720/32031 (96%)]\tLoss: 332.607330\n",
      "Train Epoch: 9 [7750/32031 (100%)]\tLoss: 265.145445\n",
      "====> Epoch: 9 Average loss: 307.1249\n",
      "====> Test set loss: 312.8598\n",
      "Train Epoch: 10 [0/32031 (0%)]\tLoss: 323.000458\n",
      "Train Epoch: 10 [1280/32031 (4%)]\tLoss: 295.780792\n",
      "Train Epoch: 10 [2560/32031 (8%)]\tLoss: 309.256866\n",
      "Train Epoch: 10 [3840/32031 (12%)]\tLoss: 300.665436\n",
      "Train Epoch: 10 [5120/32031 (16%)]\tLoss: 304.101532\n",
      "Train Epoch: 10 [6400/32031 (20%)]\tLoss: 314.026062\n",
      "Train Epoch: 10 [7680/32031 (24%)]\tLoss: 309.473938\n",
      "Train Epoch: 10 [8960/32031 (28%)]\tLoss: 312.914154\n",
      "Train Epoch: 10 [10240/32031 (32%)]\tLoss: 331.872162\n",
      "Train Epoch: 10 [11520/32031 (36%)]\tLoss: 297.425079\n",
      "Train Epoch: 10 [12800/32031 (40%)]\tLoss: 308.386749\n",
      "Train Epoch: 10 [14080/32031 (44%)]\tLoss: 290.529144\n",
      "Train Epoch: 10 [15360/32031 (48%)]\tLoss: 305.889374\n",
      "Train Epoch: 10 [16640/32031 (52%)]\tLoss: 321.802979\n",
      "Train Epoch: 10 [17920/32031 (56%)]\tLoss: 302.395782\n",
      "Train Epoch: 10 [19200/32031 (60%)]\tLoss: 300.710876\n",
      "Train Epoch: 10 [20480/32031 (64%)]\tLoss: 297.961853\n",
      "Train Epoch: 10 [21760/32031 (68%)]\tLoss: 314.582581\n",
      "Train Epoch: 10 [23040/32031 (72%)]\tLoss: 329.501526\n",
      "Train Epoch: 10 [24320/32031 (76%)]\tLoss: 297.182129\n",
      "Train Epoch: 10 [25600/32031 (80%)]\tLoss: 298.947266\n",
      "Train Epoch: 10 [26880/32031 (84%)]\tLoss: 307.805176\n",
      "Train Epoch: 10 [28160/32031 (88%)]\tLoss: 299.249207\n",
      "Train Epoch: 10 [29440/32031 (92%)]\tLoss: 290.744568\n",
      "Train Epoch: 10 [30720/32031 (96%)]\tLoss: 313.286133\n",
      "Train Epoch: 10 [7750/32031 (100%)]\tLoss: 315.888010\n",
      "====> Epoch: 10 Average loss: 304.1908\n",
      "====> Test set loss: 304.3378\n",
      "Train Epoch: 11 [0/32031 (0%)]\tLoss: 299.437561\n",
      "Train Epoch: 11 [1280/32031 (4%)]\tLoss: 304.573273\n",
      "Train Epoch: 11 [2560/32031 (8%)]\tLoss: 299.786743\n",
      "Train Epoch: 11 [3840/32031 (12%)]\tLoss: 283.718445\n",
      "Train Epoch: 11 [5120/32031 (16%)]\tLoss: 294.468048\n",
      "Train Epoch: 11 [6400/32031 (20%)]\tLoss: 293.297668\n",
      "Train Epoch: 11 [7680/32031 (24%)]\tLoss: 318.671997\n",
      "Train Epoch: 11 [8960/32031 (28%)]\tLoss: 291.214996\n",
      "Train Epoch: 11 [10240/32031 (32%)]\tLoss: 308.461060\n",
      "Train Epoch: 11 [11520/32031 (36%)]\tLoss: 284.680725\n",
      "Train Epoch: 11 [12800/32031 (40%)]\tLoss: 295.786682\n",
      "Train Epoch: 11 [14080/32031 (44%)]\tLoss: 288.703705\n",
      "Train Epoch: 11 [15360/32031 (48%)]\tLoss: 317.352325\n",
      "Train Epoch: 11 [16640/32031 (52%)]\tLoss: 304.865540\n",
      "Train Epoch: 11 [17920/32031 (56%)]\tLoss: 322.627747\n",
      "Train Epoch: 11 [19200/32031 (60%)]\tLoss: 289.733276\n",
      "Train Epoch: 11 [20480/32031 (64%)]\tLoss: 305.799255\n",
      "Train Epoch: 11 [21760/32031 (68%)]\tLoss: 299.687775\n",
      "Train Epoch: 11 [23040/32031 (72%)]\tLoss: 310.303009\n",
      "Train Epoch: 11 [24320/32031 (76%)]\tLoss: 302.307281\n",
      "Train Epoch: 11 [25600/32031 (80%)]\tLoss: 294.860107\n",
      "Train Epoch: 11 [26880/32031 (84%)]\tLoss: 286.562805\n",
      "Train Epoch: 11 [28160/32031 (88%)]\tLoss: 296.862976\n",
      "Train Epoch: 11 [29440/32031 (92%)]\tLoss: 308.650574\n",
      "Train Epoch: 11 [30720/32031 (96%)]\tLoss: 293.570557\n",
      "Train Epoch: 11 [7750/32031 (100%)]\tLoss: 283.886561\n",
      "====> Epoch: 11 Average loss: 301.5076\n",
      "====> Test set loss: 304.5958\n",
      "Train Epoch: 12 [0/32031 (0%)]\tLoss: 313.211060\n",
      "Train Epoch: 12 [1280/32031 (4%)]\tLoss: 304.980682\n",
      "Train Epoch: 12 [2560/32031 (8%)]\tLoss: 280.414734\n",
      "Train Epoch: 12 [3840/32031 (12%)]\tLoss: 299.147614\n",
      "Train Epoch: 12 [5120/32031 (16%)]\tLoss: 288.995941\n",
      "Train Epoch: 12 [6400/32031 (20%)]\tLoss: 284.412842\n",
      "Train Epoch: 12 [7680/32031 (24%)]\tLoss: 302.161072\n",
      "Train Epoch: 12 [8960/32031 (28%)]\tLoss: 320.936096\n",
      "Train Epoch: 12 [10240/32031 (32%)]\tLoss: 305.116241\n",
      "Train Epoch: 12 [11520/32031 (36%)]\tLoss: 298.070557\n",
      "Train Epoch: 12 [12800/32031 (40%)]\tLoss: 289.683044\n",
      "Train Epoch: 12 [14080/32031 (44%)]\tLoss: 285.284760\n",
      "Train Epoch: 12 [15360/32031 (48%)]\tLoss: 304.750458\n",
      "Train Epoch: 12 [16640/32031 (52%)]\tLoss: 289.947876\n",
      "Train Epoch: 12 [17920/32031 (56%)]\tLoss: 306.951385\n",
      "Train Epoch: 12 [19200/32031 (60%)]\tLoss: 307.193054\n",
      "Train Epoch: 12 [20480/32031 (64%)]\tLoss: 304.905548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [21760/32031 (68%)]\tLoss: 289.724670\n",
      "Train Epoch: 12 [23040/32031 (72%)]\tLoss: 304.851807\n",
      "Train Epoch: 12 [24320/32031 (76%)]\tLoss: 307.777832\n",
      "Train Epoch: 12 [25600/32031 (80%)]\tLoss: 302.965454\n",
      "Train Epoch: 12 [26880/32031 (84%)]\tLoss: 292.791992\n",
      "Train Epoch: 12 [28160/32031 (88%)]\tLoss: 294.424500\n",
      "Train Epoch: 12 [29440/32031 (92%)]\tLoss: 309.606262\n",
      "Train Epoch: 12 [30720/32031 (96%)]\tLoss: 310.766937\n",
      "Train Epoch: 12 [7750/32031 (100%)]\tLoss: 260.013262\n",
      "====> Epoch: 12 Average loss: 300.2108\n",
      "====> Test set loss: 297.3886\n",
      "Train Epoch: 13 [0/32031 (0%)]\tLoss: 284.801544\n",
      "Train Epoch: 13 [1280/32031 (4%)]\tLoss: 297.667847\n",
      "Train Epoch: 13 [2560/32031 (8%)]\tLoss: 293.782440\n",
      "Train Epoch: 13 [3840/32031 (12%)]\tLoss: 281.318085\n",
      "Train Epoch: 13 [5120/32031 (16%)]\tLoss: 281.117920\n",
      "Train Epoch: 13 [6400/32031 (20%)]\tLoss: 307.311035\n",
      "Train Epoch: 13 [7680/32031 (24%)]\tLoss: 286.754700\n",
      "Train Epoch: 13 [8960/32031 (28%)]\tLoss: 305.650360\n",
      "Train Epoch: 13 [10240/32031 (32%)]\tLoss: 304.577759\n",
      "Train Epoch: 13 [11520/32031 (36%)]\tLoss: 299.240936\n",
      "Train Epoch: 13 [12800/32031 (40%)]\tLoss: 289.442719\n",
      "Train Epoch: 13 [14080/32031 (44%)]\tLoss: 286.086243\n",
      "Train Epoch: 13 [15360/32031 (48%)]\tLoss: 288.117004\n",
      "Train Epoch: 13 [16640/32031 (52%)]\tLoss: 315.701904\n",
      "Train Epoch: 13 [17920/32031 (56%)]\tLoss: 318.181427\n",
      "Train Epoch: 13 [19200/32031 (60%)]\tLoss: 296.630707\n",
      "Train Epoch: 13 [20480/32031 (64%)]\tLoss: 288.234863\n",
      "Train Epoch: 13 [21760/32031 (68%)]\tLoss: 295.932159\n",
      "Train Epoch: 13 [23040/32031 (72%)]\tLoss: 284.799591\n",
      "Train Epoch: 13 [24320/32031 (76%)]\tLoss: 285.162018\n",
      "Train Epoch: 13 [25600/32031 (80%)]\tLoss: 313.154388\n",
      "Train Epoch: 13 [26880/32031 (84%)]\tLoss: 288.652069\n",
      "Train Epoch: 13 [28160/32031 (88%)]\tLoss: 288.172119\n",
      "Train Epoch: 13 [29440/32031 (92%)]\tLoss: 300.956116\n",
      "Train Epoch: 13 [30720/32031 (96%)]\tLoss: 306.055420\n",
      "Train Epoch: 13 [7750/32031 (100%)]\tLoss: 291.031345\n",
      "====> Epoch: 13 Average loss: 293.1638\n",
      "====> Test set loss: 290.0884\n",
      "Train Epoch: 14 [0/32031 (0%)]\tLoss: 306.145905\n",
      "Train Epoch: 14 [1280/32031 (4%)]\tLoss: 273.036377\n",
      "Train Epoch: 14 [2560/32031 (8%)]\tLoss: 297.796600\n",
      "Train Epoch: 14 [3840/32031 (12%)]\tLoss: 285.343414\n",
      "Train Epoch: 14 [5120/32031 (16%)]\tLoss: 276.975128\n",
      "Train Epoch: 14 [6400/32031 (20%)]\tLoss: 285.053406\n",
      "Train Epoch: 14 [7680/32031 (24%)]\tLoss: 314.427185\n",
      "Train Epoch: 14 [8960/32031 (28%)]\tLoss: 287.976929\n",
      "Train Epoch: 14 [10240/32031 (32%)]\tLoss: 282.304474\n",
      "Train Epoch: 14 [11520/32031 (36%)]\tLoss: 278.723999\n",
      "Train Epoch: 14 [12800/32031 (40%)]\tLoss: 285.739044\n",
      "Train Epoch: 14 [14080/32031 (44%)]\tLoss: 281.564545\n",
      "Train Epoch: 14 [15360/32031 (48%)]\tLoss: 285.009644\n",
      "Train Epoch: 14 [16640/32031 (52%)]\tLoss: 302.531189\n",
      "Train Epoch: 14 [17920/32031 (56%)]\tLoss: 303.421448\n",
      "Train Epoch: 14 [19200/32031 (60%)]\tLoss: 284.135498\n",
      "Train Epoch: 14 [20480/32031 (64%)]\tLoss: 289.433044\n",
      "Train Epoch: 14 [21760/32031 (68%)]\tLoss: 316.834900\n",
      "Train Epoch: 14 [23040/32031 (72%)]\tLoss: 300.228455\n",
      "Train Epoch: 14 [24320/32031 (76%)]\tLoss: 284.472504\n",
      "Train Epoch: 14 [25600/32031 (80%)]\tLoss: 289.398804\n",
      "Train Epoch: 14 [26880/32031 (84%)]\tLoss: 286.334991\n",
      "Train Epoch: 14 [28160/32031 (88%)]\tLoss: 305.132446\n",
      "Train Epoch: 14 [29440/32031 (92%)]\tLoss: 276.679871\n",
      "Train Epoch: 14 [30720/32031 (96%)]\tLoss: 282.907043\n",
      "Train Epoch: 14 [7750/32031 (100%)]\tLoss: 327.748645\n",
      "====> Epoch: 14 Average loss: 289.3482\n",
      "====> Test set loss: 292.4807\n",
      "Train Epoch: 15 [0/32031 (0%)]\tLoss: 302.933380\n",
      "Train Epoch: 15 [1280/32031 (4%)]\tLoss: 287.117310\n",
      "Train Epoch: 15 [2560/32031 (8%)]\tLoss: 288.028900\n",
      "Train Epoch: 15 [3840/32031 (12%)]\tLoss: 296.345520\n",
      "Train Epoch: 15 [5120/32031 (16%)]\tLoss: 284.046906\n",
      "Train Epoch: 15 [6400/32031 (20%)]\tLoss: 271.214630\n",
      "Train Epoch: 15 [7680/32031 (24%)]\tLoss: 279.685150\n",
      "Train Epoch: 15 [8960/32031 (28%)]\tLoss: 285.733795\n",
      "Train Epoch: 15 [10240/32031 (32%)]\tLoss: 286.590271\n",
      "Train Epoch: 15 [11520/32031 (36%)]\tLoss: 290.347931\n",
      "Train Epoch: 15 [12800/32031 (40%)]\tLoss: 273.166931\n",
      "Train Epoch: 15 [14080/32031 (44%)]\tLoss: 274.817352\n",
      "Train Epoch: 15 [15360/32031 (48%)]\tLoss: 291.481110\n",
      "Train Epoch: 15 [16640/32031 (52%)]\tLoss: 290.532318\n",
      "Train Epoch: 15 [17920/32031 (56%)]\tLoss: 302.473053\n",
      "Train Epoch: 15 [19200/32031 (60%)]\tLoss: 285.769379\n",
      "Train Epoch: 15 [20480/32031 (64%)]\tLoss: 264.815521\n",
      "Train Epoch: 15 [21760/32031 (68%)]\tLoss: 292.196320\n",
      "Train Epoch: 15 [23040/32031 (72%)]\tLoss: 300.016479\n",
      "Train Epoch: 15 [24320/32031 (76%)]\tLoss: 272.758423\n",
      "Train Epoch: 15 [25600/32031 (80%)]\tLoss: 295.584900\n",
      "Train Epoch: 15 [26880/32031 (84%)]\tLoss: 286.538727\n",
      "Train Epoch: 15 [28160/32031 (88%)]\tLoss: 266.319061\n",
      "Train Epoch: 16 [17920/32031 (56%)]\tLoss: 282.539703\n",
      "Train Epoch: 16 [19200/32031 (60%)]\tLoss: 287.256683\n",
      "Train Epoch: 16 [20480/32031 (64%)]\tLoss: 308.325134\n",
      "Train Epoch: 16 [21760/32031 (68%)]\tLoss: 279.250763\n",
      "Train Epoch: 16 [23040/32031 (72%)]\tLoss: 290.802338\n",
      "Train Epoch: 16 [24320/32031 (76%)]\tLoss: 295.586792\n",
      "Train Epoch: 16 [25600/32031 (80%)]\tLoss: 305.035706\n",
      "Train Epoch: 16 [26880/32031 (84%)]\tLoss: 291.111023\n",
      "Train Epoch: 16 [28160/32031 (88%)]\tLoss: 307.638031\n",
      "Train Epoch: 16 [29440/32031 (92%)]\tLoss: 292.933807\n",
      "Train Epoch: 16 [30720/32031 (96%)]\tLoss: 292.889832\n",
      "Train Epoch: 16 [7750/32031 (100%)]\tLoss: 296.433720\n",
      "====> Epoch: 16 Average loss: 284.7624\n",
      "====> Test set loss: 286.5779\n",
      "Train Epoch: 17 [0/32031 (0%)]\tLoss: 293.930817\n",
      "Train Epoch: 17 [1280/32031 (4%)]\tLoss: 279.055939\n",
      "Train Epoch: 17 [2560/32031 (8%)]\tLoss: 278.639343\n",
      "Train Epoch: 17 [3840/32031 (12%)]\tLoss: 279.490814\n",
      "Train Epoch: 17 [5120/32031 (16%)]\tLoss: 281.557343\n",
      "Train Epoch: 17 [6400/32031 (20%)]\tLoss: 292.331909\n",
      "Train Epoch: 17 [7680/32031 (24%)]\tLoss: 295.319885\n",
      "Train Epoch: 17 [8960/32031 (28%)]\tLoss: 301.804718\n",
      "Train Epoch: 17 [10240/32031 (32%)]\tLoss: 275.864197\n",
      "Train Epoch: 17 [11520/32031 (36%)]\tLoss: 280.389618\n",
      "Train Epoch: 17 [12800/32031 (40%)]\tLoss: 272.940216\n",
      "Train Epoch: 17 [14080/32031 (44%)]\tLoss: 287.951843\n",
      "Train Epoch: 17 [15360/32031 (48%)]\tLoss: 263.479675\n",
      "Train Epoch: 17 [16640/32031 (52%)]\tLoss: 267.623688\n",
      "Train Epoch: 17 [17920/32031 (56%)]\tLoss: 270.713257\n",
      "Train Epoch: 17 [19200/32031 (60%)]\tLoss: 278.735138\n",
      "Train Epoch: 17 [20480/32031 (64%)]\tLoss: 283.621643\n",
      "Train Epoch: 17 [21760/32031 (68%)]\tLoss: 279.976288\n",
      "Train Epoch: 17 [23040/32031 (72%)]\tLoss: 281.444824\n",
      "Train Epoch: 17 [24320/32031 (76%)]\tLoss: 292.275421\n",
      "Train Epoch: 17 [25600/32031 (80%)]\tLoss: 283.176849\n",
      "Train Epoch: 17 [26880/32031 (84%)]\tLoss: 273.415619\n",
      "Train Epoch: 17 [28160/32031 (88%)]\tLoss: 293.927765\n",
      "Train Epoch: 17 [29440/32031 (92%)]\tLoss: 276.001282\n",
      "Train Epoch: 17 [30720/32031 (96%)]\tLoss: 299.370941\n",
      "Train Epoch: 17 [7750/32031 (100%)]\tLoss: 274.932523\n",
      "====> Epoch: 17 Average loss: 283.3137\n",
      "====> Test set loss: 282.3890\n",
      "Train Epoch: 18 [0/32031 (0%)]\tLoss: 279.872681\n",
      "Train Epoch: 18 [1280/32031 (4%)]\tLoss: 263.320831\n",
      "Train Epoch: 18 [2560/32031 (8%)]\tLoss: 292.518372\n",
      "Train Epoch: 18 [3840/32031 (12%)]\tLoss: 308.930511\n",
      "Train Epoch: 18 [5120/32031 (16%)]\tLoss: 266.201935\n",
      "Train Epoch: 18 [6400/32031 (20%)]\tLoss: 271.957855\n",
      "Train Epoch: 18 [7680/32031 (24%)]\tLoss: 278.380829\n",
      "Train Epoch: 18 [8960/32031 (28%)]\tLoss: 285.162048\n",
      "Train Epoch: 18 [10240/32031 (32%)]\tLoss: 278.331879\n",
      "Train Epoch: 18 [11520/32031 (36%)]\tLoss: 285.175232\n",
      "Train Epoch: 18 [12800/32031 (40%)]\tLoss: 287.897369\n",
      "Train Epoch: 18 [14080/32031 (44%)]\tLoss: 286.434387\n",
      "Train Epoch: 18 [15360/32031 (48%)]\tLoss: 285.687561\n",
      "Train Epoch: 18 [16640/32031 (52%)]\tLoss: 298.389435\n",
      "Train Epoch: 18 [17920/32031 (56%)]\tLoss: 285.699493\n",
      "Train Epoch: 18 [19200/32031 (60%)]\tLoss: 268.844513\n",
      "Train Epoch: 18 [20480/32031 (64%)]\tLoss: 280.565369\n",
      "Train Epoch: 18 [21760/32031 (68%)]\tLoss: 269.680115\n",
      "Train Epoch: 18 [23040/32031 (72%)]\tLoss: 289.488770\n",
      "Train Epoch: 18 [24320/32031 (76%)]\tLoss: 277.741119\n",
      "Train Epoch: 18 [25600/32031 (80%)]\tLoss: 267.481689\n",
      "Train Epoch: 18 [26880/32031 (84%)]\tLoss: 275.508331\n",
      "Train Epoch: 18 [28160/32031 (88%)]\tLoss: 255.870621\n",
      "Train Epoch: 18 [29440/32031 (92%)]\tLoss: 289.507080\n",
      "Train Epoch: 18 [30720/32031 (96%)]\tLoss: 279.086731\n",
      "Train Epoch: 18 [7750/32031 (100%)]\tLoss: 280.752363\n",
      "====> Epoch: 18 Average loss: 280.5664\n",
      "====> Test set loss: 276.3532\n",
      "Train Epoch: 19 [0/32031 (0%)]\tLoss: 285.388641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [1280/32031 (4%)]\tLoss: 275.049072\n",
      "Train Epoch: 19 [2560/32031 (8%)]\tLoss: 255.114014\n",
      "Train Epoch: 19 [3840/32031 (12%)]\tLoss: 269.161255\n",
      "Train Epoch: 19 [5120/32031 (16%)]\tLoss: 257.389496\n",
      "Train Epoch: 19 [6400/32031 (20%)]\tLoss: 293.263275\n",
      "Train Epoch: 19 [7680/32031 (24%)]\tLoss: 282.462860\n",
      "Train Epoch: 19 [8960/32031 (28%)]\tLoss: 281.212738\n",
      "Train Epoch: 19 [10240/32031 (32%)]\tLoss: 290.877075\n",
      "Train Epoch: 19 [11520/32031 (36%)]\tLoss: 274.673248\n",
      "Train Epoch: 19 [12800/32031 (40%)]\tLoss: 289.820892\n",
      "Train Epoch: 19 [14080/32031 (44%)]\tLoss: 274.904266\n",
      "Train Epoch: 19 [15360/32031 (48%)]\tLoss: 274.722351\n",
      "Train Epoch: 19 [16640/32031 (52%)]\tLoss: 274.510406\n",
      "Train Epoch: 19 [17920/32031 (56%)]\tLoss: 295.228668\n",
      "Train Epoch: 19 [19200/32031 (60%)]\tLoss: 285.307587\n",
      "Train Epoch: 19 [20480/32031 (64%)]\tLoss: 257.402985\n",
      "Train Epoch: 19 [21760/32031 (68%)]\tLoss: 287.267517\n",
      "Train Epoch: 19 [23040/32031 (72%)]\tLoss: 275.571716\n",
      "Train Epoch: 19 [24320/32031 (76%)]\tLoss: 262.934082\n",
      "Train Epoch: 19 [25600/32031 (80%)]\tLoss: 286.365265\n",
      "Train Epoch: 19 [26880/32031 (84%)]\tLoss: 271.453339\n",
      "Train Epoch: 19 [28160/32031 (88%)]\tLoss: 272.958618\n",
      "Train Epoch: 19 [29440/32031 (92%)]\tLoss: 287.822174\n",
      "Train Epoch: 19 [30720/32031 (96%)]\tLoss: 267.232666\n",
      "Train Epoch: 19 [7750/32031 (100%)]\tLoss: 279.127772\n",
      "====> Epoch: 19 Average loss: 276.9815\n",
      "====> Test set loss: 279.6854\n",
      "Train Epoch: 20 [0/32031 (0%)]\tLoss: 280.533417\n",
      "Train Epoch: 20 [1280/32031 (4%)]\tLoss: 277.636658\n",
      "Train Epoch: 20 [2560/32031 (8%)]\tLoss: 272.133514\n",
      "Train Epoch: 20 [3840/32031 (12%)]\tLoss: 270.755768\n",
      "Train Epoch: 20 [5120/32031 (16%)]\tLoss: 290.503082\n",
      "Train Epoch: 20 [6400/32031 (20%)]\tLoss: 280.008209\n",
      "Train Epoch: 20 [7680/32031 (24%)]\tLoss: 274.872772\n",
      "Train Epoch: 20 [8960/32031 (28%)]\tLoss: 289.710785\n",
      "Train Epoch: 20 [10240/32031 (32%)]\tLoss: 274.313202\n",
      "Train Epoch: 20 [11520/32031 (36%)]\tLoss: 261.027710\n",
      "Train Epoch: 20 [12800/32031 (40%)]\tLoss: 285.678711\n",
      "Train Epoch: 20 [14080/32031 (44%)]\tLoss: 277.172943\n",
      "Train Epoch: 20 [15360/32031 (48%)]\tLoss: 265.649658\n",
      "Train Epoch: 20 [16640/32031 (52%)]\tLoss: 270.502258\n",
      "Train Epoch: 20 [17920/32031 (56%)]\tLoss: 308.973999\n",
      "Train Epoch: 20 [19200/32031 (60%)]\tLoss: 251.369247\n",
      "Train Epoch: 20 [20480/32031 (64%)]\tLoss: 276.655914\n",
      "Train Epoch: 20 [21760/32031 (68%)]\tLoss: 272.330933\n",
      "Train Epoch: 20 [23040/32031 (72%)]\tLoss: 277.939514\n",
      "Train Epoch: 20 [24320/32031 (76%)]\tLoss: 269.912598\n",
      "Train Epoch: 20 [25600/32031 (80%)]\tLoss: 296.032867\n",
      "Train Epoch: 20 [26880/32031 (84%)]\tLoss: 280.930908\n",
      "Train Epoch: 20 [28160/32031 (88%)]\tLoss: 266.094086\n",
      "Train Epoch: 20 [29440/32031 (92%)]\tLoss: 260.112274\n",
      "Train Epoch: 20 [30720/32031 (96%)]\tLoss: 281.983612\n",
      "Train Epoch: 20 [7750/32031 (100%)]\tLoss: 311.170646\n",
      "====> Epoch: 20 Average loss: 274.6611\n",
      "====> Test set loss: 276.9785\n",
      "Train Epoch: 21 [0/32031 (0%)]\tLoss: 305.904694\n",
      "Train Epoch: 21 [1280/32031 (4%)]\tLoss: 271.820618\n",
      "Train Epoch: 21 [2560/32031 (8%)]\tLoss: 262.000641\n",
      "Train Epoch: 21 [3840/32031 (12%)]\tLoss: 277.852325\n",
      "Train Epoch: 21 [5120/32031 (16%)]\tLoss: 269.736481\n",
      "Train Epoch: 21 [6400/32031 (20%)]\tLoss: 254.531067\n",
      "Train Epoch: 21 [7680/32031 (24%)]\tLoss: 255.277847\n",
      "Train Epoch: 21 [8960/32031 (28%)]\tLoss: 276.418365\n",
      "Train Epoch: 21 [10240/32031 (32%)]\tLoss: 274.323517\n",
      "Train Epoch: 21 [11520/32031 (36%)]\tLoss: 258.044037\n",
      "Train Epoch: 21 [12800/32031 (40%)]\tLoss: 262.053650\n",
      "Train Epoch: 21 [14080/32031 (44%)]\tLoss: 276.835815\n",
      "Train Epoch: 21 [15360/32031 (48%)]\tLoss: 260.254883\n",
      "Train Epoch: 21 [16640/32031 (52%)]\tLoss: 278.710815\n",
      "Train Epoch: 21 [17920/32031 (56%)]\tLoss: 266.798706\n",
      "Train Epoch: 21 [19200/32031 (60%)]\tLoss: 284.467651\n",
      "Train Epoch: 21 [20480/32031 (64%)]\tLoss: 269.115875\n",
      "Train Epoch: 21 [21760/32031 (68%)]\tLoss: 264.154602\n",
      "Train Epoch: 21 [23040/32031 (72%)]\tLoss: 270.422516\n",
      "Train Epoch: 21 [24320/32031 (76%)]\tLoss: 278.287018\n",
      "Train Epoch: 21 [25600/32031 (80%)]\tLoss: 276.754303\n",
      "Train Epoch: 21 [26880/32031 (84%)]\tLoss: 278.824707\n",
      "Train Epoch: 21 [28160/32031 (88%)]\tLoss: 279.379242\n",
      "Train Epoch: 21 [29440/32031 (92%)]\tLoss: 274.436401\n",
      "Train Epoch: 21 [30720/32031 (96%)]\tLoss: 279.750641\n",
      "Train Epoch: 21 [7750/32031 (100%)]\tLoss: 298.448463\n",
      "====> Epoch: 21 Average loss: 273.2161\n",
      "====> Test set loss: 271.3798\n",
      "Train Epoch: 22 [0/32031 (0%)]\tLoss: 272.973633\n",
      "Train Epoch: 22 [1280/32031 (4%)]\tLoss: 273.937958\n",
      "Train Epoch: 22 [2560/32031 (8%)]\tLoss: 281.508087\n",
      "Train Epoch: 22 [3840/32031 (12%)]\tLoss: 289.227203\n",
      "Train Epoch: 22 [5120/32031 (16%)]\tLoss: 272.976074\n",
      "Train Epoch: 22 [6400/32031 (20%)]\tLoss: 271.207428\n",
      "Train Epoch: 22 [7680/32031 (24%)]\tLoss: 278.438568\n",
      "Train Epoch: 22 [8960/32031 (28%)]\tLoss: 264.035461\n",
      "Train Epoch: 22 [10240/32031 (32%)]\tLoss: 265.306335\n",
      "Train Epoch: 22 [11520/32031 (36%)]\tLoss: 271.919708\n",
      "Train Epoch: 22 [12800/32031 (40%)]\tLoss: 264.140228\n",
      "Train Epoch: 22 [14080/32031 (44%)]\tLoss: 276.362335\n",
      "Train Epoch: 22 [15360/32031 (48%)]\tLoss: 276.601257\n",
      "Train Epoch: 22 [16640/32031 (52%)]\tLoss: 265.835327\n",
      "Train Epoch: 22 [17920/32031 (56%)]\tLoss: 251.432907\n",
      "Train Epoch: 22 [19200/32031 (60%)]\tLoss: 252.457657\n",
      "Train Epoch: 22 [20480/32031 (64%)]\tLoss: 269.506989\n",
      "Train Epoch: 22 [21760/32031 (68%)]\tLoss: 248.928192\n",
      "Train Epoch: 22 [23040/32031 (72%)]\tLoss: 264.648682\n",
      "Train Epoch: 22 [24320/32031 (76%)]\tLoss: 265.861542\n",
      "Train Epoch: 22 [25600/32031 (80%)]\tLoss: 282.154724\n",
      "Train Epoch: 22 [26880/32031 (84%)]\tLoss: 262.647491\n",
      "Train Epoch: 22 [28160/32031 (88%)]\tLoss: 252.040268\n",
      "Train Epoch: 22 [29440/32031 (92%)]\tLoss: 260.942627\n",
      "Train Epoch: 22 [30720/32031 (96%)]\tLoss: 273.181305\n",
      "Train Epoch: 22 [7750/32031 (100%)]\tLoss: 284.254190\n",
      "====> Epoch: 22 Average loss: 271.2797\n",
      "====> Test set loss: 268.2496\n",
      "Train Epoch: 23 [0/32031 (0%)]\tLoss: 269.715668\n",
      "Train Epoch: 23 [1280/32031 (4%)]\tLoss: 279.125671\n",
      "Train Epoch: 23 [2560/32031 (8%)]\tLoss: 262.599182\n",
      "Train Epoch: 23 [3840/32031 (12%)]\tLoss: 271.961975\n",
      "Train Epoch: 23 [5120/32031 (16%)]\tLoss: 260.131226\n",
      "Train Epoch: 23 [6400/32031 (20%)]\tLoss: 280.132843\n",
      "Train Epoch: 23 [7680/32031 (24%)]\tLoss: 267.322968\n",
      "Train Epoch: 23 [8960/32031 (28%)]\tLoss: 274.139984\n",
      "Train Epoch: 23 [10240/32031 (32%)]\tLoss: 265.165100\n",
      "Train Epoch: 23 [11520/32031 (36%)]\tLoss: 263.965485\n",
      "Train Epoch: 23 [12800/32031 (40%)]\tLoss: 285.370422\n",
      "Train Epoch: 23 [14080/32031 (44%)]\tLoss: 255.849319\n",
      "Train Epoch: 23 [15360/32031 (48%)]\tLoss: 256.981628\n",
      "Train Epoch: 23 [16640/32031 (52%)]\tLoss: 277.753052\n",
      "Train Epoch: 23 [17920/32031 (56%)]\tLoss: 274.992462\n",
      "Train Epoch: 23 [19200/32031 (60%)]\tLoss: 270.236145\n",
      "Train Epoch: 23 [20480/32031 (64%)]\tLoss: 264.240753\n",
      "Train Epoch: 23 [21760/32031 (68%)]\tLoss: 263.102661\n",
      "Train Epoch: 23 [23040/32031 (72%)]\tLoss: 265.659241\n",
      "Train Epoch: 23 [24320/32031 (76%)]\tLoss: 275.420074\n",
      "Train Epoch: 23 [25600/32031 (80%)]\tLoss: 258.206421\n",
      "Train Epoch: 23 [26880/32031 (84%)]\tLoss: 271.614655\n",
      "Train Epoch: 23 [28160/32031 (88%)]\tLoss: 279.994446\n",
      "Train Epoch: 23 [29440/32031 (92%)]\tLoss: 263.968353\n",
      "Train Epoch: 23 [30720/32031 (96%)]\tLoss: 273.278137\n",
      "Train Epoch: 23 [7750/32031 (100%)]\tLoss: 275.054845\n",
      "====> Epoch: 23 Average loss: 271.9356\n",
      "====> Test set loss: 272.5535\n",
      "Train Epoch: 24 [0/32031 (0%)]\tLoss: 300.029449\n",
      "Train Epoch: 24 [1280/32031 (4%)]\tLoss: 267.645569\n",
      "Train Epoch: 24 [2560/32031 (8%)]\tLoss: 270.183807\n",
      "Train Epoch: 24 [3840/32031 (12%)]\tLoss: 268.397552\n",
      "Train Epoch: 24 [5120/32031 (16%)]\tLoss: 270.508148\n",
      "Train Epoch: 24 [6400/32031 (20%)]\tLoss: 284.088348\n",
      "Train Epoch: 24 [7680/32031 (24%)]\tLoss: 273.151154\n",
      "Train Epoch: 24 [8960/32031 (28%)]\tLoss: 273.165009\n",
      "Train Epoch: 24 [10240/32031 (32%)]\tLoss: 269.863708\n",
      "Train Epoch: 24 [11520/32031 (36%)]\tLoss: 252.976990\n",
      "Train Epoch: 24 [12800/32031 (40%)]\tLoss: 254.325745\n",
      "Train Epoch: 24 [14080/32031 (44%)]\tLoss: 271.564514\n",
      "Train Epoch: 24 [15360/32031 (48%)]\tLoss: 267.151611\n",
      "Train Epoch: 24 [16640/32031 (52%)]\tLoss: 283.831360\n",
      "Train Epoch: 24 [17920/32031 (56%)]\tLoss: 268.868317\n",
      "Train Epoch: 24 [19200/32031 (60%)]\tLoss: 272.414398\n",
      "Train Epoch: 24 [20480/32031 (64%)]\tLoss: 269.942596\n",
      "Train Epoch: 24 [21760/32031 (68%)]\tLoss: 270.415405\n",
      "Train Epoch: 24 [23040/32031 (72%)]\tLoss: 274.841187\n",
      "Train Epoch: 24 [24320/32031 (76%)]\tLoss: 265.422668\n",
      "Train Epoch: 24 [25600/32031 (80%)]\tLoss: 256.091583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [26880/32031 (84%)]\tLoss: 265.471863\n",
      "Train Epoch: 24 [28160/32031 (88%)]\tLoss: 272.371674\n",
      "Train Epoch: 24 [29440/32031 (92%)]\tLoss: 273.714661\n",
      "Train Epoch: 24 [30720/32031 (96%)]\tLoss: 284.325226\n",
      "Train Epoch: 24 [7750/32031 (100%)]\tLoss: 247.724294\n",
      "====> Epoch: 24 Average loss: 269.1417\n",
      "====> Test set loss: 280.7639\n",
      "Train Epoch: 25 [0/32031 (0%)]\tLoss: 276.443115\n",
      "Train Epoch: 25 [1280/32031 (4%)]\tLoss: 264.593658\n",
      "Train Epoch: 25 [2560/32031 (8%)]\tLoss: 264.617981\n",
      "Train Epoch: 25 [3840/32031 (12%)]\tLoss: 267.547821\n",
      "Train Epoch: 25 [5120/32031 (16%)]\tLoss: 276.561859\n",
      "Train Epoch: 25 [6400/32031 (20%)]\tLoss: 280.339294\n",
      "Train Epoch: 25 [7680/32031 (24%)]\tLoss: 267.592346\n",
      "Train Epoch: 25 [8960/32031 (28%)]\tLoss: 273.384613\n",
      "Train Epoch: 25 [10240/32031 (32%)]\tLoss: 267.262390\n",
      "Train Epoch: 25 [11520/32031 (36%)]\tLoss: 257.792419\n",
      "Train Epoch: 25 [12800/32031 (40%)]\tLoss: 267.885193\n",
      "Train Epoch: 25 [14080/32031 (44%)]\tLoss: 261.064148\n",
      "Train Epoch: 25 [15360/32031 (48%)]\tLoss: 274.200317\n",
      "Train Epoch: 25 [16640/32031 (52%)]\tLoss: 268.569580\n",
      "Train Epoch: 25 [17920/32031 (56%)]\tLoss: 265.638855\n",
      "Train Epoch: 25 [19200/32031 (60%)]\tLoss: 274.005554\n",
      "Train Epoch: 25 [20480/32031 (64%)]\tLoss: 273.138672\n",
      "Train Epoch: 25 [21760/32031 (68%)]\tLoss: 281.699921\n",
      "Train Epoch: 25 [23040/32031 (72%)]\tLoss: 262.882172\n",
      "Train Epoch: 25 [24320/32031 (76%)]\tLoss: 271.383972\n",
      "Train Epoch: 25 [25600/32031 (80%)]\tLoss: 283.201477\n",
      "Train Epoch: 25 [26880/32031 (84%)]\tLoss: 256.479156\n",
      "Train Epoch: 25 [28160/32031 (88%)]\tLoss: 279.489227\n",
      "Train Epoch: 25 [29440/32031 (92%)]\tLoss: 295.970093\n",
      "Train Epoch: 25 [30720/32031 (96%)]\tLoss: 285.312927\n",
      "Train Epoch: 25 [7750/32031 (100%)]\tLoss: 308.311775\n",
      "====> Epoch: 25 Average loss: 268.4054\n",
      "====> Test set loss: 268.6512\n",
      "Train Epoch: 26 [0/32031 (0%)]\tLoss: 258.736694\n",
      "Train Epoch: 26 [1280/32031 (4%)]\tLoss: 274.427399\n",
      "Train Epoch: 26 [2560/32031 (8%)]\tLoss: 266.363770\n",
      "Train Epoch: 26 [3840/32031 (12%)]\tLoss: 270.354889\n",
      "Train Epoch: 26 [5120/32031 (16%)]\tLoss: 254.955811\n",
      "Train Epoch: 26 [6400/32031 (20%)]\tLoss: 270.275208\n",
      "Train Epoch: 26 [7680/32031 (24%)]\tLoss: 263.850952\n",
      "Train Epoch: 26 [8960/32031 (28%)]\tLoss: 257.193726\n",
      "Train Epoch: 26 [10240/32031 (32%)]\tLoss: 261.285583\n",
      "Train Epoch: 26 [11520/32031 (36%)]\tLoss: 279.446869\n",
      "Train Epoch: 26 [12800/32031 (40%)]\tLoss: 257.294739\n",
      "Train Epoch: 26 [14080/32031 (44%)]\tLoss: 262.665985\n",
      "Train Epoch: 26 [15360/32031 (48%)]\tLoss: 290.690765\n",
      "Train Epoch: 26 [16640/32031 (52%)]\tLoss: 258.958130\n",
      "Train Epoch: 26 [17920/32031 (56%)]\tLoss: 264.937897\n",
      "Train Epoch: 26 [19200/32031 (60%)]\tLoss: 250.389618\n",
      "Train Epoch: 26 [20480/32031 (64%)]\tLoss: 271.336243\n",
      "Train Epoch: 26 [21760/32031 (68%)]\tLoss: 255.678818\n",
      "Train Epoch: 26 [23040/32031 (72%)]\tLoss: 268.573395\n",
      "Train Epoch: 26 [24320/32031 (76%)]\tLoss: 254.805298\n",
      "Train Epoch: 26 [25600/32031 (80%)]\tLoss: 268.739227\n",
      "Train Epoch: 26 [26880/32031 (84%)]\tLoss: 267.924316\n",
      "Train Epoch: 26 [28160/32031 (88%)]\tLoss: 250.577896\n",
      "Train Epoch: 26 [29440/32031 (92%)]\tLoss: 258.065033\n",
      "Train Epoch: 26 [30720/32031 (96%)]\tLoss: 259.673187\n",
      "Train Epoch: 26 [7750/32031 (100%)]\tLoss: 252.970561\n",
      "====> Epoch: 26 Average loss: 266.3833\n",
      "====> Test set loss: 264.2683\n",
      "Train Epoch: 27 [0/32031 (0%)]\tLoss: 269.446808\n",
      "Train Epoch: 27 [1280/32031 (4%)]\tLoss: 261.792511\n",
      "Train Epoch: 27 [2560/32031 (8%)]\tLoss: 265.779297\n",
      "Train Epoch: 27 [3840/32031 (12%)]\tLoss: 289.459045\n",
      "Train Epoch: 27 [5120/32031 (16%)]\tLoss: 266.985046\n",
      "Train Epoch: 27 [6400/32031 (20%)]\tLoss: 263.849548\n",
      "Train Epoch: 27 [7680/32031 (24%)]\tLoss: 264.108368\n",
      "Train Epoch: 27 [8960/32031 (28%)]\tLoss: 255.200684\n",
      "Train Epoch: 27 [10240/32031 (32%)]\tLoss: 236.762970\n",
      "Train Epoch: 27 [11520/32031 (36%)]\tLoss: 271.252533\n",
      "Train Epoch: 27 [12800/32031 (40%)]\tLoss: 273.675842\n",
      "Train Epoch: 27 [14080/32031 (44%)]\tLoss: 289.708710\n",
      "Train Epoch: 27 [15360/32031 (48%)]\tLoss: 309.344788\n",
      "Train Epoch: 27 [16640/32031 (52%)]\tLoss: 283.012177\n",
      "Train Epoch: 27 [17920/32031 (56%)]\tLoss: 264.561615\n",
      "Train Epoch: 27 [19200/32031 (60%)]\tLoss: 256.541992\n",
      "Train Epoch: 27 [20480/32031 (64%)]\tLoss: 270.014160\n",
      "Train Epoch: 27 [21760/32031 (68%)]\tLoss: 272.040222\n",
      "Train Epoch: 27 [23040/32031 (72%)]\tLoss: 255.410156\n",
      "Train Epoch: 27 [24320/32031 (76%)]\tLoss: 270.529480\n",
      "Train Epoch: 27 [25600/32031 (80%)]\tLoss: 264.347626\n",
      "Train Epoch: 27 [26880/32031 (84%)]\tLoss: 246.624878\n",
      "Train Epoch: 27 [28160/32031 (88%)]\tLoss: 266.352142\n",
      "Train Epoch: 27 [29440/32031 (92%)]\tLoss: 248.143799\n",
      "Train Epoch: 27 [30720/32031 (96%)]\tLoss: 266.643982\n",
      "Train Epoch: 27 [7750/32031 (100%)]\tLoss: 270.270350\n",
      "====> Epoch: 27 Average loss: 271.1645\n",
      "====> Test set loss: 263.8919\n",
      "Train Epoch: 28 [0/32031 (0%)]\tLoss: 264.017151\n",
      "Train Epoch: 28 [1280/32031 (4%)]\tLoss: 271.489716\n",
      "Train Epoch: 28 [2560/32031 (8%)]\tLoss: 277.107422\n",
      "Train Epoch: 28 [3840/32031 (12%)]\tLoss: 243.687958\n",
      "Train Epoch: 28 [5120/32031 (16%)]\tLoss: 256.428497\n",
      "Train Epoch: 28 [6400/32031 (20%)]\tLoss: 281.068695\n",
      "Train Epoch: 28 [7680/32031 (24%)]\tLoss: 279.311768\n",
      "Train Epoch: 28 [8960/32031 (28%)]\tLoss: 284.665283\n",
      "Train Epoch: 28 [10240/32031 (32%)]\tLoss: 265.737274\n",
      "Train Epoch: 28 [11520/32031 (36%)]\tLoss: 257.554688\n",
      "Train Epoch: 28 [12800/32031 (40%)]\tLoss: 254.854248\n",
      "Train Epoch: 28 [14080/32031 (44%)]\tLoss: 257.110382\n",
      "Train Epoch: 28 [15360/32031 (48%)]\tLoss: 266.140106\n",
      "Train Epoch: 28 [16640/32031 (52%)]\tLoss: 261.614807\n",
      "Train Epoch: 28 [17920/32031 (56%)]\tLoss: 266.286194\n",
      "Train Epoch: 28 [19200/32031 (60%)]\tLoss: 254.482819\n",
      "Train Epoch: 28 [20480/32031 (64%)]\tLoss: 262.202942\n",
      "Train Epoch: 28 [21760/32031 (68%)]\tLoss: 270.055908\n",
      "Train Epoch: 28 [23040/32031 (72%)]\tLoss: 310.420929\n",
      "Train Epoch: 28 [24320/32031 (76%)]\tLoss: 279.611084\n",
      "Train Epoch: 28 [25600/32031 (80%)]\tLoss: 256.955566\n",
      "Train Epoch: 28 [26880/32031 (84%)]\tLoss: 298.626373\n",
      "Train Epoch: 28 [28160/32031 (88%)]\tLoss: 249.925430\n",
      "Train Epoch: 28 [29440/32031 (92%)]\tLoss: 264.056610\n",
      "Train Epoch: 28 [30720/32031 (96%)]\tLoss: 253.429321\n",
      "Train Epoch: 28 [7750/32031 (100%)]\tLoss: 272.327967\n",
      "====> Epoch: 28 Average loss: 267.1011\n",
      "====> Test set loss: 264.4180\n",
      "Train Epoch: 29 [0/32031 (0%)]\tLoss: 254.993881\n",
      "Train Epoch: 29 [1280/32031 (4%)]\tLoss: 259.638000\n",
      "Train Epoch: 29 [2560/32031 (8%)]\tLoss: 274.185455\n",
      "Train Epoch: 29 [3840/32031 (12%)]\tLoss: 269.584564\n",
      "Train Epoch: 29 [5120/32031 (16%)]\tLoss: 263.273315\n",
      "Train Epoch: 29 [6400/32031 (20%)]\tLoss: 260.605591\n",
      "Train Epoch: 29 [7680/32031 (24%)]\tLoss: 268.531189\n",
      "Train Epoch: 29 [8960/32031 (28%)]\tLoss: 259.076477\n",
      "Train Epoch: 29 [10240/32031 (32%)]\tLoss: 255.905609\n",
      "Train Epoch: 29 [11520/32031 (36%)]\tLoss: 269.496613\n",
      "Train Epoch: 29 [12800/32031 (40%)]\tLoss: 263.441498\n",
      "Train Epoch: 29 [14080/32031 (44%)]\tLoss: 267.535187\n",
      "Train Epoch: 29 [15360/32031 (48%)]\tLoss: 270.969910\n",
      "Train Epoch: 29 [16640/32031 (52%)]\tLoss: 261.772797\n",
      "Train Epoch: 29 [17920/32031 (56%)]\tLoss: 253.992447\n",
      "Train Epoch: 29 [19200/32031 (60%)]\tLoss: 268.296265\n",
      "Train Epoch: 29 [20480/32031 (64%)]\tLoss: 267.664154\n",
      "Train Epoch: 29 [21760/32031 (68%)]\tLoss: 250.101242\n",
      "Train Epoch: 29 [23040/32031 (72%)]\tLoss: 255.419220\n",
      "Train Epoch: 29 [24320/32031 (76%)]\tLoss: 249.146133\n",
      "Train Epoch: 29 [25600/32031 (80%)]\tLoss: 271.268921\n",
      "Train Epoch: 29 [26880/32031 (84%)]\tLoss: 263.171387\n",
      "Train Epoch: 29 [28160/32031 (88%)]\tLoss: 289.872803\n",
      "Train Epoch: 29 [29440/32031 (92%)]\tLoss: 257.966095\n",
      "Train Epoch: 29 [30720/32031 (96%)]\tLoss: 258.847961\n",
      "Train Epoch: 29 [7750/32031 (100%)]\tLoss: 277.659117\n",
      "====> Epoch: 29 Average loss: 262.5237\n",
      "====> Test set loss: 261.7360\n",
      "Train Epoch: 30 [0/32031 (0%)]\tLoss: 261.085480\n",
      "Train Epoch: 30 [1280/32031 (4%)]\tLoss: 246.707352\n",
      "Train Epoch: 30 [2560/32031 (8%)]\tLoss: 248.134583\n",
      "Train Epoch: 30 [3840/32031 (12%)]\tLoss: 277.466248\n",
      "Train Epoch: 30 [5120/32031 (16%)]\tLoss: 268.747864\n",
      "Train Epoch: 30 [6400/32031 (20%)]\tLoss: 257.303223\n",
      "Train Epoch: 30 [7680/32031 (24%)]\tLoss: 263.990509\n",
      "Train Epoch: 30 [8960/32031 (28%)]\tLoss: 249.162247\n",
      "Train Epoch: 30 [10240/32031 (32%)]\tLoss: 263.867188\n",
      "Train Epoch: 30 [11520/32031 (36%)]\tLoss: 269.598511\n",
      "Train Epoch: 30 [12800/32031 (40%)]\tLoss: 259.829285\n",
      "Train Epoch: 30 [14080/32031 (44%)]\tLoss: 270.013458\n",
      "Train Epoch: 30 [15360/32031 (48%)]\tLoss: 261.154938\n",
      "Train Epoch: 30 [16640/32031 (52%)]\tLoss: 268.304871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [17920/32031 (56%)]\tLoss: 270.753723\n",
      "Train Epoch: 30 [19200/32031 (60%)]\tLoss: 266.599640\n",
      "Train Epoch: 30 [20480/32031 (64%)]\tLoss: 268.473602\n",
      "Train Epoch: 30 [21760/32031 (68%)]\tLoss: 272.456940\n",
      "Train Epoch: 30 [23040/32031 (72%)]\tLoss: 261.485474\n",
      "Train Epoch: 30 [24320/32031 (76%)]\tLoss: 271.477539\n",
      "Train Epoch: 30 [25600/32031 (80%)]\tLoss: 274.431305\n",
      "Train Epoch: 30 [26880/32031 (84%)]\tLoss: 259.150391\n",
      "Train Epoch: 30 [28160/32031 (88%)]\tLoss: 262.908875\n",
      "Train Epoch: 30 [29440/32031 (92%)]\tLoss: 268.602844\n",
      "Train Epoch: 30 [30720/32031 (96%)]\tLoss: 258.218903\n",
      "Train Epoch: 30 [7750/32031 (100%)]\tLoss: 266.835622\n",
      "====> Epoch: 30 Average loss: 261.8509\n",
      "====> Test set loss: 263.3722\n",
      "Train Epoch: 31 [0/32031 (0%)]\tLoss: 250.080002\n",
      "Train Epoch: 31 [1280/32031 (4%)]\tLoss: 261.733948\n",
      "Train Epoch: 31 [2560/32031 (8%)]\tLoss: 257.606720\n",
      "Train Epoch: 31 [3840/32031 (12%)]\tLoss: 251.950882\n",
      "Train Epoch: 31 [5120/32031 (16%)]\tLoss: 250.287354\n",
      "Train Epoch: 31 [6400/32031 (20%)]\tLoss: 253.876755\n",
      "Train Epoch: 31 [7680/32031 (24%)]\tLoss: 253.824753\n",
      "Train Epoch: 31 [8960/32031 (28%)]\tLoss: 246.473297\n",
      "Train Epoch: 31 [10240/32031 (32%)]\tLoss: 256.326508\n",
      "Train Epoch: 31 [11520/32031 (36%)]\tLoss: 238.511765\n",
      "Train Epoch: 31 [12800/32031 (40%)]\tLoss: 255.116135\n",
      "Train Epoch: 31 [14080/32031 (44%)]\tLoss: 264.574585\n",
      "Train Epoch: 31 [15360/32031 (48%)]\tLoss: 281.698303\n",
      "Train Epoch: 31 [16640/32031 (52%)]\tLoss: 257.158356\n",
      "Train Epoch: 31 [17920/32031 (56%)]\tLoss: 264.886444\n",
      "Train Epoch: 31 [19200/32031 (60%)]\tLoss: 255.996033\n",
      "Train Epoch: 31 [20480/32031 (64%)]\tLoss: 247.674774\n",
      "Train Epoch: 31 [21760/32031 (68%)]\tLoss: 272.521698\n",
      "Train Epoch: 31 [23040/32031 (72%)]\tLoss: 259.489441\n",
      "Train Epoch: 31 [24320/32031 (76%)]\tLoss: 274.878845\n",
      "Train Epoch: 31 [25600/32031 (80%)]\tLoss: 257.078064\n",
      "Train Epoch: 31 [26880/32031 (84%)]\tLoss: 243.949524\n",
      "Train Epoch: 31 [28160/32031 (88%)]\tLoss: 261.147247\n",
      "Train Epoch: 31 [29440/32031 (92%)]\tLoss: 262.958496\n",
      "Train Epoch: 31 [30720/32031 (96%)]\tLoss: 252.251038\n",
      "Train Epoch: 31 [7750/32031 (100%)]\tLoss: 246.841151\n",
      "====> Epoch: 31 Average loss: 259.7849\n",
      "====> Test set loss: 258.5203\n",
      "Train Epoch: 32 [0/32031 (0%)]\tLoss: 265.480591\n",
      "Train Epoch: 32 [1280/32031 (4%)]\tLoss: 259.244690\n",
      "Train Epoch: 32 [2560/32031 (8%)]\tLoss: 262.679871\n",
      "Train Epoch: 32 [3840/32031 (12%)]\tLoss: 255.721146\n",
      "Train Epoch: 32 [5120/32031 (16%)]\tLoss: 248.453522\n",
      "Train Epoch: 32 [6400/32031 (20%)]\tLoss: 254.033875\n",
      "Train Epoch: 32 [7680/32031 (24%)]\tLoss: 259.988220\n",
      "Train Epoch: 32 [8960/32031 (28%)]\tLoss: 250.939148\n",
      "Train Epoch: 32 [10240/32031 (32%)]\tLoss: 239.967773\n",
      "Train Epoch: 32 [11520/32031 (36%)]\tLoss: 276.615143\n",
      "Train Epoch: 32 [12800/32031 (40%)]\tLoss: 270.527069\n",
      "Train Epoch: 32 [14080/32031 (44%)]\tLoss: 235.288757\n",
      "Train Epoch: 32 [15360/32031 (48%)]\tLoss: 272.415588\n",
      "Train Epoch: 32 [16640/32031 (52%)]\tLoss: 234.429138\n",
      "Train Epoch: 32 [17920/32031 (56%)]\tLoss: 269.920746\n",
      "Train Epoch: 32 [19200/32031 (60%)]\tLoss: 276.293457\n",
      "Train Epoch: 32 [20480/32031 (64%)]\tLoss: 285.219055\n",
      "Train Epoch: 32 [21760/32031 (68%)]\tLoss: 269.350525\n",
      "Train Epoch: 32 [23040/32031 (72%)]\tLoss: 271.583344\n",
      "Train Epoch: 32 [24320/32031 (76%)]\tLoss: 258.247650\n",
      "Train Epoch: 32 [25600/32031 (80%)]\tLoss: 258.657349\n",
      "Train Epoch: 32 [26880/32031 (84%)]\tLoss: 257.621826\n",
      "Train Epoch: 32 [28160/32031 (88%)]\tLoss: 250.235992\n",
      "Train Epoch: 32 [29440/32031 (92%)]\tLoss: 251.941177\n",
      "Train Epoch: 32 [30720/32031 (96%)]\tLoss: 248.097885\n",
      "Train Epoch: 32 [7750/32031 (100%)]\tLoss: 277.220010\n",
      "====> Epoch: 32 Average loss: 260.8051\n",
      "====> Test set loss: 263.8849\n",
      "Train Epoch: 33 [0/32031 (0%)]\tLoss: 288.603607\n",
      "Train Epoch: 33 [1280/32031 (4%)]\tLoss: 258.741180\n",
      "Train Epoch: 33 [2560/32031 (8%)]\tLoss: 266.189697\n",
      "Train Epoch: 33 [3840/32031 (12%)]\tLoss: 266.693237\n",
      "Train Epoch: 33 [5120/32031 (16%)]\tLoss: 261.615631\n",
      "Train Epoch: 33 [6400/32031 (20%)]\tLoss: 271.420258\n",
      "Train Epoch: 33 [7680/32031 (24%)]\tLoss: 252.584778\n",
      "Train Epoch: 33 [8960/32031 (28%)]\tLoss: 252.237656\n",
      "Train Epoch: 33 [10240/32031 (32%)]\tLoss: 260.851135\n",
      "Train Epoch: 33 [11520/32031 (36%)]\tLoss: 247.750626\n",
      "Train Epoch: 33 [12800/32031 (40%)]\tLoss: 251.530304\n",
      "Train Epoch: 33 [14080/32031 (44%)]\tLoss: 249.453766\n",
      "Train Epoch: 33 [15360/32031 (48%)]\tLoss: 257.318512\n",
      "Train Epoch: 33 [16640/32031 (52%)]\tLoss: 255.201462\n",
      "Train Epoch: 33 [17920/32031 (56%)]\tLoss: 247.381470\n",
      "Train Epoch: 33 [19200/32031 (60%)]\tLoss: 237.277893\n",
      "Train Epoch: 33 [20480/32031 (64%)]\tLoss: 244.405655\n",
      "Train Epoch: 33 [21760/32031 (68%)]\tLoss: 250.560059\n",
      "Train Epoch: 33 [23040/32031 (72%)]\tLoss: 278.879547\n",
      "Train Epoch: 33 [24320/32031 (76%)]\tLoss: 268.754883\n",
      "Train Epoch: 33 [25600/32031 (80%)]\tLoss: 264.606476\n",
      "Train Epoch: 33 [26880/32031 (84%)]\tLoss: 240.532532\n",
      "Train Epoch: 33 [28160/32031 (88%)]\tLoss: 251.118896\n",
      "Train Epoch: 33 [29440/32031 (92%)]\tLoss: 238.206985\n",
      "Train Epoch: 33 [30720/32031 (96%)]\tLoss: 241.649323\n",
      "Train Epoch: 33 [7750/32031 (100%)]\tLoss: 249.732123\n",
      "====> Epoch: 33 Average loss: 258.3441\n",
      "====> Test set loss: 255.5665\n",
      "Train Epoch: 34 [0/32031 (0%)]\tLoss: 260.121399\n",
      "Train Epoch: 34 [1280/32031 (4%)]\tLoss: 257.598572\n",
      "Train Epoch: 34 [2560/32031 (8%)]\tLoss: 247.102310\n",
      "Train Epoch: 34 [3840/32031 (12%)]\tLoss: 290.853851\n",
      "Train Epoch: 34 [5120/32031 (16%)]\tLoss: 254.263260\n",
      "Train Epoch: 34 [6400/32031 (20%)]\tLoss: 268.956085\n",
      "Train Epoch: 34 [7680/32031 (24%)]\tLoss: 273.133026\n",
      "Train Epoch: 34 [8960/32031 (28%)]\tLoss: 270.432709\n",
      "Train Epoch: 34 [10240/32031 (32%)]\tLoss: 273.909424\n",
      "Train Epoch: 34 [11520/32031 (36%)]\tLoss: 254.541962\n",
      "Train Epoch: 34 [12800/32031 (40%)]\tLoss: 239.090591\n",
      "Train Epoch: 34 [14080/32031 (44%)]\tLoss: 250.804535\n",
      "Train Epoch: 34 [15360/32031 (48%)]\tLoss: 267.899994\n",
      "Train Epoch: 34 [16640/32031 (52%)]\tLoss: 253.199692\n",
      "Train Epoch: 34 [17920/32031 (56%)]\tLoss: 248.266296\n",
      "Train Epoch: 34 [19200/32031 (60%)]\tLoss: 246.916855\n",
      "Train Epoch: 34 [20480/32031 (64%)]\tLoss: 260.474976\n",
      "Train Epoch: 34 [21760/32031 (68%)]\tLoss: 256.084778\n",
      "Train Epoch: 34 [23040/32031 (72%)]\tLoss: 263.419495\n",
      "Train Epoch: 34 [24320/32031 (76%)]\tLoss: 260.486420\n",
      "Train Epoch: 34 [25600/32031 (80%)]\tLoss: 274.904083\n",
      "Train Epoch: 35 [11520/32031 (36%)]\tLoss: 231.742249\n",
      "Train Epoch: 35 [12800/32031 (40%)]\tLoss: 259.668915\n",
      "Train Epoch: 35 [14080/32031 (44%)]\tLoss: 262.729462\n",
      "Train Epoch: 35 [15360/32031 (48%)]\tLoss: 245.198425\n",
      "Train Epoch: 35 [16640/32031 (52%)]\tLoss: 248.832275\n",
      "Train Epoch: 35 [17920/32031 (56%)]\tLoss: 254.005600\n",
      "Train Epoch: 35 [19200/32031 (60%)]\tLoss: 254.236603\n",
      "Train Epoch: 35 [20480/32031 (64%)]\tLoss: 236.330444\n",
      "Train Epoch: 35 [21760/32031 (68%)]\tLoss: 269.035248\n",
      "Train Epoch: 35 [23040/32031 (72%)]\tLoss: 254.156250\n",
      "Train Epoch: 35 [24320/32031 (76%)]\tLoss: 249.100098\n",
      "Train Epoch: 35 [25600/32031 (80%)]\tLoss: 246.452072\n",
      "Train Epoch: 35 [26880/32031 (84%)]\tLoss: 249.437302\n",
      "Train Epoch: 35 [28160/32031 (88%)]\tLoss: 244.501678\n",
      "Train Epoch: 35 [29440/32031 (92%)]\tLoss: 269.050964\n",
      "Train Epoch: 35 [30720/32031 (96%)]\tLoss: 239.829346\n",
      "Train Epoch: 35 [7750/32031 (100%)]\tLoss: 244.821872\n",
      "====> Epoch: 35 Average loss: 254.8988\n",
      "====> Test set loss: 258.6737\n",
      "Train Epoch: 36 [0/32031 (0%)]\tLoss: 258.863312\n",
      "Train Epoch: 36 [1280/32031 (4%)]\tLoss: 273.514709\n",
      "Train Epoch: 36 [2560/32031 (8%)]\tLoss: 253.965408\n",
      "Train Epoch: 36 [3840/32031 (12%)]\tLoss: 247.871124\n",
      "Train Epoch: 36 [5120/32031 (16%)]\tLoss: 262.457306\n",
      "Train Epoch: 36 [6400/32031 (20%)]\tLoss: 245.766525\n",
      "Train Epoch: 36 [7680/32031 (24%)]\tLoss: 255.433365\n",
      "Train Epoch: 36 [8960/32031 (28%)]\tLoss: 248.042892\n",
      "Train Epoch: 36 [10240/32031 (32%)]\tLoss: 256.543213\n",
      "Train Epoch: 36 [11520/32031 (36%)]\tLoss: 262.761475\n",
      "Train Epoch: 36 [12800/32031 (40%)]\tLoss: 254.760773\n",
      "Train Epoch: 36 [14080/32031 (44%)]\tLoss: 272.896698\n",
      "Train Epoch: 36 [15360/32031 (48%)]\tLoss: 263.961914\n",
      "Train Epoch: 36 [16640/32031 (52%)]\tLoss: 259.001801\n",
      "Train Epoch: 36 [17920/32031 (56%)]\tLoss: 263.410339\n",
      "Train Epoch: 36 [19200/32031 (60%)]\tLoss: 248.737640\n",
      "Train Epoch: 36 [20480/32031 (64%)]\tLoss: 260.319122\n",
      "Train Epoch: 36 [21760/32031 (68%)]\tLoss: 250.438599\n",
      "Train Epoch: 36 [23040/32031 (72%)]\tLoss: 255.617172\n",
      "Train Epoch: 36 [24320/32031 (76%)]\tLoss: 243.103195\n",
      "Train Epoch: 36 [25600/32031 (80%)]\tLoss: 253.075455\n",
      "Train Epoch: 36 [26880/32031 (84%)]\tLoss: 261.422729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [28160/32031 (88%)]\tLoss: 268.767456\n",
      "Train Epoch: 36 [29440/32031 (92%)]\tLoss: 247.113144\n",
      "Train Epoch: 36 [30720/32031 (96%)]\tLoss: 270.589844\n",
      "Train Epoch: 36 [7750/32031 (100%)]\tLoss: 297.471900\n",
      "====> Epoch: 36 Average loss: 254.9925\n",
      "====> Test set loss: 251.0610\n",
      "Train Epoch: 37 [0/32031 (0%)]\tLoss: 250.721802\n",
      "Train Epoch: 37 [1280/32031 (4%)]\tLoss: 260.882782\n",
      "Train Epoch: 37 [2560/32031 (8%)]\tLoss: 247.745605\n",
      "Train Epoch: 37 [3840/32031 (12%)]\tLoss: 251.471497\n",
      "Train Epoch: 37 [5120/32031 (16%)]\tLoss: 244.465210\n",
      "Train Epoch: 37 [6400/32031 (20%)]\tLoss: 259.203949\n",
      "Train Epoch: 37 [7680/32031 (24%)]\tLoss: 263.373871\n",
      "Train Epoch: 37 [8960/32031 (28%)]\tLoss: 238.683258\n",
      "Train Epoch: 37 [10240/32031 (32%)]\tLoss: 255.218140\n",
      "Train Epoch: 37 [11520/32031 (36%)]\tLoss: 261.085938\n",
      "Train Epoch: 37 [12800/32031 (40%)]\tLoss: 255.436661\n",
      "Train Epoch: 37 [14080/32031 (44%)]\tLoss: 266.926392\n",
      "Train Epoch: 37 [15360/32031 (48%)]\tLoss: 252.765778\n",
      "Train Epoch: 37 [16640/32031 (52%)]\tLoss: 236.806564\n",
      "Train Epoch: 37 [17920/32031 (56%)]\tLoss: 249.037506\n",
      "Train Epoch: 37 [19200/32031 (60%)]\tLoss: 250.672409\n",
      "Train Epoch: 37 [20480/32031 (64%)]\tLoss: 233.127777\n",
      "Train Epoch: 37 [21760/32031 (68%)]\tLoss: 252.836197\n",
      "Train Epoch: 37 [23040/32031 (72%)]\tLoss: 257.257141\n",
      "Train Epoch: 37 [24320/32031 (76%)]\tLoss: 255.430145\n",
      "Train Epoch: 37 [25600/32031 (80%)]\tLoss: 259.566132\n",
      "Train Epoch: 37 [26880/32031 (84%)]\tLoss: 246.474442\n",
      "Train Epoch: 37 [28160/32031 (88%)]\tLoss: 252.447342\n",
      "Train Epoch: 37 [29440/32031 (92%)]\tLoss: 267.662598\n",
      "Train Epoch: 37 [30720/32031 (96%)]\tLoss: 266.239136\n",
      "Train Epoch: 37 [7750/32031 (100%)]\tLoss: 293.938508\n",
      "====> Epoch: 37 Average loss: 253.7522\n",
      "====> Test set loss: 255.2121\n",
      "Train Epoch: 38 [0/32031 (0%)]\tLoss: 249.605148\n",
      "Train Epoch: 38 [1280/32031 (4%)]\tLoss: 253.307495\n",
      "Train Epoch: 38 [2560/32031 (8%)]\tLoss: 240.171295\n",
      "Train Epoch: 38 [3840/32031 (12%)]\tLoss: 262.294952\n",
      "Train Epoch: 38 [5120/32031 (16%)]\tLoss: 271.176910\n",
      "Train Epoch: 38 [6400/32031 (20%)]\tLoss: 264.707336\n",
      "Train Epoch: 38 [7680/32031 (24%)]\tLoss: 244.778214\n",
      "Train Epoch: 38 [8960/32031 (28%)]\tLoss: 261.637787\n",
      "Train Epoch: 38 [10240/32031 (32%)]\tLoss: 264.513184\n",
      "Train Epoch: 38 [11520/32031 (36%)]\tLoss: 282.959869\n",
      "Train Epoch: 38 [12800/32031 (40%)]\tLoss: 251.222931\n",
      "Train Epoch: 38 [14080/32031 (44%)]\tLoss: 265.305145\n",
      "Train Epoch: 38 [15360/32031 (48%)]\tLoss: 255.045593\n",
      "Train Epoch: 38 [16640/32031 (52%)]\tLoss: 263.759338\n",
      "Train Epoch: 38 [17920/32031 (56%)]\tLoss: 256.783142\n",
      "Train Epoch: 38 [19200/32031 (60%)]\tLoss: 260.012146\n",
      "Train Epoch: 38 [20480/32031 (64%)]\tLoss: 246.259003\n",
      "Train Epoch: 38 [21760/32031 (68%)]\tLoss: 246.842041\n",
      "Train Epoch: 38 [23040/32031 (72%)]\tLoss: 259.135376\n",
      "Train Epoch: 38 [24320/32031 (76%)]\tLoss: 257.326294\n",
      "Train Epoch: 38 [25600/32031 (80%)]\tLoss: 310.846008\n",
      "Train Epoch: 38 [26880/32031 (84%)]\tLoss: 251.208878\n",
      "Train Epoch: 38 [28160/32031 (88%)]\tLoss: 258.080444\n",
      "Train Epoch: 38 [29440/32031 (92%)]\tLoss: 263.793579\n",
      "Train Epoch: 38 [30720/32031 (96%)]\tLoss: 253.179977\n",
      "Train Epoch: 38 [7750/32031 (100%)]\tLoss: 272.547001\n",
      "====> Epoch: 38 Average loss: 254.7533\n",
      "====> Test set loss: 250.2197\n",
      "====> Test set loss: 202.6127\n",
      "Train Epoch: 232 [0/32031 (0%)]\tLoss: 202.991913\n",
      "Train Epoch: 232 [1280/32031 (4%)]\tLoss: 204.714203\n",
      "Train Epoch: 232 [2560/32031 (8%)]\tLoss: 198.800751\n",
      "Train Epoch: 232 [3840/32031 (12%)]\tLoss: 205.078827\n",
      "Train Epoch: 232 [5120/32031 (16%)]\tLoss: 209.111511\n",
      "Train Epoch: 232 [6400/32031 (20%)]\tLoss: 197.534042\n",
      "Train Epoch: 232 [7680/32031 (24%)]\tLoss: 199.395111\n",
      "Train Epoch: 232 [8960/32031 (28%)]\tLoss: 204.370544\n",
      "Train Epoch: 232 [10240/32031 (32%)]\tLoss: 196.400772\n",
      "Train Epoch: 232 [11520/32031 (36%)]\tLoss: 194.322357\n",
      "Train Epoch: 232 [12800/32031 (40%)]\tLoss: 196.974014\n",
      "Train Epoch: 232 [14080/32031 (44%)]\tLoss: 186.739456\n",
      "Train Epoch: 232 [15360/32031 (48%)]\tLoss: 206.581848\n",
      "Train Epoch: 232 [16640/32031 (52%)]\tLoss: 199.298874\n",
      "Train Epoch: 232 [17920/32031 (56%)]\tLoss: 212.862823\n",
      "Train Epoch: 232 [19200/32031 (60%)]\tLoss: 213.003159\n",
      "Train Epoch: 232 [20480/32031 (64%)]\tLoss: 210.100174\n",
      "Train Epoch: 232 [21760/32031 (68%)]\tLoss: 203.932678\n",
      "Train Epoch: 232 [23040/32031 (72%)]\tLoss: 198.563263\n",
      "Train Epoch: 232 [24320/32031 (76%)]\tLoss: 215.208710\n",
      "Train Epoch: 232 [25600/32031 (80%)]\tLoss: 204.238480\n",
      "Train Epoch: 232 [26880/32031 (84%)]\tLoss: 198.479324\n",
      "Train Epoch: 232 [28160/32031 (88%)]\tLoss: 212.806122\n",
      "Train Epoch: 232 [29440/32031 (92%)]\tLoss: 210.278183\n",
      "Train Epoch: 232 [30720/32031 (96%)]\tLoss: 209.294907\n",
      "Train Epoch: 232 [7750/32031 (100%)]\tLoss: 177.987289\n",
      "====> Epoch: 232 Average loss: 205.4375\n",
      "====> Test set loss: 198.0059\n",
      "Train Epoch: 233 [0/32031 (0%)]\tLoss: 208.009796\n",
      "Train Epoch: 233 [1280/32031 (4%)]\tLoss: 200.340881\n",
      "Train Epoch: 233 [2560/32031 (8%)]\tLoss: 198.924057\n",
      "Train Epoch: 233 [3840/32031 (12%)]\tLoss: 203.230316\n",
      "Train Epoch: 233 [5120/32031 (16%)]\tLoss: 212.256668\n",
      "Train Epoch: 233 [6400/32031 (20%)]\tLoss: 204.927612\n",
      "Train Epoch: 233 [7680/32031 (24%)]\tLoss: 213.787262\n",
      "Train Epoch: 233 [8960/32031 (28%)]\tLoss: 201.877808\n",
      "Train Epoch: 233 [10240/32031 (32%)]\tLoss: 199.508163\n",
      "Train Epoch: 233 [11520/32031 (36%)]\tLoss: 198.052032\n",
      "Train Epoch: 233 [12800/32031 (40%)]\tLoss: 207.092010\n",
      "Train Epoch: 233 [14080/32031 (44%)]\tLoss: 200.784607\n",
      "Train Epoch: 233 [15360/32031 (48%)]\tLoss: 195.899063\n",
      "Train Epoch: 233 [16640/32031 (52%)]\tLoss: 207.073700\n",
      "Train Epoch: 233 [17920/32031 (56%)]\tLoss: 210.314240\n",
      "Train Epoch: 233 [19200/32031 (60%)]\tLoss: 204.946503\n",
      "Train Epoch: 233 [20480/32031 (64%)]\tLoss: 193.548798\n",
      "Train Epoch: 233 [21760/32031 (68%)]\tLoss: 203.598602\n",
      "Train Epoch: 233 [23040/32031 (72%)]\tLoss: 211.745834\n",
      "Train Epoch: 233 [24320/32031 (76%)]\tLoss: 206.988739\n",
      "Train Epoch: 233 [25600/32031 (80%)]\tLoss: 222.778290\n",
      "Train Epoch: 233 [26880/32031 (84%)]\tLoss: 198.577148\n",
      "Train Epoch: 233 [28160/32031 (88%)]\tLoss: 199.291382\n",
      "Train Epoch: 233 [29440/32031 (92%)]\tLoss: 217.769531\n",
      "Train Epoch: 233 [30720/32031 (96%)]\tLoss: 198.338074\n",
      "Train Epoch: 233 [7750/32031 (100%)]\tLoss: 192.760065\n",
      "====> Epoch: 233 Average loss: 204.6793\n",
      "====> Test set loss: 197.7527\n",
      "Train Epoch: 234 [0/32031 (0%)]\tLoss: 205.156616\n",
      "Train Epoch: 234 [1280/32031 (4%)]\tLoss: 203.216049\n",
      "Train Epoch: 234 [2560/32031 (8%)]\tLoss: 209.242126\n",
      "Train Epoch: 234 [3840/32031 (12%)]\tLoss: 206.991669\n",
      "Train Epoch: 234 [5120/32031 (16%)]\tLoss: 209.894714\n",
      "Train Epoch: 234 [6400/32031 (20%)]\tLoss: 207.232880\n",
      "Train Epoch: 234 [7680/32031 (24%)]\tLoss: 196.340698\n",
      "Train Epoch: 234 [8960/32031 (28%)]\tLoss: 213.297409\n",
      "Train Epoch: 234 [10240/32031 (32%)]\tLoss: 204.855331\n",
      "Train Epoch: 234 [11520/32031 (36%)]\tLoss: 205.912506\n",
      "Train Epoch: 234 [12800/32031 (40%)]\tLoss: 196.754913\n",
      "Train Epoch: 234 [14080/32031 (44%)]\tLoss: 203.176163\n",
      "Train Epoch: 234 [15360/32031 (48%)]\tLoss: 211.939423\n",
      "Train Epoch: 234 [16640/32031 (52%)]\tLoss: 212.164963\n",
      "Train Epoch: 234 [17920/32031 (56%)]\tLoss: 213.289215\n",
      "Train Epoch: 234 [19200/32031 (60%)]\tLoss: 214.893799\n",
      "Train Epoch: 234 [20480/32031 (64%)]\tLoss: 191.707458\n",
      "Train Epoch: 234 [21760/32031 (68%)]\tLoss: 206.619720\n",
      "Train Epoch: 234 [23040/32031 (72%)]\tLoss: 213.880585\n",
      "Train Epoch: 234 [24320/32031 (76%)]\tLoss: 194.089584\n",
      "Train Epoch: 234 [25600/32031 (80%)]\tLoss: 208.908447\n",
      "Train Epoch: 234 [26880/32031 (84%)]\tLoss: 197.365921\n",
      "Train Epoch: 234 [28160/32031 (88%)]\tLoss: 205.063416\n",
      "Train Epoch: 234 [29440/32031 (92%)]\tLoss: 208.320511\n",
      "Train Epoch: 234 [30720/32031 (96%)]\tLoss: 194.346146\n",
      "Train Epoch: 234 [7750/32031 (100%)]\tLoss: 199.722073\n",
      "====> Epoch: 234 Average loss: 204.9758\n",
      "====> Test set loss: 198.9602\n",
      "Train Epoch: 235 [0/32031 (0%)]\tLoss: 197.701874\n",
      "Train Epoch: 235 [1280/32031 (4%)]\tLoss: 199.765717\n",
      "Train Epoch: 235 [2560/32031 (8%)]\tLoss: 193.237915\n",
      "Train Epoch: 235 [3840/32031 (12%)]\tLoss: 200.172852\n",
      "Train Epoch: 235 [5120/32031 (16%)]\tLoss: 199.877167\n",
      "Train Epoch: 235 [6400/32031 (20%)]\tLoss: 210.852249\n",
      "Train Epoch: 235 [7680/32031 (24%)]\tLoss: 206.225082\n",
      "Train Epoch: 235 [8960/32031 (28%)]\tLoss: 202.778168\n",
      "Train Epoch: 235 [10240/32031 (32%)]\tLoss: 211.009811\n",
      "Train Epoch: 235 [11520/32031 (36%)]\tLoss: 197.563751\n",
      "Train Epoch: 235 [12800/32031 (40%)]\tLoss: 193.927261\n",
      "Train Epoch: 235 [14080/32031 (44%)]\tLoss: 210.584442\n",
      "Train Epoch: 235 [15360/32031 (48%)]\tLoss: 210.674377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 235 [16640/32031 (52%)]\tLoss: 211.309723\n",
      "Train Epoch: 235 [17920/32031 (56%)]\tLoss: 213.988266\n",
      "Train Epoch: 235 [19200/32031 (60%)]\tLoss: 205.253250\n",
      "Train Epoch: 235 [20480/32031 (64%)]\tLoss: 198.651062\n",
      "Train Epoch: 235 [21760/32031 (68%)]\tLoss: 197.720474\n",
      "Train Epoch: 235 [23040/32031 (72%)]\tLoss: 203.972870\n",
      "Train Epoch: 235 [24320/32031 (76%)]\tLoss: 199.394989\n",
      "Train Epoch: 235 [25600/32031 (80%)]\tLoss: 199.283463\n",
      "Train Epoch: 235 [26880/32031 (84%)]\tLoss: 213.834122\n",
      "Train Epoch: 235 [28160/32031 (88%)]\tLoss: 201.615631\n",
      "Train Epoch: 235 [29440/32031 (92%)]\tLoss: 209.015900\n",
      "Train Epoch: 235 [30720/32031 (96%)]\tLoss: 214.457977\n",
      "Train Epoch: 235 [7750/32031 (100%)]\tLoss: 198.970451\n",
      "====> Epoch: 235 Average loss: 204.9401\n",
      "====> Test set loss: 200.8411\n",
      "Train Epoch: 236 [0/32031 (0%)]\tLoss: 210.962921\n",
      "Train Epoch: 236 [1280/32031 (4%)]\tLoss: 192.447159\n",
      "Train Epoch: 236 [2560/32031 (8%)]\tLoss: 205.110718\n",
      "Train Epoch: 236 [3840/32031 (12%)]\tLoss: 217.730530\n",
      "Train Epoch: 236 [5120/32031 (16%)]\tLoss: 201.776016\n",
      "Train Epoch: 236 [6400/32031 (20%)]\tLoss: 206.874146\n",
      "Train Epoch: 236 [7680/32031 (24%)]\tLoss: 196.667435\n",
      "Train Epoch: 236 [8960/32031 (28%)]\tLoss: 205.642334\n",
      "Train Epoch: 236 [10240/32031 (32%)]\tLoss: 206.775162\n",
      "Train Epoch: 236 [11520/32031 (36%)]\tLoss: 203.022903\n",
      "Train Epoch: 236 [12800/32031 (40%)]\tLoss: 202.112137\n",
      "Train Epoch: 236 [14080/32031 (44%)]\tLoss: 204.309906\n",
      "Train Epoch: 236 [15360/32031 (48%)]\tLoss: 207.314072\n",
      "Train Epoch: 236 [16640/32031 (52%)]\tLoss: 217.198456\n",
      "Train Epoch: 236 [17920/32031 (56%)]\tLoss: 209.406799\n",
      "Train Epoch: 236 [19200/32031 (60%)]\tLoss: 209.385880\n",
      "Train Epoch: 236 [20480/32031 (64%)]\tLoss: 212.231873\n",
      "Train Epoch: 236 [21760/32031 (68%)]\tLoss: 198.692902\n",
      "Train Epoch: 236 [23040/32031 (72%)]\tLoss: 209.338409\n",
      "Train Epoch: 236 [24320/32031 (76%)]\tLoss: 208.740723\n",
      "Train Epoch: 236 [25600/32031 (80%)]\tLoss: 198.388275\n",
      "Train Epoch: 236 [26880/32031 (84%)]\tLoss: 208.448502\n",
      "Train Epoch: 236 [28160/32031 (88%)]\tLoss: 202.269577\n",
      "Train Epoch: 236 [29440/32031 (92%)]\tLoss: 197.751007\n",
      "Train Epoch: 236 [30720/32031 (96%)]\tLoss: 218.777359\n",
      "Train Epoch: 236 [7750/32031 (100%)]\tLoss: 191.398248\n",
      "====> Epoch: 236 Average loss: 204.9614\n",
      "====> Test set loss: 197.5637\n",
      "Train Epoch: 237 [0/32031 (0%)]\tLoss: 212.789429\n",
      "Train Epoch: 237 [1280/32031 (4%)]\tLoss: 205.866287\n",
      "Train Epoch: 237 [2560/32031 (8%)]\tLoss: 222.065308\n",
      "Train Epoch: 237 [3840/32031 (12%)]\tLoss: 211.191284\n",
      "Train Epoch: 237 [5120/32031 (16%)]\tLoss: 216.743759\n",
      "Train Epoch: 237 [6400/32031 (20%)]\tLoss: 205.292572\n",
      "Train Epoch: 237 [7680/32031 (24%)]\tLoss: 207.646286\n",
      "Train Epoch: 237 [8960/32031 (28%)]\tLoss: 206.228790\n",
      "Train Epoch: 237 [10240/32031 (32%)]\tLoss: 187.447189\n",
      "Train Epoch: 237 [11520/32031 (36%)]\tLoss: 196.145264\n",
      "Train Epoch: 237 [12800/32031 (40%)]\tLoss: 205.415253\n",
      "Train Epoch: 237 [14080/32031 (44%)]\tLoss: 195.068451\n",
      "Train Epoch: 237 [15360/32031 (48%)]\tLoss: 210.233276\n",
      "Train Epoch: 237 [16640/32031 (52%)]\tLoss: 214.247589\n",
      "Train Epoch: 237 [17920/32031 (56%)]\tLoss: 202.323914\n",
      "Train Epoch: 237 [19200/32031 (60%)]\tLoss: 200.944138\n",
      "Train Epoch: 237 [20480/32031 (64%)]\tLoss: 204.675415\n",
      "Train Epoch: 237 [21760/32031 (68%)]\tLoss: 214.106689\n",
      "Train Epoch: 237 [23040/32031 (72%)]\tLoss: 203.506119\n",
      "Train Epoch: 237 [24320/32031 (76%)]\tLoss: 191.589020\n",
      "Train Epoch: 237 [25600/32031 (80%)]\tLoss: 202.837311\n",
      "Train Epoch: 237 [26880/32031 (84%)]\tLoss: 190.581207\n",
      "Train Epoch: 237 [28160/32031 (88%)]\tLoss: 193.278259\n",
      "Train Epoch: 237 [29440/32031 (92%)]\tLoss: 191.084061\n",
      "Train Epoch: 237 [30720/32031 (96%)]\tLoss: 203.844025\n",
      "Train Epoch: 237 [7750/32031 (100%)]\tLoss: 193.398910\n",
      "====> Epoch: 237 Average loss: 204.8006\n",
      "====> Test set loss: 199.3333\n",
      "Train Epoch: 238 [0/32031 (0%)]\tLoss: 208.595154\n",
      "Train Epoch: 238 [1280/32031 (4%)]\tLoss: 190.520447\n",
      "Train Epoch: 238 [2560/32031 (8%)]\tLoss: 199.810104\n",
      "Train Epoch: 238 [3840/32031 (12%)]\tLoss: 198.855270\n",
      "Train Epoch: 238 [5120/32031 (16%)]\tLoss: 214.895401\n",
      "Train Epoch: 238 [6400/32031 (20%)]\tLoss: 190.495605\n",
      "Train Epoch: 238 [7680/32031 (24%)]\tLoss: 205.976318\n",
      "Train Epoch: 238 [8960/32031 (28%)]\tLoss: 214.595901\n",
      "Train Epoch: 238 [10240/32031 (32%)]\tLoss: 209.701279\n",
      "Train Epoch: 238 [11520/32031 (36%)]\tLoss: 198.437286\n",
      "Train Epoch: 238 [12800/32031 (40%)]\tLoss: 204.399612\n",
      "Train Epoch: 238 [14080/32031 (44%)]\tLoss: 195.513519\n",
      "Train Epoch: 238 [15360/32031 (48%)]\tLoss: 201.023361\n",
      "Train Epoch: 238 [16640/32031 (52%)]\tLoss: 211.471832\n",
      "Train Epoch: 238 [17920/32031 (56%)]\tLoss: 208.810333\n",
      "Train Epoch: 238 [19200/32031 (60%)]\tLoss: 210.933533\n",
      "Train Epoch: 238 [20480/32031 (64%)]\tLoss: 199.294373\n",
      "Train Epoch: 238 [21760/32031 (68%)]\tLoss: 211.923279\n",
      "Train Epoch: 238 [23040/32031 (72%)]\tLoss: 207.621475\n",
      "Train Epoch: 238 [24320/32031 (76%)]\tLoss: 208.038849\n",
      "Train Epoch: 238 [25600/32031 (80%)]\tLoss: 193.846283\n",
      "Train Epoch: 238 [26880/32031 (84%)]\tLoss: 200.779541\n",
      "Train Epoch: 238 [28160/32031 (88%)]\tLoss: 212.492249\n",
      "Train Epoch: 238 [29440/32031 (92%)]\tLoss: 212.805649\n",
      "Train Epoch: 238 [30720/32031 (96%)]\tLoss: 202.109573\n",
      "Train Epoch: 238 [7750/32031 (100%)]\tLoss: 224.925907\n",
      "====> Epoch: 238 Average loss: 204.5066\n",
      "====> Test set loss: 200.4367\n",
      "Train Epoch: 239 [0/32031 (0%)]\tLoss: 204.009460\n",
      "Train Epoch: 239 [1280/32031 (4%)]\tLoss: 217.657852\n",
      "Train Epoch: 239 [2560/32031 (8%)]\tLoss: 197.426361\n",
      "Train Epoch: 239 [3840/32031 (12%)]\tLoss: 197.126923\n",
      "Train Epoch: 239 [5120/32031 (16%)]\tLoss: 195.768387\n",
      "Train Epoch: 239 [6400/32031 (20%)]\tLoss: 200.558426\n",
      "Train Epoch: 239 [7680/32031 (24%)]\tLoss: 207.451202\n",
      "Train Epoch: 239 [8960/32031 (28%)]\tLoss: 197.314438\n",
      "Train Epoch: 239 [10240/32031 (32%)]\tLoss: 199.708160\n",
      "Train Epoch: 239 [11520/32031 (36%)]\tLoss: 200.309479\n",
      "Train Epoch: 239 [12800/32031 (40%)]\tLoss: 200.527557\n",
      "Train Epoch: 239 [14080/32031 (44%)]\tLoss: 206.051498\n",
      "Train Epoch: 239 [15360/32031 (48%)]\tLoss: 204.356354\n",
      "Train Epoch: 239 [16640/32031 (52%)]\tLoss: 199.126480\n",
      "Train Epoch: 239 [17920/32031 (56%)]\tLoss: 204.078262\n",
      "Train Epoch: 239 [19200/32031 (60%)]\tLoss: 200.459579\n",
      "Train Epoch: 239 [20480/32031 (64%)]\tLoss: 208.749039\n",
      "Train Epoch: 239 [21760/32031 (68%)]\tLoss: 209.066193\n",
      "Train Epoch: 239 [23040/32031 (72%)]\tLoss: 209.778519\n",
      "Train Epoch: 239 [24320/32031 (76%)]\tLoss: 194.198456\n",
      "Train Epoch: 239 [25600/32031 (80%)]\tLoss: 178.250458\n",
      "Train Epoch: 239 [26880/32031 (84%)]\tLoss: 194.651230\n",
      "Train Epoch: 239 [28160/32031 (88%)]\tLoss: 201.336182\n",
      "Train Epoch: 239 [29440/32031 (92%)]\tLoss: 205.254150\n",
      "Train Epoch: 239 [30720/32031 (96%)]\tLoss: 205.219803\n",
      "Train Epoch: 239 [7750/32031 (100%)]\tLoss: 208.943753\n",
      "====> Epoch: 239 Average loss: 204.5875\n",
      "====> Test set loss: 197.5621\n",
      "Train Epoch: 240 [0/32031 (0%)]\tLoss: 207.258850\n",
      "Train Epoch: 240 [1280/32031 (4%)]\tLoss: 208.434891\n",
      "Train Epoch: 240 [2560/32031 (8%)]\tLoss: 203.860428\n",
      "Train Epoch: 240 [3840/32031 (12%)]\tLoss: 200.272095\n",
      "Train Epoch: 240 [5120/32031 (16%)]\tLoss: 219.799210\n",
      "Train Epoch: 240 [6400/32031 (20%)]\tLoss: 211.139130\n",
      "Train Epoch: 240 [7680/32031 (24%)]\tLoss: 213.628082\n",
      "Train Epoch: 240 [8960/32031 (28%)]\tLoss: 194.423080\n",
      "Train Epoch: 240 [10240/32031 (32%)]\tLoss: 198.280884\n",
      "Train Epoch: 240 [11520/32031 (36%)]\tLoss: 194.734818\n",
      "Train Epoch: 240 [12800/32031 (40%)]\tLoss: 209.913147\n",
      "Train Epoch: 240 [14080/32031 (44%)]\tLoss: 208.746429\n",
      "Train Epoch: 240 [15360/32031 (48%)]\tLoss: 219.164139\n",
      "Train Epoch: 240 [16640/32031 (52%)]\tLoss: 213.768311\n",
      "Train Epoch: 240 [17920/32031 (56%)]\tLoss: 209.574814\n",
      "Train Epoch: 240 [19200/32031 (60%)]\tLoss: 203.254959\n",
      "Train Epoch: 240 [20480/32031 (64%)]\tLoss: 209.042816\n",
      "Train Epoch: 240 [21760/32031 (68%)]\tLoss: 207.849258\n",
      "Train Epoch: 240 [23040/32031 (72%)]\tLoss: 195.263855\n",
      "Train Epoch: 240 [24320/32031 (76%)]\tLoss: 197.195709\n",
      "Train Epoch: 240 [25600/32031 (80%)]\tLoss: 216.307373\n",
      "Train Epoch: 240 [26880/32031 (84%)]\tLoss: 205.588318\n",
      "Train Epoch: 240 [28160/32031 (88%)]\tLoss: 209.374573\n",
      "Train Epoch: 240 [29440/32031 (92%)]\tLoss: 199.642532\n",
      "Train Epoch: 240 [30720/32031 (96%)]\tLoss: 207.781494\n",
      "Train Epoch: 240 [7750/32031 (100%)]\tLoss: 193.550797\n",
      "====> Epoch: 240 Average loss: 204.6156\n",
      "====> Test set loss: 198.1703\n",
      "Train Epoch: 241 [0/32031 (0%)]\tLoss: 213.270462\n",
      "Train Epoch: 241 [1280/32031 (4%)]\tLoss: 197.014084\n",
      "Train Epoch: 241 [2560/32031 (8%)]\tLoss: 202.087036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 241 [3840/32031 (12%)]\tLoss: 216.118713\n",
      "Train Epoch: 241 [5120/32031 (16%)]\tLoss: 201.277008\n",
      "Train Epoch: 241 [6400/32031 (20%)]\tLoss: 207.054398\n",
      "Train Epoch: 241 [7680/32031 (24%)]\tLoss: 210.564423\n",
      "Train Epoch: 241 [8960/32031 (28%)]\tLoss: 212.096542\n",
      "Train Epoch: 241 [10240/32031 (32%)]\tLoss: 207.840607\n",
      "Train Epoch: 241 [11520/32031 (36%)]\tLoss: 205.687439\n",
      "Train Epoch: 241 [12800/32031 (40%)]\tLoss: 202.703094\n",
      "Train Epoch: 241 [14080/32031 (44%)]\tLoss: 206.533173\n",
      "Train Epoch: 241 [15360/32031 (48%)]\tLoss: 199.943359\n",
      "Train Epoch: 241 [16640/32031 (52%)]\tLoss: 199.004562\n",
      "Train Epoch: 241 [17920/32031 (56%)]\tLoss: 204.445465\n",
      "Train Epoch: 241 [19200/32031 (60%)]\tLoss: 219.965332\n",
      "Train Epoch: 241 [20480/32031 (64%)]\tLoss: 203.109161\n",
      "Train Epoch: 241 [21760/32031 (68%)]\tLoss: 205.167343\n",
      "Train Epoch: 241 [23040/32031 (72%)]\tLoss: 199.391251\n",
      "Train Epoch: 241 [24320/32031 (76%)]\tLoss: 206.932907\n",
      "Train Epoch: 241 [25600/32031 (80%)]\tLoss: 216.749298\n",
      "Train Epoch: 241 [26880/32031 (84%)]\tLoss: 217.766113\n",
      "Train Epoch: 241 [28160/32031 (88%)]\tLoss: 206.883179\n",
      "Train Epoch: 241 [29440/32031 (92%)]\tLoss: 217.192245\n",
      "Train Epoch: 241 [30720/32031 (96%)]\tLoss: 213.796997\n",
      "Train Epoch: 241 [7750/32031 (100%)]\tLoss: 198.393523\n",
      "====> Epoch: 241 Average loss: 204.5773\n",
      "====> Test set loss: 199.3499\n",
      "Train Epoch: 242 [0/32031 (0%)]\tLoss: 195.973267\n",
      "Train Epoch: 242 [1280/32031 (4%)]\tLoss: 204.066757\n",
      "Train Epoch: 242 [2560/32031 (8%)]\tLoss: 211.548065\n",
      "Train Epoch: 242 [3840/32031 (12%)]\tLoss: 208.305008\n",
      "Train Epoch: 242 [5120/32031 (16%)]\tLoss: 207.934265\n",
      "Train Epoch: 242 [6400/32031 (20%)]\tLoss: 197.463364\n",
      "Train Epoch: 242 [7680/32031 (24%)]\tLoss: 197.270599\n",
      "Train Epoch: 242 [8960/32031 (28%)]\tLoss: 200.019073\n",
      "Train Epoch: 242 [10240/32031 (32%)]\tLoss: 200.227875\n",
      "Train Epoch: 242 [11520/32031 (36%)]\tLoss: 189.821030\n",
      "Train Epoch: 242 [12800/32031 (40%)]\tLoss: 193.699768\n",
      "Train Epoch: 242 [14080/32031 (44%)]\tLoss: 205.140518\n",
      "Train Epoch: 242 [15360/32031 (48%)]\tLoss: 198.971252\n",
      "Train Epoch: 242 [16640/32031 (52%)]\tLoss: 204.258957\n",
      "Train Epoch: 242 [17920/32031 (56%)]\tLoss: 202.827591\n",
      "Train Epoch: 242 [19200/32031 (60%)]\tLoss: 185.531326\n",
      "Train Epoch: 242 [20480/32031 (64%)]\tLoss: 208.664139\n",
      "Train Epoch: 242 [21760/32031 (68%)]\tLoss: 204.932678\n",
      "Train Epoch: 242 [23040/32031 (72%)]\tLoss: 214.897141\n",
      "Train Epoch: 242 [24320/32031 (76%)]\tLoss: 198.336136\n",
      "Train Epoch: 242 [25600/32031 (80%)]\tLoss: 199.790573\n",
      "Train Epoch: 242 [26880/32031 (84%)]\tLoss: 207.959824\n",
      "Train Epoch: 242 [28160/32031 (88%)]\tLoss: 197.064148\n",
      "Train Epoch: 242 [29440/32031 (92%)]\tLoss: 209.993942\n",
      "Train Epoch: 242 [30720/32031 (96%)]\tLoss: 202.874542\n",
      "Train Epoch: 242 [7750/32031 (100%)]\tLoss: 201.362163\n",
      "====> Epoch: 242 Average loss: 204.7251\n",
      "====> Test set loss: 200.3085\n",
      "Train Epoch: 243 [0/32031 (0%)]\tLoss: 213.999115\n",
      "Train Epoch: 243 [1280/32031 (4%)]\tLoss: 210.554947\n",
      "Train Epoch: 243 [2560/32031 (8%)]\tLoss: 205.409256\n",
      "Train Epoch: 243 [3840/32031 (12%)]\tLoss: 209.325974\n",
      "Train Epoch: 243 [5120/32031 (16%)]\tLoss: 194.224243\n",
      "Train Epoch: 243 [6400/32031 (20%)]\tLoss: 205.734848\n",
      "Train Epoch: 243 [7680/32031 (24%)]\tLoss: 203.040680\n",
      "Train Epoch: 243 [8960/32031 (28%)]\tLoss: 197.541046\n",
      "Train Epoch: 243 [10240/32031 (32%)]\tLoss: 203.872147\n",
      "Train Epoch: 243 [11520/32031 (36%)]\tLoss: 208.083649\n",
      "Train Epoch: 243 [12800/32031 (40%)]\tLoss: 191.062363\n",
      "Train Epoch: 243 [14080/32031 (44%)]\tLoss: 192.547577\n",
      "Train Epoch: 243 [15360/32031 (48%)]\tLoss: 200.917892\n",
      "Train Epoch: 243 [16640/32031 (52%)]\tLoss: 209.320099\n",
      "Train Epoch: 243 [17920/32031 (56%)]\tLoss: 199.758179\n",
      "Train Epoch: 243 [19200/32031 (60%)]\tLoss: 207.665298\n",
      "Train Epoch: 243 [20480/32031 (64%)]\tLoss: 193.524872\n",
      "Train Epoch: 243 [21760/32031 (68%)]\tLoss: 209.938126\n",
      "Train Epoch: 243 [23040/32031 (72%)]\tLoss: 180.528152\n",
      "Train Epoch: 243 [24320/32031 (76%)]\tLoss: 201.193192\n",
      "Train Epoch: 243 [25600/32031 (80%)]\tLoss: 215.081665\n",
      "Train Epoch: 243 [26880/32031 (84%)]\tLoss: 205.675400\n",
      "Train Epoch: 243 [28160/32031 (88%)]\tLoss: 220.894104\n",
      "Train Epoch: 243 [29440/32031 (92%)]\tLoss: 202.517242\n",
      "Train Epoch: 243 [30720/32031 (96%)]\tLoss: 197.560623\n",
      "Train Epoch: 243 [7750/32031 (100%)]\tLoss: 195.390798\n",
      "====> Epoch: 243 Average loss: 204.5880\n",
      "====> Test set loss: 197.4510\n",
      "Train Epoch: 244 [0/32031 (0%)]\tLoss: 205.447601\n",
      "Train Epoch: 244 [1280/32031 (4%)]\tLoss: 210.866318\n",
      "Train Epoch: 244 [2560/32031 (8%)]\tLoss: 203.641174\n",
      "Train Epoch: 244 [3840/32031 (12%)]\tLoss: 202.167053\n",
      "Train Epoch: 244 [5120/32031 (16%)]\tLoss: 219.346878\n",
      "Train Epoch: 244 [6400/32031 (20%)]\tLoss: 209.576157\n",
      "Train Epoch: 244 [7680/32031 (24%)]\tLoss: 206.753754\n",
      "Train Epoch: 244 [8960/32031 (28%)]\tLoss: 220.379120\n",
      "Train Epoch: 244 [10240/32031 (32%)]\tLoss: 199.906235\n",
      "Train Epoch: 244 [11520/32031 (36%)]\tLoss: 201.983856\n",
      "Train Epoch: 244 [12800/32031 (40%)]\tLoss: 207.183563\n",
      "Train Epoch: 244 [14080/32031 (44%)]\tLoss: 194.301758\n",
      "Train Epoch: 244 [15360/32031 (48%)]\tLoss: 200.997635\n",
      "Train Epoch: 244 [16640/32031 (52%)]\tLoss: 192.600876\n",
      "Train Epoch: 244 [17920/32031 (56%)]\tLoss: 202.850067\n",
      "Train Epoch: 244 [19200/32031 (60%)]\tLoss: 200.582458\n",
      "Train Epoch: 244 [20480/32031 (64%)]\tLoss: 205.212311\n",
      "Train Epoch: 244 [21760/32031 (68%)]\tLoss: 198.720154\n",
      "Train Epoch: 244 [23040/32031 (72%)]\tLoss: 208.427933\n",
      "Train Epoch: 244 [24320/32031 (76%)]\tLoss: 198.156372\n",
      "Train Epoch: 244 [25600/32031 (80%)]\tLoss: 216.725922\n",
      "Train Epoch: 244 [26880/32031 (84%)]\tLoss: 202.689743\n",
      "Train Epoch: 244 [28160/32031 (88%)]\tLoss: 203.132202\n",
      "Train Epoch: 244 [29440/32031 (92%)]\tLoss: 198.087738\n",
      "Train Epoch: 244 [30720/32031 (96%)]\tLoss: 189.467651\n",
      "Train Epoch: 244 [7750/32031 (100%)]\tLoss: 207.552167\n",
      "====> Epoch: 244 Average loss: 204.3175\n",
      "====> Test set loss: 200.1189\n",
      "Train Epoch: 245 [0/32031 (0%)]\tLoss: 211.893265\n",
      "Train Epoch: 245 [1280/32031 (4%)]\tLoss: 206.860901\n",
      "Train Epoch: 245 [2560/32031 (8%)]\tLoss: 195.596191\n",
      "Train Epoch: 245 [3840/32031 (12%)]\tLoss: 203.708359\n",
      "Train Epoch: 245 [5120/32031 (16%)]\tLoss: 193.777161\n",
      "Train Epoch: 245 [6400/32031 (20%)]\tLoss: 202.077682\n",
      "Train Epoch: 245 [7680/32031 (24%)]\tLoss: 207.029358\n",
      "Train Epoch: 245 [8960/32031 (28%)]\tLoss: 206.982559\n",
      "Train Epoch: 245 [10240/32031 (32%)]\tLoss: 211.232101\n",
      "Train Epoch: 245 [11520/32031 (36%)]\tLoss: 193.827072\n",
      "Train Epoch: 245 [12800/32031 (40%)]\tLoss: 205.934464\n",
      "Train Epoch: 245 [14080/32031 (44%)]\tLoss: 206.177124\n",
      "Train Epoch: 245 [15360/32031 (48%)]\tLoss: 209.627777\n",
      "Train Epoch: 245 [16640/32031 (52%)]\tLoss: 200.881927\n",
      "Train Epoch: 245 [17920/32031 (56%)]\tLoss: 207.060135\n",
      "Train Epoch: 245 [19200/32031 (60%)]\tLoss: 203.280884\n",
      "Train Epoch: 245 [20480/32031 (64%)]\tLoss: 205.309235\n",
      "Train Epoch: 245 [21760/32031 (68%)]\tLoss: 214.133652\n",
      "Train Epoch: 245 [23040/32031 (72%)]\tLoss: 200.530991\n",
      "Train Epoch: 245 [24320/32031 (76%)]\tLoss: 209.688721\n",
      "Train Epoch: 245 [25600/32031 (80%)]\tLoss: 208.208862\n",
      "Train Epoch: 245 [26880/32031 (84%)]\tLoss: 203.361481\n",
      "Train Epoch: 245 [28160/32031 (88%)]\tLoss: 199.483994\n",
      "Train Epoch: 245 [29440/32031 (92%)]\tLoss: 197.729477\n",
      "Train Epoch: 245 [30720/32031 (96%)]\tLoss: 205.440033\n",
      "Train Epoch: 245 [7750/32031 (100%)]\tLoss: 198.092836\n",
      "====> Epoch: 245 Average loss: 204.7997\n",
      "====> Test set loss: 199.4697\n",
      "Train Epoch: 246 [0/32031 (0%)]\tLoss: 207.055618\n",
      "Train Epoch: 246 [1280/32031 (4%)]\tLoss: 210.173187\n",
      "Train Epoch: 246 [2560/32031 (8%)]\tLoss: 208.893158\n",
      "Train Epoch: 246 [3840/32031 (12%)]\tLoss: 201.719177\n",
      "Train Epoch: 246 [5120/32031 (16%)]\tLoss: 195.330612\n",
      "Train Epoch: 246 [6400/32031 (20%)]\tLoss: 206.677551\n",
      "Train Epoch: 246 [7680/32031 (24%)]\tLoss: 205.184357\n",
      "Train Epoch: 246 [8960/32031 (28%)]\tLoss: 201.779724\n",
      "Train Epoch: 246 [10240/32031 (32%)]\tLoss: 206.291931\n",
      "Train Epoch: 246 [11520/32031 (36%)]\tLoss: 205.085678\n",
      "Train Epoch: 246 [12800/32031 (40%)]\tLoss: 207.025314\n",
      "Train Epoch: 246 [14080/32031 (44%)]\tLoss: 205.064148\n",
      "Train Epoch: 246 [15360/32031 (48%)]\tLoss: 207.795425\n",
      "Train Epoch: 246 [16640/32031 (52%)]\tLoss: 196.891983\n",
      "Train Epoch: 246 [17920/32031 (56%)]\tLoss: 205.809525\n",
      "Train Epoch: 246 [19200/32031 (60%)]\tLoss: 187.647949\n",
      "Train Epoch: 246 [20480/32031 (64%)]\tLoss: 204.545990\n",
      "Train Epoch: 246 [21760/32031 (68%)]\tLoss: 204.140030\n",
      "Train Epoch: 246 [23040/32031 (72%)]\tLoss: 205.744003\n",
      "Train Epoch: 246 [24320/32031 (76%)]\tLoss: 201.564636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 246 [25600/32031 (80%)]\tLoss: 211.657562\n",
      "Train Epoch: 246 [26880/32031 (84%)]\tLoss: 197.317032\n",
      "Train Epoch: 246 [28160/32031 (88%)]\tLoss: 206.740997\n",
      "Train Epoch: 246 [29440/32031 (92%)]\tLoss: 207.496094\n",
      "Train Epoch: 246 [30720/32031 (96%)]\tLoss: 209.905914\n",
      "Train Epoch: 246 [7750/32031 (100%)]\tLoss: 234.422253\n",
      "====> Epoch: 246 Average loss: 204.5109\n",
      "====> Test set loss: 202.6573\n",
      "Train Epoch: 247 [0/32031 (0%)]\tLoss: 205.478928\n",
      "Train Epoch: 247 [1280/32031 (4%)]\tLoss: 204.208008\n",
      "Train Epoch: 247 [2560/32031 (8%)]\tLoss: 211.524414\n",
      "Train Epoch: 247 [3840/32031 (12%)]\tLoss: 201.366943\n",
      "Train Epoch: 247 [5120/32031 (16%)]\tLoss: 195.336182\n",
      "Train Epoch: 247 [6400/32031 (20%)]\tLoss: 206.647385\n",
      "Train Epoch: 247 [7680/32031 (24%)]\tLoss: 205.316818\n",
      "Train Epoch: 247 [8960/32031 (28%)]\tLoss: 202.707626\n",
      "Train Epoch: 247 [10240/32031 (32%)]\tLoss: 186.083969\n",
      "Train Epoch: 247 [11520/32031 (36%)]\tLoss: 188.695847\n",
      "Train Epoch: 247 [12800/32031 (40%)]\tLoss: 194.075928\n",
      "Train Epoch: 247 [14080/32031 (44%)]\tLoss: 201.048920\n",
      "Train Epoch: 247 [15360/32031 (48%)]\tLoss: 217.036804\n",
      "Train Epoch: 247 [16640/32031 (52%)]\tLoss: 215.430283\n",
      "Train Epoch: 247 [17920/32031 (56%)]\tLoss: 221.608902\n",
      "Train Epoch: 247 [19200/32031 (60%)]\tLoss: 205.387115\n",
      "Train Epoch: 247 [20480/32031 (64%)]\tLoss: 217.257660\n",
      "Train Epoch: 247 [21760/32031 (68%)]\tLoss: 205.524185\n",
      "Train Epoch: 247 [23040/32031 (72%)]\tLoss: 212.573425\n",
      "Train Epoch: 247 [24320/32031 (76%)]\tLoss: 214.083817\n",
      "Train Epoch: 247 [25600/32031 (80%)]\tLoss: 201.153503\n",
      "Train Epoch: 247 [26880/32031 (84%)]\tLoss: 211.069168\n",
      "Train Epoch: 247 [28160/32031 (88%)]\tLoss: 209.813995\n",
      "Train Epoch: 247 [29440/32031 (92%)]\tLoss: 198.347092\n",
      "Train Epoch: 247 [30720/32031 (96%)]\tLoss: 205.157104\n",
      "Train Epoch: 247 [7750/32031 (100%)]\tLoss: 186.373787\n",
      "====> Epoch: 247 Average loss: 204.1944\n",
      "====> Test set loss: 198.1093\n",
      "Train Epoch: 248 [0/32031 (0%)]\tLoss: 204.659180\n",
      "Train Epoch: 248 [1280/32031 (4%)]\tLoss: 211.694153\n",
      "Train Epoch: 248 [2560/32031 (8%)]\tLoss: 197.941269\n",
      "Train Epoch: 248 [3840/32031 (12%)]\tLoss: 195.402222\n",
      "Train Epoch: 248 [5120/32031 (16%)]\tLoss: 198.901138\n",
      "Train Epoch: 248 [6400/32031 (20%)]\tLoss: 215.761002\n",
      "Train Epoch: 248 [7680/32031 (24%)]\tLoss: 202.020523\n",
      "Train Epoch: 248 [8960/32031 (28%)]\tLoss: 202.425461\n",
      "Train Epoch: 248 [10240/32031 (32%)]\tLoss: 204.421646\n",
      "Train Epoch: 248 [11520/32031 (36%)]\tLoss: 203.081146\n",
      "Train Epoch: 248 [12800/32031 (40%)]\tLoss: 196.052399\n",
      "Train Epoch: 248 [14080/32031 (44%)]\tLoss: 208.925812\n",
      "Train Epoch: 248 [15360/32031 (48%)]\tLoss: 206.093140\n",
      "Train Epoch: 248 [16640/32031 (52%)]\tLoss: 212.753021\n",
      "Train Epoch: 248 [17920/32031 (56%)]\tLoss: 215.646683\n",
      "Train Epoch: 248 [19200/32031 (60%)]\tLoss: 201.227615\n",
      "Train Epoch: 248 [20480/32031 (64%)]\tLoss: 200.535629\n",
      "Train Epoch: 248 [21760/32031 (68%)]\tLoss: 201.901413\n",
      "Train Epoch: 248 [23040/32031 (72%)]\tLoss: 198.246552\n",
      "Train Epoch: 248 [24320/32031 (76%)]\tLoss: 200.043457\n",
      "Train Epoch: 248 [25600/32031 (80%)]\tLoss: 211.239532\n",
      "Train Epoch: 248 [26880/32031 (84%)]\tLoss: 223.761871\n",
      "Train Epoch: 248 [28160/32031 (88%)]\tLoss: 194.184921\n",
      "Train Epoch: 248 [29440/32031 (92%)]\tLoss: 213.805847\n",
      "Train Epoch: 248 [30720/32031 (96%)]\tLoss: 191.402786\n",
      "Train Epoch: 248 [7750/32031 (100%)]\tLoss: 192.499039\n",
      "====> Epoch: 248 Average loss: 204.1681\n",
      "====> Test set loss: 198.5303\n",
      "Train Epoch: 249 [0/32031 (0%)]\tLoss: 202.437103\n",
      "Train Epoch: 249 [1280/32031 (4%)]\tLoss: 201.189224\n",
      "Train Epoch: 249 [2560/32031 (8%)]\tLoss: 197.447510\n",
      "Train Epoch: 249 [3840/32031 (12%)]\tLoss: 211.121750\n",
      "Train Epoch: 249 [5120/32031 (16%)]\tLoss: 202.560532\n",
      "Train Epoch: 249 [6400/32031 (20%)]\tLoss: 206.005554\n",
      "Train Epoch: 249 [7680/32031 (24%)]\tLoss: 203.756943\n",
      "Train Epoch: 249 [8960/32031 (28%)]\tLoss: 199.977493\n",
      "Train Epoch: 249 [10240/32031 (32%)]\tLoss: 211.562912\n",
      "Train Epoch: 249 [11520/32031 (36%)]\tLoss: 206.796402\n",
      "Train Epoch: 249 [12800/32031 (40%)]\tLoss: 218.574142\n",
      "Train Epoch: 249 [14080/32031 (44%)]\tLoss: 213.038956\n",
      "Train Epoch: 249 [15360/32031 (48%)]\tLoss: 211.662888\n",
      "Train Epoch: 249 [16640/32031 (52%)]\tLoss: 207.538467\n",
      "Train Epoch: 249 [17920/32031 (56%)]\tLoss: 203.710709\n",
      "Train Epoch: 249 [19200/32031 (60%)]\tLoss: 196.599106\n",
      "Train Epoch: 249 [20480/32031 (64%)]\tLoss: 206.161835\n",
      "Train Epoch: 249 [21760/32031 (68%)]\tLoss: 197.965302\n",
      "Train Epoch: 249 [23040/32031 (72%)]\tLoss: 198.728210\n",
      "Train Epoch: 249 [24320/32031 (76%)]\tLoss: 205.124619\n",
      "Train Epoch: 249 [25600/32031 (80%)]\tLoss: 212.090027\n",
      "Train Epoch: 249 [26880/32031 (84%)]\tLoss: 202.404053\n",
      "Train Epoch: 249 [28160/32031 (88%)]\tLoss: 201.511154\n",
      "Train Epoch: 249 [29440/32031 (92%)]\tLoss: 194.331360\n",
      "Train Epoch: 249 [30720/32031 (96%)]\tLoss: 222.358612\n",
      "Train Epoch: 249 [7750/32031 (100%)]\tLoss: 193.079511\n",
      "====> Epoch: 249 Average loss: 204.4490\n",
      "====> Test set loss: 197.7406\n",
      "Train Epoch: 250 [0/32031 (0%)]\tLoss: 203.554459\n",
      "Train Epoch: 250 [1280/32031 (4%)]\tLoss: 202.038528\n",
      "Train Epoch: 250 [2560/32031 (8%)]\tLoss: 201.864365\n",
      "Train Epoch: 250 [3840/32031 (12%)]\tLoss: 187.956207\n",
      "Train Epoch: 250 [5120/32031 (16%)]\tLoss: 202.825409\n",
      "Train Epoch: 250 [6400/32031 (20%)]\tLoss: 185.332291\n",
      "Train Epoch: 250 [7680/32031 (24%)]\tLoss: 205.772461\n",
      "Train Epoch: 250 [8960/32031 (28%)]\tLoss: 187.670273\n",
      "Train Epoch: 250 [10240/32031 (32%)]\tLoss: 204.754669\n",
      "Train Epoch: 250 [11520/32031 (36%)]\tLoss: 193.461517\n",
      "Train Epoch: 250 [12800/32031 (40%)]\tLoss: 208.858093\n",
      "Train Epoch: 250 [14080/32031 (44%)]\tLoss: 207.055267\n",
      "Train Epoch: 250 [15360/32031 (48%)]\tLoss: 206.751099\n",
      "Train Epoch: 250 [16640/32031 (52%)]\tLoss: 205.125137\n",
      "Train Epoch: 250 [17920/32031 (56%)]\tLoss: 205.375702\n",
      "Train Epoch: 250 [19200/32031 (60%)]\tLoss: 204.005753\n",
      "Train Epoch: 250 [20480/32031 (64%)]\tLoss: 198.424118\n",
      "Train Epoch: 250 [21760/32031 (68%)]\tLoss: 194.431274\n",
      "Train Epoch: 250 [23040/32031 (72%)]\tLoss: 212.788406\n",
      "Train Epoch: 250 [24320/32031 (76%)]\tLoss: 204.495285\n",
      "Train Epoch: 250 [25600/32031 (80%)]\tLoss: 198.189316\n",
      "Train Epoch: 250 [26880/32031 (84%)]\tLoss: 203.756088\n",
      "Train Epoch: 250 [28160/32031 (88%)]\tLoss: 196.517593\n",
      "Train Epoch: 250 [29440/32031 (92%)]\tLoss: 201.425980\n",
      "Train Epoch: 250 [30720/32031 (96%)]\tLoss: 224.569077\n",
      "Train Epoch: 250 [7750/32031 (100%)]\tLoss: 210.784778\n",
      "====> Epoch: 250 Average loss: 204.2915\n",
      "====> Test set loss: 198.8831\n",
      "Train Epoch: 251 [0/32031 (0%)]\tLoss: 212.998169\n",
      "Train Epoch: 251 [1280/32031 (4%)]\tLoss: 201.426605\n",
      "Train Epoch: 251 [2560/32031 (8%)]\tLoss: 193.133560\n",
      "Train Epoch: 251 [3840/32031 (12%)]\tLoss: 207.311081\n",
      "Train Epoch: 251 [5120/32031 (16%)]\tLoss: 202.172348\n",
      "Train Epoch: 251 [6400/32031 (20%)]\tLoss: 203.620789\n",
      "Train Epoch: 251 [7680/32031 (24%)]\tLoss: 200.358810\n",
      "Train Epoch: 251 [8960/32031 (28%)]\tLoss: 214.063171\n",
      "Train Epoch: 251 [10240/32031 (32%)]\tLoss: 203.084702\n",
      "Train Epoch: 251 [11520/32031 (36%)]\tLoss: 210.646912\n",
      "Train Epoch: 251 [12800/32031 (40%)]\tLoss: 204.022156\n",
      "Train Epoch: 251 [14080/32031 (44%)]\tLoss: 204.407150\n",
      "Train Epoch: 251 [15360/32031 (48%)]\tLoss: 211.139221\n",
      "Train Epoch: 251 [16640/32031 (52%)]\tLoss: 202.236481\n",
      "Train Epoch: 251 [17920/32031 (56%)]\tLoss: 201.605988\n",
      "Train Epoch: 251 [19200/32031 (60%)]\tLoss: 214.251755\n",
      "Train Epoch: 251 [20480/32031 (64%)]\tLoss: 205.528091\n",
      "Train Epoch: 251 [21760/32031 (68%)]\tLoss: 213.851120\n",
      "Train Epoch: 251 [23040/32031 (72%)]\tLoss: 206.826492\n",
      "Train Epoch: 251 [24320/32031 (76%)]\tLoss: 203.628632\n",
      "Train Epoch: 251 [25600/32031 (80%)]\tLoss: 212.932281\n",
      "Train Epoch: 251 [26880/32031 (84%)]\tLoss: 201.678787\n",
      "Train Epoch: 251 [28160/32031 (88%)]\tLoss: 207.507202\n",
      "Train Epoch: 251 [29440/32031 (92%)]\tLoss: 199.929413\n",
      "Train Epoch: 251 [30720/32031 (96%)]\tLoss: 193.906357\n",
      "Train Epoch: 251 [7750/32031 (100%)]\tLoss: 215.354067\n",
      "====> Epoch: 251 Average loss: 204.1595\n",
      "====> Test set loss: 197.9614\n",
      "Train Epoch: 252 [0/32031 (0%)]\tLoss: 200.754944\n",
      "Train Epoch: 252 [1280/32031 (4%)]\tLoss: 202.861069\n",
      "Train Epoch: 252 [2560/32031 (8%)]\tLoss: 186.557068\n",
      "Train Epoch: 252 [3840/32031 (12%)]\tLoss: 195.282181\n",
      "Train Epoch: 252 [5120/32031 (16%)]\tLoss: 209.218201\n",
      "Train Epoch: 252 [6400/32031 (20%)]\tLoss: 202.573471\n",
      "Train Epoch: 252 [7680/32031 (24%)]\tLoss: 208.996429\n",
      "Train Epoch: 252 [8960/32031 (28%)]\tLoss: 197.759537\n",
      "Train Epoch: 252 [10240/32031 (32%)]\tLoss: 215.246674\n",
      "Train Epoch: 252 [11520/32031 (36%)]\tLoss: 199.737579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 252 [12800/32031 (40%)]\tLoss: 201.038055\n",
      "Train Epoch: 252 [14080/32031 (44%)]\tLoss: 203.082062\n",
      "Train Epoch: 252 [15360/32031 (48%)]\tLoss: 205.876144\n",
      "Train Epoch: 252 [16640/32031 (52%)]\tLoss: 203.821472\n",
      "Train Epoch: 252 [17920/32031 (56%)]\tLoss: 213.881012\n",
      "Train Epoch: 252 [19200/32031 (60%)]\tLoss: 194.301804\n",
      "Train Epoch: 252 [20480/32031 (64%)]\tLoss: 205.062805\n",
      "Train Epoch: 252 [21760/32031 (68%)]\tLoss: 208.456665\n",
      "Train Epoch: 252 [23040/32031 (72%)]\tLoss: 208.091919\n",
      "Train Epoch: 252 [24320/32031 (76%)]\tLoss: 198.759506\n",
      "Train Epoch: 252 [25600/32031 (80%)]\tLoss: 200.385818\n",
      "Train Epoch: 252 [26880/32031 (84%)]\tLoss: 196.826447\n",
      "Train Epoch: 252 [28160/32031 (88%)]\tLoss: 203.939224\n",
      "Train Epoch: 252 [29440/32031 (92%)]\tLoss: 205.087433\n",
      "Train Epoch: 252 [30720/32031 (96%)]\tLoss: 208.693771\n",
      "Train Epoch: 252 [7750/32031 (100%)]\tLoss: 207.651194\n",
      "====> Epoch: 252 Average loss: 204.0850\n",
      "====> Test set loss: 199.1685\n",
      "Train Epoch: 253 [0/32031 (0%)]\tLoss: 225.014771\n",
      "Train Epoch: 253 [1280/32031 (4%)]\tLoss: 208.281097\n",
      "Train Epoch: 253 [2560/32031 (8%)]\tLoss: 201.271149\n",
      "Train Epoch: 253 [3840/32031 (12%)]\tLoss: 208.107697\n",
      "Train Epoch: 253 [5120/32031 (16%)]\tLoss: 197.235565\n",
      "Train Epoch: 253 [6400/32031 (20%)]\tLoss: 198.831772\n",
      "Train Epoch: 253 [7680/32031 (24%)]\tLoss: 206.094162\n",
      "Train Epoch: 253 [8960/32031 (28%)]\tLoss: 201.457977\n",
      "Train Epoch: 253 [10240/32031 (32%)]\tLoss: 208.511368\n",
      "Train Epoch: 253 [11520/32031 (36%)]\tLoss: 199.280884\n",
      "Train Epoch: 253 [12800/32031 (40%)]\tLoss: 203.550995\n",
      "Train Epoch: 253 [14080/32031 (44%)]\tLoss: 204.089539\n",
      "Train Epoch: 253 [15360/32031 (48%)]\tLoss: 196.869904\n",
      "Train Epoch: 253 [16640/32031 (52%)]\tLoss: 203.111725\n",
      "Train Epoch: 253 [17920/32031 (56%)]\tLoss: 200.775177\n",
      "Train Epoch: 253 [19200/32031 (60%)]\tLoss: 210.029709\n",
      "Train Epoch: 253 [20480/32031 (64%)]\tLoss: 197.321548\n",
      "Train Epoch: 253 [21760/32031 (68%)]\tLoss: 196.839325\n",
      "Train Epoch: 253 [23040/32031 (72%)]\tLoss: 221.017548\n",
      "Train Epoch: 253 [24320/32031 (76%)]\tLoss: 210.014160\n",
      "Train Epoch: 253 [25600/32031 (80%)]\tLoss: 191.499954\n",
      "Train Epoch: 253 [26880/32031 (84%)]\tLoss: 197.686737\n",
      "Train Epoch: 253 [28160/32031 (88%)]\tLoss: 209.941376\n",
      "Train Epoch: 253 [29440/32031 (92%)]\tLoss: 206.872742\n",
      "Train Epoch: 253 [30720/32031 (96%)]\tLoss: 208.745605\n",
      "Train Epoch: 253 [7750/32031 (100%)]\tLoss: 181.202558\n",
      "====> Epoch: 253 Average loss: 204.3019\n",
      "====> Test set loss: 199.0998\n",
      "Train Epoch: 254 [0/32031 (0%)]\tLoss: 209.540817\n",
      "Train Epoch: 254 [1280/32031 (4%)]\tLoss: 202.234650\n",
      "Train Epoch: 254 [2560/32031 (8%)]\tLoss: 201.846771\n",
      "Train Epoch: 254 [3840/32031 (12%)]\tLoss: 196.859940\n",
      "Train Epoch: 254 [5120/32031 (16%)]\tLoss: 196.500183\n",
      "Train Epoch: 254 [6400/32031 (20%)]\tLoss: 205.996719\n",
      "Train Epoch: 254 [7680/32031 (24%)]\tLoss: 197.110092\n",
      "Train Epoch: 254 [8960/32031 (28%)]\tLoss: 202.460754\n",
      "Train Epoch: 254 [10240/32031 (32%)]\tLoss: 203.599731\n",
      "Train Epoch: 254 [11520/32031 (36%)]\tLoss: 203.304871\n",
      "Train Epoch: 254 [12800/32031 (40%)]\tLoss: 205.371674\n",
      "Train Epoch: 254 [14080/32031 (44%)]\tLoss: 197.656738\n",
      "Train Epoch: 254 [15360/32031 (48%)]\tLoss: 221.074570\n",
      "Train Epoch: 254 [16640/32031 (52%)]\tLoss: 199.884949\n",
      "Train Epoch: 254 [17920/32031 (56%)]\tLoss: 213.949554\n",
      "Train Epoch: 254 [19200/32031 (60%)]\tLoss: 203.866638\n",
      "Train Epoch: 254 [20480/32031 (64%)]\tLoss: 211.677185\n",
      "Train Epoch: 254 [21760/32031 (68%)]\tLoss: 209.458878\n",
      "Train Epoch: 254 [23040/32031 (72%)]\tLoss: 207.463348\n",
      "Train Epoch: 254 [24320/32031 (76%)]\tLoss: 206.404327\n",
      "Train Epoch: 254 [25600/32031 (80%)]\tLoss: 208.747757\n",
      "Train Epoch: 254 [26880/32031 (84%)]\tLoss: 202.625870\n",
      "Train Epoch: 254 [28160/32031 (88%)]\tLoss: 205.528687\n",
      "Train Epoch: 254 [29440/32031 (92%)]\tLoss: 218.604263\n",
      "Train Epoch: 254 [30720/32031 (96%)]\tLoss: 205.996918\n",
      "Train Epoch: 254 [7750/32031 (100%)]\tLoss: 195.911117\n",
      "====> Epoch: 254 Average loss: 204.7704\n",
      "====> Test set loss: 197.3820\n",
      "Train Epoch: 255 [0/32031 (0%)]\tLoss: 209.432114\n",
      "Train Epoch: 255 [1280/32031 (4%)]\tLoss: 208.066895\n",
      "Train Epoch: 255 [2560/32031 (8%)]\tLoss: 195.898026\n",
      "Train Epoch: 255 [3840/32031 (12%)]\tLoss: 200.386276\n",
      "Train Epoch: 255 [5120/32031 (16%)]\tLoss: 208.320999\n",
      "Train Epoch: 255 [6400/32031 (20%)]\tLoss: 207.703140\n",
      "Train Epoch: 255 [7680/32031 (24%)]\tLoss: 206.714722\n",
      "Train Epoch: 255 [8960/32031 (28%)]\tLoss: 198.067810\n",
      "Train Epoch: 255 [10240/32031 (32%)]\tLoss: 214.178345\n",
      "Train Epoch: 255 [11520/32031 (36%)]\tLoss: 215.149338\n",
      "Train Epoch: 255 [12800/32031 (40%)]\tLoss: 206.970337\n",
      "Train Epoch: 255 [14080/32031 (44%)]\tLoss: 200.401306\n",
      "Train Epoch: 255 [15360/32031 (48%)]\tLoss: 201.469116\n",
      "Train Epoch: 255 [16640/32031 (52%)]\tLoss: 200.042999\n",
      "Train Epoch: 255 [17920/32031 (56%)]\tLoss: 195.713470\n",
      "Train Epoch: 255 [19200/32031 (60%)]\tLoss: 199.723663\n",
      "Train Epoch: 255 [20480/32031 (64%)]\tLoss: 201.404968\n",
      "Train Epoch: 255 [21760/32031 (68%)]\tLoss: 198.811462\n",
      "Train Epoch: 255 [23040/32031 (72%)]\tLoss: 215.711655\n",
      "Train Epoch: 255 [24320/32031 (76%)]\tLoss: 198.959290\n",
      "Train Epoch: 255 [25600/32031 (80%)]\tLoss: 199.536652\n",
      "Train Epoch: 255 [26880/32031 (84%)]\tLoss: 197.566711\n",
      "Train Epoch: 255 [28160/32031 (88%)]\tLoss: 215.924850\n",
      "Train Epoch: 255 [29440/32031 (92%)]\tLoss: 204.780167\n",
      "Train Epoch: 255 [30720/32031 (96%)]\tLoss: 213.536499\n",
      "Train Epoch: 255 [7750/32031 (100%)]\tLoss: 203.882844\n",
      "====> Epoch: 255 Average loss: 203.9992\n",
      "====> Test set loss: 198.1915\n",
      "Train Epoch: 256 [0/32031 (0%)]\tLoss: 195.477371\n",
      "Train Epoch: 256 [1280/32031 (4%)]\tLoss: 189.181671\n",
      "Train Epoch: 256 [2560/32031 (8%)]\tLoss: 198.938644\n",
      "Train Epoch: 256 [3840/32031 (12%)]\tLoss: 202.745178\n",
      "Train Epoch: 256 [5120/32031 (16%)]\tLoss: 204.994522\n",
      "Train Epoch: 256 [6400/32031 (20%)]\tLoss: 198.442139\n",
      "Train Epoch: 256 [7680/32031 (24%)]\tLoss: 207.967178\n",
      "Train Epoch: 256 [8960/32031 (28%)]\tLoss: 209.572632\n",
      "Train Epoch: 256 [10240/32031 (32%)]\tLoss: 205.602890\n",
      "Train Epoch: 256 [11520/32031 (36%)]\tLoss: 191.300201\n",
      "Train Epoch: 256 [12800/32031 (40%)]\tLoss: 207.090912\n",
      "Train Epoch: 256 [14080/32031 (44%)]\tLoss: 188.791992\n",
      "Train Epoch: 256 [15360/32031 (48%)]\tLoss: 208.893921\n",
      "Train Epoch: 256 [16640/32031 (52%)]\tLoss: 203.473877\n",
      "Train Epoch: 256 [17920/32031 (56%)]\tLoss: 205.984467\n",
      "Train Epoch: 256 [19200/32031 (60%)]\tLoss: 204.811584\n",
      "Train Epoch: 256 [20480/32031 (64%)]\tLoss: 207.380768\n",
      "Train Epoch: 256 [21760/32031 (68%)]\tLoss: 210.921951\n",
      "Train Epoch: 256 [23040/32031 (72%)]\tLoss: 203.889069\n",
      "Train Epoch: 256 [24320/32031 (76%)]\tLoss: 208.663315\n",
      "Train Epoch: 256 [25600/32031 (80%)]\tLoss: 197.053558\n",
      "Train Epoch: 256 [26880/32031 (84%)]\tLoss: 201.507355\n",
      "Train Epoch: 256 [28160/32031 (88%)]\tLoss: 198.078781\n",
      "Train Epoch: 256 [29440/32031 (92%)]\tLoss: 203.212631\n",
      "Train Epoch: 256 [30720/32031 (96%)]\tLoss: 212.874817\n",
      "Train Epoch: 256 [7750/32031 (100%)]\tLoss: 191.981493\n",
      "====> Epoch: 256 Average loss: 204.2348\n",
      "====> Test set loss: 200.6352\n",
      "Train Epoch: 257 [0/32031 (0%)]\tLoss: 209.742828\n",
      "Train Epoch: 257 [1280/32031 (4%)]\tLoss: 202.115906\n",
      "Train Epoch: 257 [2560/32031 (8%)]\tLoss: 201.316589\n",
      "Train Epoch: 257 [3840/32031 (12%)]\tLoss: 198.785858\n",
      "Train Epoch: 257 [5120/32031 (16%)]\tLoss: 205.142975\n",
      "Train Epoch: 257 [6400/32031 (20%)]\tLoss: 204.440933\n",
      "Train Epoch: 257 [7680/32031 (24%)]\tLoss: 208.809555\n",
      "Train Epoch: 257 [8960/32031 (28%)]\tLoss: 191.502579\n",
      "Train Epoch: 257 [10240/32031 (32%)]\tLoss: 201.651382\n",
      "Train Epoch: 257 [11520/32031 (36%)]\tLoss: 209.887909\n",
      "Train Epoch: 257 [12800/32031 (40%)]\tLoss: 205.031647\n",
      "Train Epoch: 257 [14080/32031 (44%)]\tLoss: 205.617874\n",
      "Train Epoch: 257 [15360/32031 (48%)]\tLoss: 209.648819\n",
      "Train Epoch: 257 [16640/32031 (52%)]\tLoss: 199.904205\n",
      "Train Epoch: 257 [17920/32031 (56%)]\tLoss: 203.811478\n",
      "Train Epoch: 257 [19200/32031 (60%)]\tLoss: 208.220200\n",
      "Train Epoch: 257 [20480/32031 (64%)]\tLoss: 203.901016\n",
      "Train Epoch: 257 [21760/32031 (68%)]\tLoss: 198.420593\n",
      "Train Epoch: 257 [23040/32031 (72%)]\tLoss: 199.290390\n",
      "Train Epoch: 257 [24320/32031 (76%)]\tLoss: 216.975250\n",
      "Train Epoch: 257 [25600/32031 (80%)]\tLoss: 205.925751\n",
      "Train Epoch: 257 [26880/32031 (84%)]\tLoss: 203.725861\n",
      "Train Epoch: 257 [28160/32031 (88%)]\tLoss: 205.935226\n",
      "Train Epoch: 257 [29440/32031 (92%)]\tLoss: 205.646484\n",
      "Train Epoch: 257 [30720/32031 (96%)]\tLoss: 205.084290\n",
      "Train Epoch: 257 [7750/32031 (100%)]\tLoss: 205.069115\n",
      "====> Epoch: 257 Average loss: 204.2155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 198.9185\n",
      "Train Epoch: 258 [0/32031 (0%)]\tLoss: 204.223419\n",
      "Train Epoch: 258 [1280/32031 (4%)]\tLoss: 208.695023\n",
      "Train Epoch: 258 [2560/32031 (8%)]\tLoss: 204.849686\n",
      "Train Epoch: 258 [3840/32031 (12%)]\tLoss: 202.712921\n",
      "Train Epoch: 258 [5120/32031 (16%)]\tLoss: 209.611862\n",
      "Train Epoch: 258 [6400/32031 (20%)]\tLoss: 209.557388\n",
      "Train Epoch: 258 [7680/32031 (24%)]\tLoss: 194.842178\n",
      "Train Epoch: 258 [8960/32031 (28%)]\tLoss: 202.612885\n",
      "Train Epoch: 258 [10240/32031 (32%)]\tLoss: 200.322769\n",
      "Train Epoch: 258 [11520/32031 (36%)]\tLoss: 205.138794\n",
      "Train Epoch: 258 [12800/32031 (40%)]\tLoss: 203.343033\n",
      "Train Epoch: 258 [14080/32031 (44%)]\tLoss: 203.719696\n",
      "Train Epoch: 258 [15360/32031 (48%)]\tLoss: 224.268234\n",
      "Train Epoch: 258 [16640/32031 (52%)]\tLoss: 195.609161\n",
      "Train Epoch: 258 [17920/32031 (56%)]\tLoss: 204.388046\n",
      "Train Epoch: 258 [19200/32031 (60%)]\tLoss: 210.579529\n",
      "Train Epoch: 258 [20480/32031 (64%)]\tLoss: 204.178482\n",
      "Train Epoch: 258 [21760/32031 (68%)]\tLoss: 206.625458\n",
      "Train Epoch: 258 [23040/32031 (72%)]\tLoss: 196.224991\n",
      "Train Epoch: 258 [24320/32031 (76%)]\tLoss: 213.969086\n",
      "Train Epoch: 258 [25600/32031 (80%)]\tLoss: 207.239227\n",
      "Train Epoch: 258 [26880/32031 (84%)]\tLoss: 206.565872\n",
      "Train Epoch: 258 [28160/32031 (88%)]\tLoss: 195.355652\n",
      "Train Epoch: 258 [29440/32031 (92%)]\tLoss: 209.777298\n",
      "Train Epoch: 258 [30720/32031 (96%)]\tLoss: 204.224197\n",
      "Train Epoch: 258 [7750/32031 (100%)]\tLoss: 202.229823\n",
      "====> Epoch: 258 Average loss: 203.9610\n",
      "====> Test set loss: 197.3048\n",
      "Train Epoch: 259 [0/32031 (0%)]\tLoss: 192.307953\n",
      "Train Epoch: 259 [1280/32031 (4%)]\tLoss: 208.174530\n",
      "Train Epoch: 259 [2560/32031 (8%)]\tLoss: 215.854843\n",
      "Train Epoch: 259 [3840/32031 (12%)]\tLoss: 200.988663\n",
      "Train Epoch: 259 [5120/32031 (16%)]\tLoss: 208.920944\n",
      "Train Epoch: 259 [6400/32031 (20%)]\tLoss: 195.469543\n",
      "Train Epoch: 259 [7680/32031 (24%)]\tLoss: 202.188660\n",
      "Train Epoch: 259 [8960/32031 (28%)]\tLoss: 209.345917\n",
      "Train Epoch: 259 [10240/32031 (32%)]\tLoss: 215.316879\n",
      "Train Epoch: 259 [11520/32031 (36%)]\tLoss: 203.767319\n",
      "Train Epoch: 259 [12800/32031 (40%)]\tLoss: 203.634125\n",
      "Train Epoch: 259 [14080/32031 (44%)]\tLoss: 208.672638\n",
      "Train Epoch: 259 [15360/32031 (48%)]\tLoss: 197.560013\n",
      "Train Epoch: 259 [16640/32031 (52%)]\tLoss: 206.130280\n",
      "Train Epoch: 259 [17920/32031 (56%)]\tLoss: 199.907394\n",
      "Train Epoch: 259 [19200/32031 (60%)]\tLoss: 209.661285\n",
      "Train Epoch: 259 [20480/32031 (64%)]\tLoss: 209.333084\n",
      "Train Epoch: 259 [21760/32031 (68%)]\tLoss: 201.955597\n",
      "Train Epoch: 259 [23040/32031 (72%)]\tLoss: 199.744110\n",
      "Train Epoch: 259 [24320/32031 (76%)]\tLoss: 213.486328\n",
      "Train Epoch: 259 [25600/32031 (80%)]\tLoss: 202.104248\n",
      "Train Epoch: 259 [26880/32031 (84%)]\tLoss: 204.642548\n",
      "Train Epoch: 259 [28160/32031 (88%)]\tLoss: 200.318085\n",
      "Train Epoch: 259 [29440/32031 (92%)]\tLoss: 203.671906\n",
      "Train Epoch: 259 [30720/32031 (96%)]\tLoss: 203.892349\n",
      "Train Epoch: 259 [7750/32031 (100%)]\tLoss: 214.019957\n",
      "====> Epoch: 259 Average loss: 203.8997\n",
      "====> Test set loss: 200.9721\n",
      "Train Epoch: 260 [0/32031 (0%)]\tLoss: 194.509460\n",
      "Train Epoch: 260 [1280/32031 (4%)]\tLoss: 207.551270\n",
      "Train Epoch: 260 [2560/32031 (8%)]\tLoss: 186.873566\n",
      "Train Epoch: 260 [3840/32031 (12%)]\tLoss: 202.416504\n",
      "Train Epoch: 260 [5120/32031 (16%)]\tLoss: 188.716858\n",
      "Train Epoch: 260 [6400/32031 (20%)]\tLoss: 198.113235\n",
      "Train Epoch: 260 [7680/32031 (24%)]\tLoss: 211.396179\n",
      "Train Epoch: 260 [8960/32031 (28%)]\tLoss: 199.078339\n",
      "Train Epoch: 260 [10240/32031 (32%)]\tLoss: 192.174820\n",
      "Train Epoch: 260 [11520/32031 (36%)]\tLoss: 201.273804\n",
      "Train Epoch: 260 [12800/32031 (40%)]\tLoss: 200.921143\n",
      "Train Epoch: 260 [14080/32031 (44%)]\tLoss: 209.611313\n",
      "Train Epoch: 260 [15360/32031 (48%)]\tLoss: 206.808487\n",
      "Train Epoch: 260 [16640/32031 (52%)]\tLoss: 207.673065\n",
      "Train Epoch: 260 [17920/32031 (56%)]\tLoss: 205.312531\n",
      "Train Epoch: 260 [19200/32031 (60%)]\tLoss: 202.157394\n",
      "Train Epoch: 260 [20480/32031 (64%)]\tLoss: 198.763412\n",
      "Train Epoch: 260 [21760/32031 (68%)]\tLoss: 188.855377\n",
      "Train Epoch: 260 [23040/32031 (72%)]\tLoss: 193.450226\n",
      "Train Epoch: 260 [24320/32031 (76%)]\tLoss: 198.725891\n",
      "Train Epoch: 260 [25600/32031 (80%)]\tLoss: 209.040863\n",
      "Train Epoch: 260 [26880/32031 (84%)]\tLoss: 206.502899\n",
      "Train Epoch: 260 [28160/32031 (88%)]\tLoss: 204.286972\n",
      "Train Epoch: 260 [29440/32031 (92%)]\tLoss: 200.061050\n",
      "Train Epoch: 260 [30720/32031 (96%)]\tLoss: 210.825348\n",
      "Train Epoch: 260 [7750/32031 (100%)]\tLoss: 201.644279\n",
      "====> Epoch: 260 Average loss: 204.1559\n",
      "====> Test set loss: 197.4846\n",
      "Train Epoch: 261 [0/32031 (0%)]\tLoss: 207.514771\n",
      "Train Epoch: 261 [1280/32031 (4%)]\tLoss: 203.854706\n",
      "Train Epoch: 261 [2560/32031 (8%)]\tLoss: 197.772339\n",
      "Train Epoch: 261 [3840/32031 (12%)]\tLoss: 199.312927\n",
      "Train Epoch: 261 [5120/32031 (16%)]\tLoss: 210.318985\n",
      "Train Epoch: 261 [6400/32031 (20%)]\tLoss: 198.759399\n",
      "Train Epoch: 261 [7680/32031 (24%)]\tLoss: 209.648727\n",
      "Train Epoch: 261 [8960/32031 (28%)]\tLoss: 190.716141\n",
      "Train Epoch: 261 [10240/32031 (32%)]\tLoss: 190.248230\n",
      "Train Epoch: 261 [11520/32031 (36%)]\tLoss: 203.608490\n",
      "Train Epoch: 261 [12800/32031 (40%)]\tLoss: 215.594437\n",
      "Train Epoch: 261 [14080/32031 (44%)]\tLoss: 219.189438\n",
      "Train Epoch: 261 [15360/32031 (48%)]\tLoss: 201.763290\n",
      "Train Epoch: 261 [16640/32031 (52%)]\tLoss: 207.473022\n",
      "Train Epoch: 261 [17920/32031 (56%)]\tLoss: 208.002930\n",
      "Train Epoch: 261 [19200/32031 (60%)]\tLoss: 210.872559\n",
      "Train Epoch: 261 [20480/32031 (64%)]\tLoss: 201.919586\n",
      "Train Epoch: 261 [21760/32031 (68%)]\tLoss: 210.937958\n",
      "Train Epoch: 261 [23040/32031 (72%)]\tLoss: 200.739471\n",
      "Train Epoch: 261 [24320/32031 (76%)]\tLoss: 195.708084\n",
      "Train Epoch: 261 [25600/32031 (80%)]\tLoss: 195.824890\n",
      "Train Epoch: 261 [26880/32031 (84%)]\tLoss: 198.553421\n",
      "Train Epoch: 261 [28160/32031 (88%)]\tLoss: 200.784027\n",
      "Train Epoch: 261 [29440/32031 (92%)]\tLoss: 199.928513\n",
      "Train Epoch: 261 [30720/32031 (96%)]\tLoss: 199.737991\n",
      "Train Epoch: 261 [7750/32031 (100%)]\tLoss: 187.459740\n",
      "====> Epoch: 261 Average loss: 204.0957\n",
      "====> Test set loss: 197.6391\n",
      "Train Epoch: 262 [0/32031 (0%)]\tLoss: 203.469849\n",
      "Train Epoch: 262 [1280/32031 (4%)]\tLoss: 208.360321\n",
      "Train Epoch: 262 [2560/32031 (8%)]\tLoss: 198.167526\n",
      "Train Epoch: 262 [3840/32031 (12%)]\tLoss: 209.935913\n",
      "Train Epoch: 262 [5120/32031 (16%)]\tLoss: 210.970642\n",
      "Train Epoch: 262 [6400/32031 (20%)]\tLoss: 203.708710\n",
      "Train Epoch: 262 [7680/32031 (24%)]\tLoss: 197.552414\n",
      "Train Epoch: 262 [8960/32031 (28%)]\tLoss: 203.420532\n",
      "Train Epoch: 262 [10240/32031 (32%)]\tLoss: 200.461761\n",
      "Train Epoch: 262 [11520/32031 (36%)]\tLoss: 204.854355\n",
      "Train Epoch: 262 [12800/32031 (40%)]\tLoss: 210.138199\n",
      "Train Epoch: 262 [14080/32031 (44%)]\tLoss: 192.504456\n",
      "Train Epoch: 262 [15360/32031 (48%)]\tLoss: 198.878342\n",
      "Train Epoch: 262 [16640/32031 (52%)]\tLoss: 205.053589\n",
      "Train Epoch: 262 [17920/32031 (56%)]\tLoss: 222.596481\n",
      "Train Epoch: 262 [19200/32031 (60%)]\tLoss: 198.400406\n",
      "Train Epoch: 262 [20480/32031 (64%)]\tLoss: 204.186493\n",
      "Train Epoch: 262 [21760/32031 (68%)]\tLoss: 214.469925\n",
      "Train Epoch: 262 [23040/32031 (72%)]\tLoss: 205.832031\n",
      "Train Epoch: 262 [24320/32031 (76%)]\tLoss: 210.124817\n",
      "Train Epoch: 262 [25600/32031 (80%)]\tLoss: 197.399933\n",
      "Train Epoch: 262 [26880/32031 (84%)]\tLoss: 208.953964\n",
      "Train Epoch: 262 [28160/32031 (88%)]\tLoss: 213.406067\n",
      "Train Epoch: 262 [29440/32031 (92%)]\tLoss: 204.861221\n",
      "Train Epoch: 262 [30720/32031 (96%)]\tLoss: 212.453415\n",
      "Train Epoch: 262 [7750/32031 (100%)]\tLoss: 199.791945\n",
      "====> Epoch: 262 Average loss: 203.8165\n",
      "====> Test set loss: 197.6161\n",
      "Train Epoch: 263 [0/32031 (0%)]\tLoss: 214.983337\n",
      "Train Epoch: 263 [1280/32031 (4%)]\tLoss: 213.013412\n",
      "Train Epoch: 263 [2560/32031 (8%)]\tLoss: 188.308380\n",
      "Train Epoch: 263 [3840/32031 (12%)]\tLoss: 202.994980\n",
      "Train Epoch: 263 [5120/32031 (16%)]\tLoss: 204.559280\n",
      "Train Epoch: 263 [6400/32031 (20%)]\tLoss: 203.136993\n",
      "Train Epoch: 263 [7680/32031 (24%)]\tLoss: 204.770355\n",
      "Train Epoch: 263 [8960/32031 (28%)]\tLoss: 201.046448\n",
      "Train Epoch: 263 [10240/32031 (32%)]\tLoss: 203.868454\n",
      "Train Epoch: 263 [11520/32031 (36%)]\tLoss: 206.532761\n",
      "Train Epoch: 263 [12800/32031 (40%)]\tLoss: 193.252899\n",
      "Train Epoch: 263 [14080/32031 (44%)]\tLoss: 196.551346\n",
      "Train Epoch: 263 [15360/32031 (48%)]\tLoss: 199.325500\n",
      "Train Epoch: 263 [16640/32031 (52%)]\tLoss: 197.930664\n",
      "Train Epoch: 263 [17920/32031 (56%)]\tLoss: 199.851303\n",
      "Train Epoch: 263 [19200/32031 (60%)]\tLoss: 200.591766\n",
      "Train Epoch: 263 [20480/32031 (64%)]\tLoss: 207.864883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 263 [21760/32031 (68%)]\tLoss: 193.851089\n",
      "Train Epoch: 263 [23040/32031 (72%)]\tLoss: 204.182144\n",
      "Train Epoch: 263 [24320/32031 (76%)]\tLoss: 213.621277\n",
      "Train Epoch: 263 [25600/32031 (80%)]\tLoss: 208.462524\n",
      "Train Epoch: 263 [26880/32031 (84%)]\tLoss: 205.980408\n",
      "Train Epoch: 263 [28160/32031 (88%)]\tLoss: 215.165573\n",
      "Train Epoch: 263 [29440/32031 (92%)]\tLoss: 210.338470\n",
      "Train Epoch: 263 [30720/32031 (96%)]\tLoss: 193.999557\n",
      "Train Epoch: 263 [7750/32031 (100%)]\tLoss: 215.540039\n",
      "====> Epoch: 263 Average loss: 203.9195\n",
      "====> Test set loss: 198.2164\n",
      "Train Epoch: 264 [0/32031 (0%)]\tLoss: 213.839752\n",
      "Train Epoch: 264 [1280/32031 (4%)]\tLoss: 198.816864\n",
      "Train Epoch: 264 [2560/32031 (8%)]\tLoss: 202.050125\n",
      "Train Epoch: 264 [3840/32031 (12%)]\tLoss: 197.569351\n",
      "Train Epoch: 264 [5120/32031 (16%)]\tLoss: 206.148468\n",
      "Train Epoch: 264 [6400/32031 (20%)]\tLoss: 205.403641\n",
      "Train Epoch: 264 [7680/32031 (24%)]\tLoss: 203.731812\n",
      "Train Epoch: 264 [8960/32031 (28%)]\tLoss: 197.902939\n",
      "Train Epoch: 264 [10240/32031 (32%)]\tLoss: 213.499527\n",
      "Train Epoch: 264 [11520/32031 (36%)]\tLoss: 199.429428\n",
      "Train Epoch: 264 [12800/32031 (40%)]\tLoss: 208.377808\n",
      "Train Epoch: 264 [14080/32031 (44%)]\tLoss: 199.718384\n",
      "Train Epoch: 264 [15360/32031 (48%)]\tLoss: 204.810547\n",
      "Train Epoch: 264 [16640/32031 (52%)]\tLoss: 196.097733\n",
      "Train Epoch: 264 [17920/32031 (56%)]\tLoss: 206.205383\n",
      "Train Epoch: 264 [19200/32031 (60%)]\tLoss: 212.451233\n",
      "Train Epoch: 264 [20480/32031 (64%)]\tLoss: 203.658173\n",
      "Train Epoch: 264 [21760/32031 (68%)]\tLoss: 206.546021\n",
      "Train Epoch: 264 [23040/32031 (72%)]\tLoss: 207.487762\n",
      "Train Epoch: 264 [24320/32031 (76%)]\tLoss: 217.007462\n",
      "Train Epoch: 264 [25600/32031 (80%)]\tLoss: 213.984436\n",
      "Train Epoch: 264 [26880/32031 (84%)]\tLoss: 213.065079\n",
      "Train Epoch: 264 [28160/32031 (88%)]\tLoss: 203.071671\n",
      "Train Epoch: 264 [29440/32031 (92%)]\tLoss: 210.948013\n",
      "Train Epoch: 264 [30720/32031 (96%)]\tLoss: 197.529846\n",
      "Train Epoch: 264 [7750/32031 (100%)]\tLoss: 211.574424\n",
      "====> Epoch: 264 Average loss: 204.0805\n",
      "====> Test set loss: 200.5243\n",
      "Train Epoch: 265 [0/32031 (0%)]\tLoss: 192.131851\n",
      "Train Epoch: 265 [1280/32031 (4%)]\tLoss: 210.539368\n",
      "Train Epoch: 265 [2560/32031 (8%)]\tLoss: 196.332489\n",
      "Train Epoch: 265 [3840/32031 (12%)]\tLoss: 211.859436\n",
      "Train Epoch: 265 [5120/32031 (16%)]\tLoss: 209.737488\n",
      "Train Epoch: 265 [6400/32031 (20%)]\tLoss: 208.942551\n",
      "Train Epoch: 265 [7680/32031 (24%)]\tLoss: 196.372726\n",
      "Train Epoch: 265 [8960/32031 (28%)]\tLoss: 204.393814\n",
      "Train Epoch: 265 [10240/32031 (32%)]\tLoss: 194.330231\n",
      "Train Epoch: 265 [11520/32031 (36%)]\tLoss: 213.190536\n",
      "Train Epoch: 265 [12800/32031 (40%)]\tLoss: 202.639694\n",
      "Train Epoch: 265 [14080/32031 (44%)]\tLoss: 195.358795\n",
      "Train Epoch: 265 [15360/32031 (48%)]\tLoss: 197.710907\n",
      "Train Epoch: 265 [16640/32031 (52%)]\tLoss: 204.171082\n",
      "Train Epoch: 265 [17920/32031 (56%)]\tLoss: 200.127335\n",
      "Train Epoch: 265 [19200/32031 (60%)]\tLoss: 195.860901\n",
      "Train Epoch: 265 [20480/32031 (64%)]\tLoss: 198.624680\n",
      "Train Epoch: 265 [21760/32031 (68%)]\tLoss: 204.403931\n",
      "Train Epoch: 265 [23040/32031 (72%)]\tLoss: 199.458939\n",
      "Train Epoch: 265 [24320/32031 (76%)]\tLoss: 193.705978\n",
      "Train Epoch: 265 [25600/32031 (80%)]\tLoss: 208.674789\n",
      "Train Epoch: 265 [26880/32031 (84%)]\tLoss: 209.660950\n",
      "Train Epoch: 265 [28160/32031 (88%)]\tLoss: 208.036331\n",
      "Train Epoch: 265 [29440/32031 (92%)]\tLoss: 216.432465\n",
      "Train Epoch: 265 [30720/32031 (96%)]\tLoss: 201.452911\n",
      "Train Epoch: 265 [7750/32031 (100%)]\tLoss: 226.148107\n",
      "====> Epoch: 265 Average loss: 203.8274\n",
      "====> Test set loss: 197.6702\n",
      "Train Epoch: 266 [0/32031 (0%)]\tLoss: 190.824005\n",
      "Train Epoch: 266 [1280/32031 (4%)]\tLoss: 205.266327\n",
      "Train Epoch: 266 [2560/32031 (8%)]\tLoss: 209.304932\n",
      "Train Epoch: 266 [3840/32031 (12%)]\tLoss: 203.986908\n",
      "Train Epoch: 266 [5120/32031 (16%)]\tLoss: 214.783325\n",
      "Train Epoch: 266 [6400/32031 (20%)]\tLoss: 196.780487\n",
      "Train Epoch: 266 [7680/32031 (24%)]\tLoss: 205.096680\n",
      "Train Epoch: 266 [8960/32031 (28%)]\tLoss: 201.414978\n",
      "Train Epoch: 266 [10240/32031 (32%)]\tLoss: 208.072769\n",
      "Train Epoch: 266 [11520/32031 (36%)]\tLoss: 206.443954\n",
      "Train Epoch: 266 [12800/32031 (40%)]\tLoss: 198.963669\n",
      "Train Epoch: 266 [14080/32031 (44%)]\tLoss: 198.925583\n",
      "Train Epoch: 266 [15360/32031 (48%)]\tLoss: 212.905090\n",
      "Train Epoch: 266 [16640/32031 (52%)]\tLoss: 213.590271\n",
      "Train Epoch: 266 [17920/32031 (56%)]\tLoss: 204.636810\n",
      "Train Epoch: 266 [19200/32031 (60%)]\tLoss: 215.430695\n",
      "Train Epoch: 266 [20480/32031 (64%)]\tLoss: 198.780701\n",
      "Train Epoch: 266 [21760/32031 (68%)]\tLoss: 202.715668\n",
      "Train Epoch: 266 [23040/32031 (72%)]\tLoss: 211.672760\n",
      "Train Epoch: 266 [24320/32031 (76%)]\tLoss: 205.719849\n",
      "Train Epoch: 266 [25600/32031 (80%)]\tLoss: 199.354095\n",
      "Train Epoch: 266 [26880/32031 (84%)]\tLoss: 203.060242\n",
      "Train Epoch: 266 [28160/32031 (88%)]\tLoss: 199.790421\n",
      "Train Epoch: 266 [29440/32031 (92%)]\tLoss: 220.224213\n",
      "Train Epoch: 266 [30720/32031 (96%)]\tLoss: 200.219955\n",
      "Train Epoch: 266 [7750/32031 (100%)]\tLoss: 202.934964\n",
      "====> Epoch: 266 Average loss: 204.3149\n",
      "====> Test set loss: 196.3673\n",
      "Train Epoch: 267 [0/32031 (0%)]\tLoss: 208.312668\n",
      "Train Epoch: 267 [1280/32031 (4%)]\tLoss: 199.538239\n",
      "Train Epoch: 267 [2560/32031 (8%)]\tLoss: 219.250031\n",
      "Train Epoch: 267 [3840/32031 (12%)]\tLoss: 189.278336\n",
      "Train Epoch: 267 [5120/32031 (16%)]\tLoss: 205.426285\n",
      "Train Epoch: 267 [6400/32031 (20%)]\tLoss: 206.956207\n",
      "Train Epoch: 267 [7680/32031 (24%)]\tLoss: 192.498978\n",
      "Train Epoch: 267 [8960/32031 (28%)]\tLoss: 204.294479\n",
      "Train Epoch: 267 [10240/32031 (32%)]\tLoss: 209.409592\n",
      "Train Epoch: 267 [11520/32031 (36%)]\tLoss: 211.814850\n",
      "Train Epoch: 267 [12800/32031 (40%)]\tLoss: 208.134033\n",
      "Train Epoch: 267 [14080/32031 (44%)]\tLoss: 207.037613\n",
      "Train Epoch: 267 [15360/32031 (48%)]\tLoss: 199.211151\n",
      "Train Epoch: 267 [16640/32031 (52%)]\tLoss: 204.802872\n",
      "Train Epoch: 267 [17920/32031 (56%)]\tLoss: 195.715668\n",
      "Train Epoch: 267 [19200/32031 (60%)]\tLoss: 212.069061\n",
      "Train Epoch: 267 [20480/32031 (64%)]\tLoss: 197.441391\n",
      "Train Epoch: 267 [21760/32031 (68%)]\tLoss: 207.734436\n",
      "Train Epoch: 267 [23040/32031 (72%)]\tLoss: 198.312149\n",
      "Train Epoch: 267 [24320/32031 (76%)]\tLoss: 195.447723\n",
      "Train Epoch: 267 [25600/32031 (80%)]\tLoss: 213.033890\n",
      "Train Epoch: 267 [26880/32031 (84%)]\tLoss: 203.272934\n",
      "Train Epoch: 267 [28160/32031 (88%)]\tLoss: 197.925552\n",
      "Train Epoch: 267 [29440/32031 (92%)]\tLoss: 195.035980\n",
      "Train Epoch: 267 [30720/32031 (96%)]\tLoss: 206.514999\n",
      "Train Epoch: 267 [7750/32031 (100%)]\tLoss: 184.576849\n",
      "====> Epoch: 267 Average loss: 203.7004\n",
      "====> Test set loss: 198.0727\n",
      "Train Epoch: 268 [0/32031 (0%)]\tLoss: 204.649673\n",
      "Train Epoch: 268 [1280/32031 (4%)]\tLoss: 193.823410\n",
      "Train Epoch: 268 [2560/32031 (8%)]\tLoss: 200.741302\n",
      "Train Epoch: 268 [3840/32031 (12%)]\tLoss: 198.892441\n",
      "Train Epoch: 268 [5120/32031 (16%)]\tLoss: 203.776138\n",
      "Train Epoch: 268 [6400/32031 (20%)]\tLoss: 204.831268\n",
      "Train Epoch: 268 [7680/32031 (24%)]\tLoss: 204.569702\n",
      "Train Epoch: 268 [8960/32031 (28%)]\tLoss: 204.848297\n",
      "Train Epoch: 268 [10240/32031 (32%)]\tLoss: 204.659424\n",
      "Train Epoch: 268 [11520/32031 (36%)]\tLoss: 205.062561\n",
      "Train Epoch: 268 [12800/32031 (40%)]\tLoss: 199.925369\n",
      "Train Epoch: 268 [14080/32031 (44%)]\tLoss: 202.677963\n",
      "Train Epoch: 268 [15360/32031 (48%)]\tLoss: 191.179657\n",
      "Train Epoch: 268 [16640/32031 (52%)]\tLoss: 196.615509\n",
      "Train Epoch: 268 [17920/32031 (56%)]\tLoss: 220.461060\n",
      "Train Epoch: 268 [19200/32031 (60%)]\tLoss: 205.372131\n",
      "Train Epoch: 268 [20480/32031 (64%)]\tLoss: 208.105957\n",
      "Train Epoch: 268 [21760/32031 (68%)]\tLoss: 200.031158\n",
      "Train Epoch: 268 [23040/32031 (72%)]\tLoss: 203.828644\n",
      "Train Epoch: 268 [24320/32031 (76%)]\tLoss: 195.498398\n",
      "Train Epoch: 268 [25600/32031 (80%)]\tLoss: 188.580933\n",
      "Train Epoch: 268 [26880/32031 (84%)]\tLoss: 207.635162\n",
      "Train Epoch: 268 [28160/32031 (88%)]\tLoss: 202.696960\n",
      "Train Epoch: 268 [29440/32031 (92%)]\tLoss: 211.060196\n",
      "Train Epoch: 268 [30720/32031 (96%)]\tLoss: 196.158524\n",
      "Train Epoch: 268 [7750/32031 (100%)]\tLoss: 195.556987\n",
      "====> Epoch: 268 Average loss: 203.6882\n",
      "====> Test set loss: 199.2057\n",
      "Train Epoch: 269 [0/32031 (0%)]\tLoss: 195.870346\n",
      "Train Epoch: 269 [1280/32031 (4%)]\tLoss: 192.311737\n",
      "Train Epoch: 269 [2560/32031 (8%)]\tLoss: 190.888290\n",
      "Train Epoch: 269 [3840/32031 (12%)]\tLoss: 201.398132\n",
      "Train Epoch: 269 [5120/32031 (16%)]\tLoss: 198.178665\n",
      "Train Epoch: 269 [6400/32031 (20%)]\tLoss: 209.668976\n",
      "Train Epoch: 269 [7680/32031 (24%)]\tLoss: 202.031967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 269 [8960/32031 (28%)]\tLoss: 205.511185\n",
      "Train Epoch: 269 [10240/32031 (32%)]\tLoss: 183.527222\n",
      "Train Epoch: 269 [11520/32031 (36%)]\tLoss: 204.599487\n",
      "Train Epoch: 269 [12800/32031 (40%)]\tLoss: 196.611023\n",
      "Train Epoch: 269 [14080/32031 (44%)]\tLoss: 207.733780\n",
      "Train Epoch: 269 [15360/32031 (48%)]\tLoss: 211.342072\n",
      "Train Epoch: 269 [16640/32031 (52%)]\tLoss: 210.495926\n",
      "Train Epoch: 269 [17920/32031 (56%)]\tLoss: 209.941696\n",
      "Train Epoch: 269 [19200/32031 (60%)]\tLoss: 208.256393\n",
      "Train Epoch: 269 [20480/32031 (64%)]\tLoss: 203.774109\n",
      "Train Epoch: 269 [21760/32031 (68%)]\tLoss: 217.232147\n",
      "Train Epoch: 269 [23040/32031 (72%)]\tLoss: 195.891281\n",
      "Train Epoch: 269 [24320/32031 (76%)]\tLoss: 200.384857\n",
      "Train Epoch: 269 [25600/32031 (80%)]\tLoss: 216.007080\n",
      "Train Epoch: 269 [26880/32031 (84%)]\tLoss: 213.132965\n",
      "Train Epoch: 269 [28160/32031 (88%)]\tLoss: 195.933777\n",
      "Train Epoch: 269 [29440/32031 (92%)]\tLoss: 208.102859\n",
      "Train Epoch: 269 [30720/32031 (96%)]\tLoss: 201.169724\n",
      "Train Epoch: 269 [7750/32031 (100%)]\tLoss: 196.706779\n",
      "====> Epoch: 269 Average loss: 204.0039\n",
      "====> Test set loss: 198.5693\n",
      "Train Epoch: 270 [0/32031 (0%)]\tLoss: 193.846176\n",
      "Train Epoch: 270 [1280/32031 (4%)]\tLoss: 201.581085\n",
      "Train Epoch: 270 [2560/32031 (8%)]\tLoss: 202.539948\n",
      "Train Epoch: 270 [3840/32031 (12%)]\tLoss: 203.961853\n",
      "Train Epoch: 270 [5120/32031 (16%)]\tLoss: 210.572113\n",
      "Train Epoch: 270 [6400/32031 (20%)]\tLoss: 192.902985\n",
      "Train Epoch: 270 [7680/32031 (24%)]\tLoss: 190.891006\n",
      "Train Epoch: 270 [8960/32031 (28%)]\tLoss: 202.807358\n",
      "Train Epoch: 270 [10240/32031 (32%)]\tLoss: 221.683548\n",
      "Train Epoch: 270 [11520/32031 (36%)]\tLoss: 201.246658\n",
      "Train Epoch: 270 [12800/32031 (40%)]\tLoss: 207.299088\n",
      "Train Epoch: 270 [14080/32031 (44%)]\tLoss: 201.762283\n",
      "Train Epoch: 270 [15360/32031 (48%)]\tLoss: 211.647552\n",
      "Train Epoch: 270 [16640/32031 (52%)]\tLoss: 212.695923\n",
      "Train Epoch: 270 [17920/32031 (56%)]\tLoss: 208.028152\n",
      "Train Epoch: 270 [19200/32031 (60%)]\tLoss: 217.009689\n",
      "Train Epoch: 270 [20480/32031 (64%)]\tLoss: 210.165466\n",
      "Train Epoch: 270 [21760/32031 (68%)]\tLoss: 197.133408\n",
      "Train Epoch: 270 [23040/32031 (72%)]\tLoss: 196.366776\n",
      "Train Epoch: 270 [24320/32031 (76%)]\tLoss: 213.906967\n",
      "Train Epoch: 270 [25600/32031 (80%)]\tLoss: 198.128021\n",
      "Train Epoch: 270 [26880/32031 (84%)]\tLoss: 208.270462\n",
      "Train Epoch: 270 [28160/32031 (88%)]\tLoss: 203.005676\n",
      "Train Epoch: 270 [29440/32031 (92%)]\tLoss: 204.668091\n",
      "Train Epoch: 270 [30720/32031 (96%)]\tLoss: 195.603775\n",
      "Train Epoch: 270 [7750/32031 (100%)]\tLoss: 213.414441\n",
      "====> Epoch: 270 Average loss: 203.8005\n",
      "====> Test set loss: 197.7100\n",
      "Train Epoch: 271 [0/32031 (0%)]\tLoss: 199.307068\n",
      "Train Epoch: 271 [1280/32031 (4%)]\tLoss: 214.025513\n",
      "Train Epoch: 271 [2560/32031 (8%)]\tLoss: 201.151657\n",
      "Train Epoch: 271 [3840/32031 (12%)]\tLoss: 201.921616\n",
      "Train Epoch: 271 [5120/32031 (16%)]\tLoss: 195.217957\n",
      "Train Epoch: 271 [6400/32031 (20%)]\tLoss: 203.958298\n",
      "Train Epoch: 271 [7680/32031 (24%)]\tLoss: 207.033600\n",
      "Train Epoch: 271 [8960/32031 (28%)]\tLoss: 198.899323\n",
      "Train Epoch: 271 [10240/32031 (32%)]\tLoss: 206.334198\n",
      "Train Epoch: 271 [11520/32031 (36%)]\tLoss: 207.759003\n",
      "Train Epoch: 271 [12800/32031 (40%)]\tLoss: 193.004395\n",
      "Train Epoch: 271 [14080/32031 (44%)]\tLoss: 204.341827\n",
      "Train Epoch: 271 [15360/32031 (48%)]\tLoss: 202.855179\n",
      "Train Epoch: 271 [16640/32031 (52%)]\tLoss: 203.192917\n",
      "Train Epoch: 271 [17920/32031 (56%)]\tLoss: 206.841339\n",
      "Train Epoch: 271 [19200/32031 (60%)]\tLoss: 190.465637\n",
      "Train Epoch: 271 [20480/32031 (64%)]\tLoss: 194.592712\n",
      "Train Epoch: 271 [21760/32031 (68%)]\tLoss: 215.110886\n",
      "Train Epoch: 271 [23040/32031 (72%)]\tLoss: 219.581848\n",
      "Train Epoch: 271 [24320/32031 (76%)]\tLoss: 216.762283\n",
      "Train Epoch: 271 [25600/32031 (80%)]\tLoss: 186.499161\n",
      "Train Epoch: 271 [26880/32031 (84%)]\tLoss: 197.137802\n",
      "Train Epoch: 271 [28160/32031 (88%)]\tLoss: 197.523666\n",
      "Train Epoch: 271 [29440/32031 (92%)]\tLoss: 200.174805\n",
      "Train Epoch: 271 [30720/32031 (96%)]\tLoss: 216.742767\n",
      "Train Epoch: 271 [7750/32031 (100%)]\tLoss: 176.396988\n",
      "====> Epoch: 271 Average loss: 204.0320\n",
      "====> Test set loss: 199.3712\n",
      "Train Epoch: 272 [0/32031 (0%)]\tLoss: 194.426682\n",
      "Train Epoch: 272 [1280/32031 (4%)]\tLoss: 196.575790\n",
      "Train Epoch: 272 [2560/32031 (8%)]\tLoss: 200.124023\n",
      "Train Epoch: 272 [3840/32031 (12%)]\tLoss: 207.024216\n",
      "Train Epoch: 272 [5120/32031 (16%)]\tLoss: 202.738235\n",
      "Train Epoch: 272 [6400/32031 (20%)]\tLoss: 205.091949\n",
      "Train Epoch: 272 [7680/32031 (24%)]\tLoss: 193.359009\n",
      "Train Epoch: 272 [8960/32031 (28%)]\tLoss: 201.690613\n",
      "Train Epoch: 272 [10240/32031 (32%)]\tLoss: 207.594238\n",
      "Train Epoch: 272 [11520/32031 (36%)]\tLoss: 206.058472\n",
      "Train Epoch: 272 [12800/32031 (40%)]\tLoss: 207.132538\n",
      "Train Epoch: 272 [14080/32031 (44%)]\tLoss: 208.113831\n",
      "Train Epoch: 272 [15360/32031 (48%)]\tLoss: 202.960007\n",
      "Train Epoch: 272 [16640/32031 (52%)]\tLoss: 202.483139\n",
      "Train Epoch: 272 [17920/32031 (56%)]\tLoss: 198.838486\n",
      "Train Epoch: 272 [19200/32031 (60%)]\tLoss: 201.948776\n",
      "Train Epoch: 272 [20480/32031 (64%)]\tLoss: 207.337784\n",
      "Train Epoch: 272 [21760/32031 (68%)]\tLoss: 193.671539\n",
      "Train Epoch: 272 [23040/32031 (72%)]\tLoss: 200.817032\n",
      "Train Epoch: 272 [24320/32031 (76%)]\tLoss: 216.862320\n",
      "Train Epoch: 272 [25600/32031 (80%)]\tLoss: 203.319366\n",
      "Train Epoch: 272 [26880/32031 (84%)]\tLoss: 202.282944\n",
      "Train Epoch: 272 [28160/32031 (88%)]\tLoss: 200.346436\n",
      "Train Epoch: 272 [29440/32031 (92%)]\tLoss: 211.720764\n",
      "Train Epoch: 272 [30720/32031 (96%)]\tLoss: 200.237457\n",
      "Train Epoch: 272 [7750/32031 (100%)]\tLoss: 204.209441\n",
      "====> Epoch: 272 Average loss: 203.5954\n",
      "====> Test set loss: 196.6521\n",
      "Train Epoch: 273 [0/32031 (0%)]\tLoss: 199.387146\n",
      "Train Epoch: 273 [1280/32031 (4%)]\tLoss: 202.181168\n",
      "Train Epoch: 273 [2560/32031 (8%)]\tLoss: 191.857620\n",
      "Train Epoch: 273 [3840/32031 (12%)]\tLoss: 204.543106\n",
      "Train Epoch: 273 [5120/32031 (16%)]\tLoss: 193.345139\n",
      "Train Epoch: 273 [6400/32031 (20%)]\tLoss: 203.854401\n",
      "Train Epoch: 273 [7680/32031 (24%)]\tLoss: 199.072479\n",
      "Train Epoch: 273 [8960/32031 (28%)]\tLoss: 205.439590\n",
      "Train Epoch: 273 [10240/32031 (32%)]\tLoss: 204.999771\n",
      "Train Epoch: 273 [11520/32031 (36%)]\tLoss: 204.967972\n",
      "Train Epoch: 273 [12800/32031 (40%)]\tLoss: 202.291245\n",
      "Train Epoch: 273 [14080/32031 (44%)]\tLoss: 198.298447\n",
      "Train Epoch: 273 [15360/32031 (48%)]\tLoss: 211.796143\n",
      "Train Epoch: 273 [16640/32031 (52%)]\tLoss: 211.416565\n",
      "Train Epoch: 273 [17920/32031 (56%)]\tLoss: 207.534912\n",
      "Train Epoch: 273 [19200/32031 (60%)]\tLoss: 195.422226\n",
      "Train Epoch: 273 [20480/32031 (64%)]\tLoss: 213.285080\n",
      "Train Epoch: 273 [21760/32031 (68%)]\tLoss: 210.532166\n",
      "Train Epoch: 273 [23040/32031 (72%)]\tLoss: 204.565186\n",
      "Train Epoch: 273 [24320/32031 (76%)]\tLoss: 210.032532\n",
      "Train Epoch: 273 [25600/32031 (80%)]\tLoss: 203.724106\n",
      "Train Epoch: 273 [26880/32031 (84%)]\tLoss: 201.172653\n",
      "Train Epoch: 273 [28160/32031 (88%)]\tLoss: 203.268692\n",
      "Train Epoch: 273 [29440/32031 (92%)]\tLoss: 211.220963\n",
      "Train Epoch: 273 [30720/32031 (96%)]\tLoss: 208.270203\n",
      "Train Epoch: 273 [7750/32031 (100%)]\tLoss: 225.791992\n",
      "====> Epoch: 273 Average loss: 203.6749\n",
      "====> Test set loss: 197.6862\n",
      "Train Epoch: 274 [0/32031 (0%)]\tLoss: 201.131210\n",
      "Train Epoch: 274 [1280/32031 (4%)]\tLoss: 209.548325\n",
      "Train Epoch: 274 [2560/32031 (8%)]\tLoss: 210.188583\n",
      "Train Epoch: 274 [3840/32031 (12%)]\tLoss: 205.547806\n",
      "Train Epoch: 274 [5120/32031 (16%)]\tLoss: 185.509491\n",
      "Train Epoch: 274 [6400/32031 (20%)]\tLoss: 209.036987\n",
      "Train Epoch: 274 [7680/32031 (24%)]\tLoss: 199.267990\n",
      "Train Epoch: 274 [8960/32031 (28%)]\tLoss: 202.111465\n",
      "Train Epoch: 274 [10240/32031 (32%)]\tLoss: 198.545425\n",
      "Train Epoch: 274 [11520/32031 (36%)]\tLoss: 201.631866\n",
      "Train Epoch: 274 [12800/32031 (40%)]\tLoss: 211.869370\n",
      "Train Epoch: 274 [14080/32031 (44%)]\tLoss: 200.972900\n",
      "Train Epoch: 274 [15360/32031 (48%)]\tLoss: 194.363831\n",
      "Train Epoch: 274 [16640/32031 (52%)]\tLoss: 200.829666\n",
      "Train Epoch: 274 [17920/32031 (56%)]\tLoss: 197.358734\n",
      "Train Epoch: 274 [19200/32031 (60%)]\tLoss: 187.642227\n",
      "Train Epoch: 274 [20480/32031 (64%)]\tLoss: 200.144928\n",
      "Train Epoch: 274 [21760/32031 (68%)]\tLoss: 207.870972\n",
      "Train Epoch: 274 [23040/32031 (72%)]\tLoss: 209.430237\n",
      "Train Epoch: 274 [24320/32031 (76%)]\tLoss: 195.118225\n",
      "Train Epoch: 274 [25600/32031 (80%)]\tLoss: 213.847824\n",
      "Train Epoch: 274 [26880/32031 (84%)]\tLoss: 199.280838\n",
      "Train Epoch: 274 [28160/32031 (88%)]\tLoss: 211.617325\n",
      "Train Epoch: 274 [29440/32031 (92%)]\tLoss: 217.534180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 274 [30720/32031 (96%)]\tLoss: 207.392273\n",
      "Train Epoch: 274 [7750/32031 (100%)]\tLoss: 189.221585\n",
      "====> Epoch: 274 Average loss: 203.7529\n",
      "====> Test set loss: 199.9646\n",
      "Train Epoch: 275 [0/32031 (0%)]\tLoss: 196.807968\n",
      "Train Epoch: 275 [1280/32031 (4%)]\tLoss: 210.455872\n",
      "Train Epoch: 275 [2560/32031 (8%)]\tLoss: 202.182755\n",
      "Train Epoch: 275 [3840/32031 (12%)]\tLoss: 204.133621\n",
      "Train Epoch: 275 [5120/32031 (16%)]\tLoss: 203.059906\n",
      "Train Epoch: 275 [6400/32031 (20%)]\tLoss: 198.847122\n",
      "Train Epoch: 275 [7680/32031 (24%)]\tLoss: 194.066345\n",
      "Train Epoch: 275 [8960/32031 (28%)]\tLoss: 193.140289\n",
      "Train Epoch: 275 [10240/32031 (32%)]\tLoss: 201.754318\n",
      "Train Epoch: 275 [11520/32031 (36%)]\tLoss: 205.079742\n",
      "Train Epoch: 275 [12800/32031 (40%)]\tLoss: 203.140991\n",
      "Train Epoch: 275 [14080/32031 (44%)]\tLoss: 213.449951\n",
      "Train Epoch: 275 [15360/32031 (48%)]\tLoss: 190.086670\n",
      "Train Epoch: 275 [16640/32031 (52%)]\tLoss: 199.244705\n",
      "Train Epoch: 275 [17920/32031 (56%)]\tLoss: 205.172241\n",
      "Train Epoch: 275 [19200/32031 (60%)]\tLoss: 214.660217\n",
      "Train Epoch: 275 [20480/32031 (64%)]\tLoss: 201.040665\n",
      "Train Epoch: 275 [21760/32031 (68%)]\tLoss: 202.813187\n",
      "Train Epoch: 275 [23040/32031 (72%)]\tLoss: 196.935989\n",
      "Train Epoch: 275 [24320/32031 (76%)]\tLoss: 211.222549\n",
      "Train Epoch: 275 [25600/32031 (80%)]\tLoss: 210.843964\n",
      "Train Epoch: 275 [26880/32031 (84%)]\tLoss: 211.448654\n",
      "Train Epoch: 275 [28160/32031 (88%)]\tLoss: 196.871246\n",
      "Train Epoch: 275 [29440/32031 (92%)]\tLoss: 214.145752\n",
      "Train Epoch: 275 [30720/32031 (96%)]\tLoss: 207.972046\n",
      "Train Epoch: 275 [7750/32031 (100%)]\tLoss: 215.326140\n",
      "====> Epoch: 275 Average loss: 203.8136\n",
      "====> Test set loss: 196.9176\n",
      "Train Epoch: 276 [0/32031 (0%)]\tLoss: 198.365158\n",
      "Train Epoch: 276 [1280/32031 (4%)]\tLoss: 200.093506\n",
      "Train Epoch: 276 [2560/32031 (8%)]\tLoss: 193.393127\n",
      "Train Epoch: 276 [3840/32031 (12%)]\tLoss: 195.032715\n",
      "Train Epoch: 276 [5120/32031 (16%)]\tLoss: 191.022278\n",
      "Train Epoch: 276 [6400/32031 (20%)]\tLoss: 207.841248\n",
      "Train Epoch: 276 [7680/32031 (24%)]\tLoss: 210.407364\n",
      "Train Epoch: 276 [8960/32031 (28%)]\tLoss: 198.392349\n",
      "Train Epoch: 276 [10240/32031 (32%)]\tLoss: 191.015945\n",
      "Train Epoch: 276 [11520/32031 (36%)]\tLoss: 200.802185\n",
      "Train Epoch: 276 [12800/32031 (40%)]\tLoss: 190.795135\n",
      "Train Epoch: 276 [14080/32031 (44%)]\tLoss: 196.011414\n",
      "Train Epoch: 276 [15360/32031 (48%)]\tLoss: 206.541763\n",
      "Train Epoch: 276 [16640/32031 (52%)]\tLoss: 204.864380\n",
      "Train Epoch: 276 [17920/32031 (56%)]\tLoss: 201.395386\n",
      "Train Epoch: 276 [19200/32031 (60%)]\tLoss: 206.042740\n",
      "Train Epoch: 276 [20480/32031 (64%)]\tLoss: 199.139862\n",
      "Train Epoch: 276 [21760/32031 (68%)]\tLoss: 193.996017\n",
      "Train Epoch: 276 [23040/32031 (72%)]\tLoss: 199.934113\n",
      "Train Epoch: 276 [24320/32031 (76%)]\tLoss: 202.969513\n",
      "Train Epoch: 276 [25600/32031 (80%)]\tLoss: 204.812134\n",
      "Train Epoch: 276 [26880/32031 (84%)]\tLoss: 203.647614\n",
      "Train Epoch: 276 [28160/32031 (88%)]\tLoss: 189.245087\n",
      "Train Epoch: 276 [29440/32031 (92%)]\tLoss: 208.517120\n",
      "Train Epoch: 276 [30720/32031 (96%)]\tLoss: 199.281952\n",
      "Train Epoch: 276 [7750/32031 (100%)]\tLoss: 198.904360\n",
      "====> Epoch: 276 Average loss: 203.8999\n",
      "====> Test set loss: 197.7784\n",
      "Train Epoch: 277 [0/32031 (0%)]\tLoss: 206.792999\n",
      "Train Epoch: 277 [1280/32031 (4%)]\tLoss: 202.288315\n",
      "Train Epoch: 277 [2560/32031 (8%)]\tLoss: 207.610916\n",
      "Train Epoch: 277 [3840/32031 (12%)]\tLoss: 214.435623\n",
      "Train Epoch: 277 [5120/32031 (16%)]\tLoss: 205.586227\n",
      "Train Epoch: 277 [6400/32031 (20%)]\tLoss: 208.994125\n",
      "Train Epoch: 277 [7680/32031 (24%)]\tLoss: 202.602264\n",
      "Train Epoch: 277 [8960/32031 (28%)]\tLoss: 214.603683\n",
      "Train Epoch: 277 [10240/32031 (32%)]\tLoss: 200.816315\n",
      "Train Epoch: 277 [11520/32031 (36%)]\tLoss: 187.767151\n",
      "Train Epoch: 277 [12800/32031 (40%)]\tLoss: 197.039093\n",
      "Train Epoch: 277 [14080/32031 (44%)]\tLoss: 207.860382\n",
      "Train Epoch: 277 [15360/32031 (48%)]\tLoss: 194.398117\n",
      "Train Epoch: 277 [16640/32031 (52%)]\tLoss: 206.856430\n",
      "Train Epoch: 277 [17920/32031 (56%)]\tLoss: 204.220413\n",
      "Train Epoch: 277 [19200/32031 (60%)]\tLoss: 198.089462\n",
      "Train Epoch: 277 [20480/32031 (64%)]\tLoss: 208.177582\n",
      "Train Epoch: 277 [21760/32031 (68%)]\tLoss: 209.812332\n",
      "Train Epoch: 277 [23040/32031 (72%)]\tLoss: 214.874313\n",
      "Train Epoch: 277 [24320/32031 (76%)]\tLoss: 191.473419\n",
      "Train Epoch: 277 [25600/32031 (80%)]\tLoss: 206.911926\n",
      "Train Epoch: 277 [26880/32031 (84%)]\tLoss: 196.818710\n",
      "Train Epoch: 277 [28160/32031 (88%)]\tLoss: 210.397278\n",
      "Train Epoch: 277 [29440/32031 (92%)]\tLoss: 212.868332\n",
      "Train Epoch: 277 [30720/32031 (96%)]\tLoss: 203.893112\n",
      "Train Epoch: 277 [7750/32031 (100%)]\tLoss: 210.073195\n",
      "====> Epoch: 277 Average loss: 203.9208\n",
      "====> Test set loss: 197.1767\n",
      "Train Epoch: 278 [0/32031 (0%)]\tLoss: 202.160248\n",
      "Train Epoch: 278 [1280/32031 (4%)]\tLoss: 190.016022\n",
      "Train Epoch: 278 [2560/32031 (8%)]\tLoss: 203.605896\n",
      "Train Epoch: 278 [3840/32031 (12%)]\tLoss: 195.748627\n",
      "Train Epoch: 278 [5120/32031 (16%)]\tLoss: 205.274353\n",
      "Train Epoch: 278 [6400/32031 (20%)]\tLoss: 193.886444\n",
      "Train Epoch: 278 [7680/32031 (24%)]\tLoss: 200.440430\n",
      "Train Epoch: 278 [8960/32031 (28%)]\tLoss: 184.387772\n",
      "Train Epoch: 278 [10240/32031 (32%)]\tLoss: 204.260315\n",
      "Train Epoch: 278 [11520/32031 (36%)]\tLoss: 208.638992\n",
      "Train Epoch: 278 [12800/32031 (40%)]\tLoss: 212.161880\n",
      "Train Epoch: 278 [14080/32031 (44%)]\tLoss: 203.571945\n",
      "Train Epoch: 278 [15360/32031 (48%)]\tLoss: 202.170258\n",
      "Train Epoch: 278 [16640/32031 (52%)]\tLoss: 210.799805\n",
      "Train Epoch: 278 [17920/32031 (56%)]\tLoss: 213.264740\n",
      "Train Epoch: 278 [19200/32031 (60%)]\tLoss: 197.680847\n",
      "Train Epoch: 278 [20480/32031 (64%)]\tLoss: 194.477219\n",
      "Train Epoch: 278 [21760/32031 (68%)]\tLoss: 203.494034\n",
      "Train Epoch: 278 [23040/32031 (72%)]\tLoss: 220.098633\n",
      "Train Epoch: 278 [24320/32031 (76%)]\tLoss: 202.864655\n",
      "Train Epoch: 278 [25600/32031 (80%)]\tLoss: 188.490967\n",
      "Train Epoch: 278 [26880/32031 (84%)]\tLoss: 207.529037\n",
      "Train Epoch: 278 [28160/32031 (88%)]\tLoss: 212.314743\n",
      "Train Epoch: 278 [29440/32031 (92%)]\tLoss: 196.968964\n",
      "Train Epoch: 278 [30720/32031 (96%)]\tLoss: 206.290741\n",
      "Train Epoch: 278 [7750/32031 (100%)]\tLoss: 194.282053\n",
      "====> Epoch: 278 Average loss: 203.3364\n",
      "====> Test set loss: 198.8774\n",
      "Train Epoch: 279 [0/32031 (0%)]\tLoss: 205.103912\n",
      "Train Epoch: 279 [1280/32031 (4%)]\tLoss: 197.906464\n",
      "Train Epoch: 279 [2560/32031 (8%)]\tLoss: 206.686676\n",
      "Train Epoch: 279 [3840/32031 (12%)]\tLoss: 211.377747\n",
      "Train Epoch: 279 [5120/32031 (16%)]\tLoss: 204.535172\n",
      "Train Epoch: 279 [6400/32031 (20%)]\tLoss: 200.889420\n",
      "Train Epoch: 279 [7680/32031 (24%)]\tLoss: 206.426895\n",
      "Train Epoch: 279 [8960/32031 (28%)]\tLoss: 208.077942\n",
      "Train Epoch: 279 [10240/32031 (32%)]\tLoss: 206.082031\n",
      "Train Epoch: 279 [11520/32031 (36%)]\tLoss: 203.791656\n",
      "Train Epoch: 279 [12800/32031 (40%)]\tLoss: 189.669708\n",
      "Train Epoch: 279 [14080/32031 (44%)]\tLoss: 211.745499\n",
      "Train Epoch: 279 [15360/32031 (48%)]\tLoss: 199.593292\n",
      "Train Epoch: 279 [16640/32031 (52%)]\tLoss: 212.492493\n",
      "Train Epoch: 279 [17920/32031 (56%)]\tLoss: 204.473404\n",
      "Train Epoch: 279 [19200/32031 (60%)]\tLoss: 197.044373\n",
      "Train Epoch: 279 [20480/32031 (64%)]\tLoss: 214.408218\n",
      "Train Epoch: 279 [21760/32031 (68%)]\tLoss: 208.410416\n",
      "Train Epoch: 279 [23040/32031 (72%)]\tLoss: 207.460175\n",
      "Train Epoch: 279 [24320/32031 (76%)]\tLoss: 195.002106\n",
      "Train Epoch: 279 [25600/32031 (80%)]\tLoss: 204.552002\n",
      "Train Epoch: 279 [26880/32031 (84%)]\tLoss: 211.315430\n",
      "Train Epoch: 279 [28160/32031 (88%)]\tLoss: 199.253952\n",
      "Train Epoch: 279 [29440/32031 (92%)]\tLoss: 194.202606\n",
      "Train Epoch: 279 [30720/32031 (96%)]\tLoss: 204.070923\n",
      "Train Epoch: 279 [7750/32031 (100%)]\tLoss: 209.705094\n",
      "====> Epoch: 279 Average loss: 203.2784\n",
      "====> Test set loss: 198.7787\n",
      "Train Epoch: 280 [0/32031 (0%)]\tLoss: 187.516617\n",
      "Train Epoch: 280 [1280/32031 (4%)]\tLoss: 207.932495\n",
      "Train Epoch: 280 [2560/32031 (8%)]\tLoss: 209.353516\n",
      "Train Epoch: 280 [3840/32031 (12%)]\tLoss: 196.931870\n",
      "Train Epoch: 280 [5120/32031 (16%)]\tLoss: 200.370438\n",
      "Train Epoch: 280 [6400/32031 (20%)]\tLoss: 205.069931\n",
      "Train Epoch: 280 [7680/32031 (24%)]\tLoss: 205.603531\n",
      "Train Epoch: 280 [8960/32031 (28%)]\tLoss: 197.179260\n",
      "Train Epoch: 280 [10240/32031 (32%)]\tLoss: 203.021820\n",
      "Train Epoch: 280 [11520/32031 (36%)]\tLoss: 203.721588\n",
      "Train Epoch: 280 [12800/32031 (40%)]\tLoss: 188.730469\n",
      "Train Epoch: 280 [14080/32031 (44%)]\tLoss: 204.093735\n",
      "Train Epoch: 280 [15360/32031 (48%)]\tLoss: 202.226547\n",
      "Train Epoch: 280 [16640/32031 (52%)]\tLoss: 203.869385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 280 [17920/32031 (56%)]\tLoss: 202.478500\n",
      "Train Epoch: 280 [19200/32031 (60%)]\tLoss: 207.844803\n",
      "Train Epoch: 280 [20480/32031 (64%)]\tLoss: 214.381561\n",
      "Train Epoch: 280 [21760/32031 (68%)]\tLoss: 206.157043\n",
      "Train Epoch: 280 [23040/32031 (72%)]\tLoss: 205.779678\n",
      "Train Epoch: 280 [24320/32031 (76%)]\tLoss: 203.149567\n",
      "Train Epoch: 280 [25600/32031 (80%)]\tLoss: 201.864914\n",
      "Train Epoch: 280 [26880/32031 (84%)]\tLoss: 209.634354\n",
      "Train Epoch: 280 [28160/32031 (88%)]\tLoss: 199.389587\n",
      "Train Epoch: 280 [29440/32031 (92%)]\tLoss: 215.183044\n",
      "Train Epoch: 280 [30720/32031 (96%)]\tLoss: 210.058914\n",
      "Train Epoch: 280 [7750/32031 (100%)]\tLoss: 187.831905\n",
      "====> Epoch: 280 Average loss: 203.5376\n",
      "====> Test set loss: 199.8368\n",
      "Train Epoch: 281 [0/32031 (0%)]\tLoss: 210.759079\n",
      "Train Epoch: 281 [1280/32031 (4%)]\tLoss: 213.273529\n",
      "Train Epoch: 281 [2560/32031 (8%)]\tLoss: 217.206375\n",
      "Train Epoch: 281 [3840/32031 (12%)]\tLoss: 207.429794\n",
      "Train Epoch: 281 [5120/32031 (16%)]\tLoss: 202.861557\n",
      "Train Epoch: 281 [6400/32031 (20%)]\tLoss: 193.734283\n",
      "Train Epoch: 281 [7680/32031 (24%)]\tLoss: 195.019547\n",
      "Train Epoch: 281 [8960/32031 (28%)]\tLoss: 201.475098\n",
      "Train Epoch: 281 [10240/32031 (32%)]\tLoss: 203.804443\n",
      "Train Epoch: 281 [11520/32031 (36%)]\tLoss: 195.209061\n",
      "Train Epoch: 281 [12800/32031 (40%)]\tLoss: 203.528839\n",
      "Train Epoch: 281 [14080/32031 (44%)]\tLoss: 198.968353\n",
      "Train Epoch: 281 [15360/32031 (48%)]\tLoss: 203.769150\n",
      "Train Epoch: 281 [16640/32031 (52%)]\tLoss: 206.649368\n",
      "Train Epoch: 281 [17920/32031 (56%)]\tLoss: 201.352051\n",
      "Train Epoch: 281 [19200/32031 (60%)]\tLoss: 217.341110\n",
      "Train Epoch: 281 [20480/32031 (64%)]\tLoss: 216.491974\n",
      "Train Epoch: 281 [21760/32031 (68%)]\tLoss: 204.252472\n",
      "Train Epoch: 281 [23040/32031 (72%)]\tLoss: 205.049698\n",
      "Train Epoch: 281 [24320/32031 (76%)]\tLoss: 208.141479\n",
      "Train Epoch: 281 [25600/32031 (80%)]\tLoss: 201.734314\n",
      "Train Epoch: 281 [26880/32031 (84%)]\tLoss: 206.945724\n",
      "Train Epoch: 281 [28160/32031 (88%)]\tLoss: 207.188354\n",
      "Train Epoch: 281 [29440/32031 (92%)]\tLoss: 218.724213\n",
      "Train Epoch: 281 [30720/32031 (96%)]\tLoss: 188.093292\n",
      "Train Epoch: 281 [7750/32031 (100%)]\tLoss: 204.190776\n",
      "====> Epoch: 281 Average loss: 203.7724\n",
      "====> Test set loss: 196.2309\n",
      "Train Epoch: 282 [0/32031 (0%)]\tLoss: 195.782272\n",
      "Train Epoch: 282 [1280/32031 (4%)]\tLoss: 197.246277\n",
      "Train Epoch: 282 [2560/32031 (8%)]\tLoss: 197.213806\n",
      "Train Epoch: 282 [3840/32031 (12%)]\tLoss: 208.233170\n",
      "Train Epoch: 282 [5120/32031 (16%)]\tLoss: 206.962769\n",
      "Train Epoch: 282 [6400/32031 (20%)]\tLoss: 207.650787\n",
      "Train Epoch: 282 [7680/32031 (24%)]\tLoss: 203.441803\n",
      "Train Epoch: 282 [8960/32031 (28%)]\tLoss: 199.656570\n",
      "Train Epoch: 282 [10240/32031 (32%)]\tLoss: 204.108612\n",
      "Train Epoch: 282 [11520/32031 (36%)]\tLoss: 200.427536\n",
      "Train Epoch: 282 [12800/32031 (40%)]\tLoss: 199.190536\n",
      "Train Epoch: 282 [14080/32031 (44%)]\tLoss: 200.196991\n",
      "Train Epoch: 282 [15360/32031 (48%)]\tLoss: 204.475220\n",
      "Train Epoch: 282 [16640/32031 (52%)]\tLoss: 209.064346\n",
      "Train Epoch: 282 [17920/32031 (56%)]\tLoss: 212.951080\n",
      "Train Epoch: 282 [19200/32031 (60%)]\tLoss: 214.680328\n",
      "Train Epoch: 282 [20480/32031 (64%)]\tLoss: 206.057571\n",
      "Train Epoch: 282 [21760/32031 (68%)]\tLoss: 195.954712\n",
      "Train Epoch: 282 [23040/32031 (72%)]\tLoss: 198.729889\n",
      "Train Epoch: 282 [24320/32031 (76%)]\tLoss: 205.556061\n",
      "Train Epoch: 282 [25600/32031 (80%)]\tLoss: 193.616028\n",
      "Train Epoch: 282 [26880/32031 (84%)]\tLoss: 202.335938\n",
      "Train Epoch: 282 [28160/32031 (88%)]\tLoss: 198.198853\n",
      "Train Epoch: 282 [29440/32031 (92%)]\tLoss: 208.570511\n",
      "Train Epoch: 282 [30720/32031 (96%)]\tLoss: 201.690002\n",
      "Train Epoch: 282 [7750/32031 (100%)]\tLoss: 208.751481\n",
      "====> Epoch: 282 Average loss: 203.1395\n",
      "====> Test set loss: 198.3470\n",
      "Train Epoch: 283 [0/32031 (0%)]\tLoss: 205.742859\n",
      "Train Epoch: 283 [1280/32031 (4%)]\tLoss: 203.518478\n",
      "Train Epoch: 283 [2560/32031 (8%)]\tLoss: 199.790588\n",
      "Train Epoch: 283 [3840/32031 (12%)]\tLoss: 203.242264\n",
      "Train Epoch: 283 [5120/32031 (16%)]\tLoss: 199.611786\n",
      "Train Epoch: 283 [6400/32031 (20%)]\tLoss: 220.315903\n",
      "Train Epoch: 283 [7680/32031 (24%)]\tLoss: 200.711594\n",
      "Train Epoch: 283 [8960/32031 (28%)]\tLoss: 192.195862\n",
      "Train Epoch: 283 [10240/32031 (32%)]\tLoss: 203.864853\n",
      "Train Epoch: 283 [11520/32031 (36%)]\tLoss: 189.583557\n",
      "Train Epoch: 283 [12800/32031 (40%)]\tLoss: 196.438858\n",
      "Train Epoch: 283 [14080/32031 (44%)]\tLoss: 197.296814\n",
      "Train Epoch: 283 [15360/32031 (48%)]\tLoss: 202.415634\n",
      "Train Epoch: 283 [16640/32031 (52%)]\tLoss: 200.321564\n",
      "Train Epoch: 283 [17920/32031 (56%)]\tLoss: 202.060471\n",
      "Train Epoch: 283 [19200/32031 (60%)]\tLoss: 207.258087\n",
      "Train Epoch: 283 [20480/32031 (64%)]\tLoss: 205.379929\n",
      "Train Epoch: 283 [21760/32031 (68%)]\tLoss: 204.740021\n",
      "Train Epoch: 283 [23040/32031 (72%)]\tLoss: 200.474075\n",
      "Train Epoch: 283 [24320/32031 (76%)]\tLoss: 214.188202\n",
      "Train Epoch: 283 [25600/32031 (80%)]\tLoss: 208.234436\n",
      "Train Epoch: 283 [26880/32031 (84%)]\tLoss: 208.993958\n",
      "Train Epoch: 283 [28160/32031 (88%)]\tLoss: 198.763077\n",
      "Train Epoch: 283 [29440/32031 (92%)]\tLoss: 209.509979\n",
      "Train Epoch: 283 [30720/32031 (96%)]\tLoss: 207.173828\n",
      "Train Epoch: 283 [7750/32031 (100%)]\tLoss: 184.665417\n",
      "====> Epoch: 283 Average loss: 203.5736\n",
      "====> Test set loss: 197.6509\n",
      "Train Epoch: 284 [0/32031 (0%)]\tLoss: 201.539658\n",
      "Train Epoch: 284 [1280/32031 (4%)]\tLoss: 203.141235\n",
      "Train Epoch: 284 [2560/32031 (8%)]\tLoss: 205.235382\n",
      "Train Epoch: 284 [3840/32031 (12%)]\tLoss: 217.527191\n",
      "Train Epoch: 284 [5120/32031 (16%)]\tLoss: 197.472397\n",
      "Train Epoch: 284 [6400/32031 (20%)]\tLoss: 208.261108\n",
      "Train Epoch: 284 [7680/32031 (24%)]\tLoss: 189.602737\n",
      "Train Epoch: 284 [8960/32031 (28%)]\tLoss: 204.115723\n",
      "Train Epoch: 284 [10240/32031 (32%)]\tLoss: 211.076385\n",
      "Train Epoch: 284 [11520/32031 (36%)]\tLoss: 220.175110\n",
      "Train Epoch: 284 [12800/32031 (40%)]\tLoss: 223.593643\n",
      "Train Epoch: 284 [14080/32031 (44%)]\tLoss: 199.043564\n",
      "Train Epoch: 284 [15360/32031 (48%)]\tLoss: 204.915451\n",
      "Train Epoch: 284 [16640/32031 (52%)]\tLoss: 199.875824\n",
      "Train Epoch: 284 [17920/32031 (56%)]\tLoss: 201.504562\n",
      "Train Epoch: 284 [19200/32031 (60%)]\tLoss: 210.982605\n",
      "Train Epoch: 284 [20480/32031 (64%)]\tLoss: 198.407028\n",
      "Train Epoch: 284 [21760/32031 (68%)]\tLoss: 203.943054\n",
      "Train Epoch: 284 [23040/32031 (72%)]\tLoss: 197.743805\n",
      "Train Epoch: 284 [24320/32031 (76%)]\tLoss: 215.524765\n",
      "Train Epoch: 284 [25600/32031 (80%)]\tLoss: 196.934036\n",
      "Train Epoch: 284 [26880/32031 (84%)]\tLoss: 202.206818\n",
      "Train Epoch: 284 [28160/32031 (88%)]\tLoss: 202.873825\n",
      "Train Epoch: 284 [29440/32031 (92%)]\tLoss: 198.576523\n",
      "Train Epoch: 284 [30720/32031 (96%)]\tLoss: 207.149857\n",
      "Train Epoch: 284 [7750/32031 (100%)]\tLoss: 219.646988\n",
      "====> Epoch: 284 Average loss: 203.4182\n",
      "====> Test set loss: 197.3774\n",
      "Train Epoch: 285 [0/32031 (0%)]\tLoss: 194.960709\n",
      "Train Epoch: 285 [1280/32031 (4%)]\tLoss: 197.700104\n",
      "Train Epoch: 285 [2560/32031 (8%)]\tLoss: 200.207062\n",
      "Train Epoch: 285 [3840/32031 (12%)]\tLoss: 206.355606\n",
      "Train Epoch: 285 [5120/32031 (16%)]\tLoss: 194.114166\n",
      "Train Epoch: 285 [6400/32031 (20%)]\tLoss: 209.817627\n",
      "Train Epoch: 285 [7680/32031 (24%)]\tLoss: 209.797729\n",
      "Train Epoch: 285 [8960/32031 (28%)]\tLoss: 209.850830\n",
      "Train Epoch: 285 [10240/32031 (32%)]\tLoss: 212.623627\n",
      "Train Epoch: 285 [11520/32031 (36%)]\tLoss: 203.907776\n",
      "Train Epoch: 285 [12800/32031 (40%)]\tLoss: 194.497253\n",
      "Train Epoch: 285 [14080/32031 (44%)]\tLoss: 200.262253\n",
      "Train Epoch: 285 [15360/32031 (48%)]\tLoss: 204.043167\n",
      "Train Epoch: 285 [16640/32031 (52%)]\tLoss: 205.534180\n",
      "Train Epoch: 285 [17920/32031 (56%)]\tLoss: 203.354797\n",
      "Train Epoch: 285 [19200/32031 (60%)]\tLoss: 210.923386\n",
      "Train Epoch: 285 [20480/32031 (64%)]\tLoss: 198.156586\n",
      "Train Epoch: 285 [21760/32031 (68%)]\tLoss: 204.103882\n",
      "Train Epoch: 285 [23040/32031 (72%)]\tLoss: 212.215714\n",
      "Train Epoch: 285 [24320/32031 (76%)]\tLoss: 191.125305\n",
      "Train Epoch: 285 [25600/32031 (80%)]\tLoss: 203.254944\n",
      "Train Epoch: 285 [26880/32031 (84%)]\tLoss: 209.393524\n",
      "Train Epoch: 285 [28160/32031 (88%)]\tLoss: 202.290909\n",
      "Train Epoch: 285 [29440/32031 (92%)]\tLoss: 200.781723\n",
      "Train Epoch: 285 [30720/32031 (96%)]\tLoss: 199.365204\n",
      "Train Epoch: 285 [7750/32031 (100%)]\tLoss: 210.378686\n",
      "====> Epoch: 285 Average loss: 203.2602\n",
      "====> Test set loss: 196.8402\n",
      "Train Epoch: 286 [0/32031 (0%)]\tLoss: 200.028000\n",
      "Train Epoch: 286 [1280/32031 (4%)]\tLoss: 195.474945\n",
      "Train Epoch: 286 [2560/32031 (8%)]\tLoss: 201.239609\n",
      "Train Epoch: 286 [3840/32031 (12%)]\tLoss: 218.853149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 286 [5120/32031 (16%)]\tLoss: 220.395187\n",
      "Train Epoch: 286 [6400/32031 (20%)]\tLoss: 195.981400\n",
      "Train Epoch: 286 [7680/32031 (24%)]\tLoss: 190.651215\n",
      "Train Epoch: 286 [8960/32031 (28%)]\tLoss: 194.787766\n",
      "Train Epoch: 286 [10240/32031 (32%)]\tLoss: 192.481613\n",
      "Train Epoch: 286 [11520/32031 (36%)]\tLoss: 205.239914\n",
      "Train Epoch: 286 [12800/32031 (40%)]\tLoss: 201.321243\n",
      "Train Epoch: 286 [14080/32031 (44%)]\tLoss: 204.224609\n",
      "Train Epoch: 286 [15360/32031 (48%)]\tLoss: 198.795303\n",
      "Train Epoch: 286 [16640/32031 (52%)]\tLoss: 209.563904\n",
      "Train Epoch: 286 [17920/32031 (56%)]\tLoss: 212.175797\n",
      "Train Epoch: 286 [19200/32031 (60%)]\tLoss: 203.879074\n",
      "Train Epoch: 286 [20480/32031 (64%)]\tLoss: 200.653397\n",
      "Train Epoch: 286 [21760/32031 (68%)]\tLoss: 211.236435\n",
      "Train Epoch: 286 [23040/32031 (72%)]\tLoss: 212.329758\n",
      "Train Epoch: 286 [24320/32031 (76%)]\tLoss: 212.703476\n",
      "Train Epoch: 286 [25600/32031 (80%)]\tLoss: 213.233139\n",
      "Train Epoch: 286 [26880/32031 (84%)]\tLoss: 205.433365\n",
      "Train Epoch: 286 [28160/32031 (88%)]\tLoss: 199.935730\n",
      "Train Epoch: 286 [29440/32031 (92%)]\tLoss: 197.571533\n",
      "Train Epoch: 286 [30720/32031 (96%)]\tLoss: 194.816650\n",
      "Train Epoch: 286 [7750/32031 (100%)]\tLoss: 201.274304\n",
      "====> Epoch: 286 Average loss: 203.5302\n",
      "====> Test set loss: 196.9290\n",
      "Train Epoch: 287 [0/32031 (0%)]\tLoss: 207.144241\n",
      "Train Epoch: 287 [1280/32031 (4%)]\tLoss: 193.888000\n",
      "Train Epoch: 287 [2560/32031 (8%)]\tLoss: 206.491638\n",
      "Train Epoch: 287 [3840/32031 (12%)]\tLoss: 210.963028\n",
      "Train Epoch: 287 [5120/32031 (16%)]\tLoss: 191.356491\n",
      "Train Epoch: 287 [6400/32031 (20%)]\tLoss: 202.828232\n",
      "Train Epoch: 287 [7680/32031 (24%)]\tLoss: 212.007538\n",
      "Train Epoch: 287 [8960/32031 (28%)]\tLoss: 202.405182\n",
      "Train Epoch: 287 [10240/32031 (32%)]\tLoss: 211.533173\n",
      "Train Epoch: 287 [11520/32031 (36%)]\tLoss: 202.907120\n",
      "Train Epoch: 287 [12800/32031 (40%)]\tLoss: 202.535217\n",
      "Train Epoch: 287 [14080/32031 (44%)]\tLoss: 196.378174\n",
      "Train Epoch: 287 [15360/32031 (48%)]\tLoss: 202.172272\n",
      "Train Epoch: 287 [16640/32031 (52%)]\tLoss: 201.338684\n",
      "Train Epoch: 287 [17920/32031 (56%)]\tLoss: 207.384689\n",
      "Train Epoch: 287 [19200/32031 (60%)]\tLoss: 196.870514\n",
      "Train Epoch: 287 [20480/32031 (64%)]\tLoss: 209.441055\n",
      "Train Epoch: 287 [21760/32031 (68%)]\tLoss: 190.219299\n",
      "Train Epoch: 287 [23040/32031 (72%)]\tLoss: 195.331345\n",
      "Train Epoch: 287 [24320/32031 (76%)]\tLoss: 199.858826\n",
      "Train Epoch: 287 [25600/32031 (80%)]\tLoss: 207.198639\n",
      "Train Epoch: 287 [26880/32031 (84%)]\tLoss: 209.303528\n",
      "Train Epoch: 287 [28160/32031 (88%)]\tLoss: 197.153793\n",
      "Train Epoch: 287 [29440/32031 (92%)]\tLoss: 202.395782\n",
      "Train Epoch: 287 [30720/32031 (96%)]\tLoss: 197.431870\n",
      "Train Epoch: 287 [7750/32031 (100%)]\tLoss: 216.241274\n",
      "====> Epoch: 287 Average loss: 203.4544\n",
      "====> Test set loss: 198.3167\n",
      "Train Epoch: 288 [0/32031 (0%)]\tLoss: 205.460327\n",
      "Train Epoch: 288 [1280/32031 (4%)]\tLoss: 191.622772\n",
      "Train Epoch: 288 [2560/32031 (8%)]\tLoss: 207.015411\n",
      "Train Epoch: 288 [3840/32031 (12%)]\tLoss: 200.804489\n",
      "Train Epoch: 288 [5120/32031 (16%)]\tLoss: 207.835297\n",
      "Train Epoch: 288 [6400/32031 (20%)]\tLoss: 206.273621\n",
      "Train Epoch: 288 [7680/32031 (24%)]\tLoss: 200.465744\n",
      "Train Epoch: 288 [8960/32031 (28%)]\tLoss: 196.705521\n",
      "Train Epoch: 288 [10240/32031 (32%)]\tLoss: 195.841202\n",
      "Train Epoch: 288 [11520/32031 (36%)]\tLoss: 202.517975\n",
      "Train Epoch: 288 [12800/32031 (40%)]\tLoss: 196.691010\n",
      "Train Epoch: 288 [14080/32031 (44%)]\tLoss: 210.610275\n",
      "Train Epoch: 288 [15360/32031 (48%)]\tLoss: 195.978577\n",
      "Train Epoch: 288 [16640/32031 (52%)]\tLoss: 214.941269\n",
      "Train Epoch: 288 [17920/32031 (56%)]\tLoss: 210.167419\n",
      "Train Epoch: 288 [19200/32031 (60%)]\tLoss: 198.129745\n",
      "Train Epoch: 288 [20480/32031 (64%)]\tLoss: 196.623413\n",
      "Train Epoch: 288 [21760/32031 (68%)]\tLoss: 206.486557\n",
      "Train Epoch: 288 [23040/32031 (72%)]\tLoss: 203.238495\n",
      "Train Epoch: 288 [24320/32031 (76%)]\tLoss: 199.400024\n",
      "Train Epoch: 288 [25600/32031 (80%)]\tLoss: 199.778976\n",
      "Train Epoch: 288 [26880/32031 (84%)]\tLoss: 199.624130\n",
      "Train Epoch: 288 [28160/32031 (88%)]\tLoss: 205.108459\n",
      "Train Epoch: 288 [29440/32031 (92%)]\tLoss: 196.497375\n",
      "Train Epoch: 288 [30720/32031 (96%)]\tLoss: 206.039062\n",
      "Train Epoch: 288 [7750/32031 (100%)]\tLoss: 223.897319\n",
      "====> Epoch: 288 Average loss: 203.6065\n",
      "====> Test set loss: 196.5107\n",
      "Train Epoch: 289 [0/32031 (0%)]\tLoss: 198.031952\n",
      "Train Epoch: 289 [1280/32031 (4%)]\tLoss: 188.580460\n",
      "Train Epoch: 289 [2560/32031 (8%)]\tLoss: 215.055450\n",
      "Train Epoch: 289 [3840/32031 (12%)]\tLoss: 209.602798\n",
      "Train Epoch: 289 [5120/32031 (16%)]\tLoss: 209.159805\n",
      "Train Epoch: 289 [6400/32031 (20%)]\tLoss: 192.173599\n",
      "Train Epoch: 289 [7680/32031 (24%)]\tLoss: 196.377136\n",
      "Train Epoch: 289 [8960/32031 (28%)]\tLoss: 207.924911\n",
      "Train Epoch: 289 [10240/32031 (32%)]\tLoss: 212.967209\n",
      "Train Epoch: 289 [11520/32031 (36%)]\tLoss: 207.356049\n",
      "Train Epoch: 289 [12800/32031 (40%)]\tLoss: 204.167191\n",
      "Train Epoch: 289 [14080/32031 (44%)]\tLoss: 197.433121\n",
      "Train Epoch: 289 [15360/32031 (48%)]\tLoss: 215.146896\n",
      "Train Epoch: 289 [16640/32031 (52%)]\tLoss: 199.564835\n",
      "Train Epoch: 289 [17920/32031 (56%)]\tLoss: 209.333511\n",
      "Train Epoch: 289 [19200/32031 (60%)]\tLoss: 210.292160\n",
      "Train Epoch: 289 [20480/32031 (64%)]\tLoss: 213.569351\n",
      "Train Epoch: 289 [21760/32031 (68%)]\tLoss: 200.432312\n",
      "Train Epoch: 289 [23040/32031 (72%)]\tLoss: 206.185669\n",
      "Train Epoch: 289 [24320/32031 (76%)]\tLoss: 209.742325\n",
      "Train Epoch: 289 [25600/32031 (80%)]\tLoss: 212.632263\n",
      "Train Epoch: 289 [26880/32031 (84%)]\tLoss: 204.534836\n",
      "Train Epoch: 289 [28160/32031 (88%)]\tLoss: 205.475342\n",
      "Train Epoch: 289 [29440/32031 (92%)]\tLoss: 199.721695\n",
      "Train Epoch: 289 [30720/32031 (96%)]\tLoss: 201.708984\n",
      "Train Epoch: 289 [7750/32031 (100%)]\tLoss: 191.337198\n",
      "====> Epoch: 289 Average loss: 203.4126\n",
      "====> Test set loss: 200.6701\n",
      "Train Epoch: 290 [0/32031 (0%)]\tLoss: 211.034805\n",
      "Train Epoch: 290 [1280/32031 (4%)]\tLoss: 198.241043\n",
      "Train Epoch: 290 [2560/32031 (8%)]\tLoss: 210.887573\n",
      "Train Epoch: 290 [3840/32031 (12%)]\tLoss: 218.654907\n",
      "Train Epoch: 290 [5120/32031 (16%)]\tLoss: 199.905777\n",
      "Train Epoch: 290 [6400/32031 (20%)]\tLoss: 206.101898\n",
      "Train Epoch: 290 [7680/32031 (24%)]\tLoss: 207.817963\n",
      "Train Epoch: 290 [8960/32031 (28%)]\tLoss: 196.109528\n",
      "Train Epoch: 290 [10240/32031 (32%)]\tLoss: 206.862564\n",
      "Train Epoch: 290 [11520/32031 (36%)]\tLoss: 198.242172\n",
      "Train Epoch: 290 [12800/32031 (40%)]\tLoss: 201.046036\n",
      "Train Epoch: 290 [14080/32031 (44%)]\tLoss: 195.387360\n",
      "Train Epoch: 290 [15360/32031 (48%)]\tLoss: 192.206573\n",
      "Train Epoch: 290 [16640/32031 (52%)]\tLoss: 192.681061\n",
      "Train Epoch: 290 [17920/32031 (56%)]\tLoss: 211.629883\n",
      "Train Epoch: 290 [19200/32031 (60%)]\tLoss: 194.010391\n",
      "Train Epoch: 290 [20480/32031 (64%)]\tLoss: 204.356232\n",
      "Train Epoch: 290 [21760/32031 (68%)]\tLoss: 205.440887\n",
      "Train Epoch: 290 [23040/32031 (72%)]\tLoss: 202.861481\n",
      "Train Epoch: 290 [24320/32031 (76%)]\tLoss: 202.646622\n",
      "Train Epoch: 290 [25600/32031 (80%)]\tLoss: 206.968414\n",
      "Train Epoch: 290 [26880/32031 (84%)]\tLoss: 204.449905\n",
      "Train Epoch: 290 [28160/32031 (88%)]\tLoss: 206.933777\n",
      "Train Epoch: 290 [29440/32031 (92%)]\tLoss: 203.511475\n",
      "Train Epoch: 290 [30720/32031 (96%)]\tLoss: 200.724670\n",
      "Train Epoch: 290 [7750/32031 (100%)]\tLoss: 208.096081\n",
      "====> Epoch: 290 Average loss: 203.5543\n",
      "====> Test set loss: 198.4745\n",
      "Train Epoch: 291 [0/32031 (0%)]\tLoss: 200.055649\n",
      "Train Epoch: 291 [1280/32031 (4%)]\tLoss: 197.739502\n",
      "Train Epoch: 291 [2560/32031 (8%)]\tLoss: 202.669983\n",
      "Train Epoch: 291 [3840/32031 (12%)]\tLoss: 195.386368\n",
      "Train Epoch: 291 [5120/32031 (16%)]\tLoss: 206.274567\n",
      "Train Epoch: 291 [6400/32031 (20%)]\tLoss: 201.694366\n",
      "Train Epoch: 291 [7680/32031 (24%)]\tLoss: 201.782333\n",
      "Train Epoch: 291 [8960/32031 (28%)]\tLoss: 200.132156\n",
      "Train Epoch: 291 [10240/32031 (32%)]\tLoss: 195.064728\n",
      "Train Epoch: 291 [11520/32031 (36%)]\tLoss: 202.129608\n",
      "Train Epoch: 291 [12800/32031 (40%)]\tLoss: 204.002060\n",
      "Train Epoch: 291 [14080/32031 (44%)]\tLoss: 205.008682\n",
      "Train Epoch: 291 [15360/32031 (48%)]\tLoss: 192.296127\n",
      "Train Epoch: 291 [16640/32031 (52%)]\tLoss: 203.772034\n",
      "Train Epoch: 291 [17920/32031 (56%)]\tLoss: 192.514969\n",
      "Train Epoch: 291 [19200/32031 (60%)]\tLoss: 206.180725\n",
      "Train Epoch: 291 [20480/32031 (64%)]\tLoss: 203.679611\n",
      "Train Epoch: 291 [21760/32031 (68%)]\tLoss: 206.378464\n",
      "Train Epoch: 291 [23040/32031 (72%)]\tLoss: 214.016846\n",
      "Train Epoch: 291 [24320/32031 (76%)]\tLoss: 200.455658\n",
      "Train Epoch: 291 [25600/32031 (80%)]\tLoss: 196.771957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 291 [26880/32031 (84%)]\tLoss: 217.987213\n",
      "Train Epoch: 291 [28160/32031 (88%)]\tLoss: 207.955627\n",
      "Train Epoch: 291 [29440/32031 (92%)]\tLoss: 211.386490\n",
      "Train Epoch: 291 [30720/32031 (96%)]\tLoss: 209.210388\n",
      "Train Epoch: 291 [7750/32031 (100%)]\tLoss: 236.624575\n",
      "====> Epoch: 291 Average loss: 203.0458\n",
      "====> Test set loss: 199.0848\n",
      "Train Epoch: 292 [0/32031 (0%)]\tLoss: 198.791916\n",
      "Train Epoch: 292 [1280/32031 (4%)]\tLoss: 196.468353\n",
      "Train Epoch: 292 [2560/32031 (8%)]\tLoss: 196.292114\n",
      "Train Epoch: 292 [3840/32031 (12%)]\tLoss: 209.282852\n",
      "Train Epoch: 292 [5120/32031 (16%)]\tLoss: 204.594559\n",
      "Train Epoch: 292 [6400/32031 (20%)]\tLoss: 217.146286\n",
      "Train Epoch: 292 [7680/32031 (24%)]\tLoss: 194.314850\n",
      "Train Epoch: 292 [8960/32031 (28%)]\tLoss: 194.988739\n",
      "Train Epoch: 292 [10240/32031 (32%)]\tLoss: 209.057922\n",
      "Train Epoch: 292 [11520/32031 (36%)]\tLoss: 196.203934\n",
      "Train Epoch: 292 [12800/32031 (40%)]\tLoss: 206.441055\n",
      "Train Epoch: 292 [14080/32031 (44%)]\tLoss: 204.132446\n",
      "Train Epoch: 292 [15360/32031 (48%)]\tLoss: 198.802139\n",
      "Train Epoch: 292 [16640/32031 (52%)]\tLoss: 200.875137\n",
      "Train Epoch: 292 [17920/32031 (56%)]\tLoss: 206.137070\n",
      "Train Epoch: 292 [19200/32031 (60%)]\tLoss: 209.218307\n",
      "Train Epoch: 292 [20480/32031 (64%)]\tLoss: 202.455948\n",
      "Train Epoch: 292 [21760/32031 (68%)]\tLoss: 203.962036\n",
      "Train Epoch: 292 [23040/32031 (72%)]\tLoss: 204.145676\n",
      "Train Epoch: 292 [24320/32031 (76%)]\tLoss: 208.994080\n",
      "Train Epoch: 292 [25600/32031 (80%)]\tLoss: 197.746536\n",
      "Train Epoch: 292 [26880/32031 (84%)]\tLoss: 204.266754\n",
      "Train Epoch: 292 [28160/32031 (88%)]\tLoss: 194.976074\n",
      "Train Epoch: 292 [29440/32031 (92%)]\tLoss: 194.051483\n",
      "Train Epoch: 292 [30720/32031 (96%)]\tLoss: 211.026367\n",
      "Train Epoch: 292 [7750/32031 (100%)]\tLoss: 210.757765\n",
      "====> Epoch: 292 Average loss: 203.3259\n",
      "====> Test set loss: 198.1781\n",
      "Train Epoch: 293 [0/32031 (0%)]\tLoss: 197.989288\n",
      "Train Epoch: 293 [1280/32031 (4%)]\tLoss: 202.060883\n",
      "Train Epoch: 293 [2560/32031 (8%)]\tLoss: 195.026550\n",
      "Train Epoch: 293 [3840/32031 (12%)]\tLoss: 197.257004\n",
      "Train Epoch: 293 [5120/32031 (16%)]\tLoss: 204.492615\n",
      "Train Epoch: 293 [6400/32031 (20%)]\tLoss: 195.429321\n",
      "Train Epoch: 293 [7680/32031 (24%)]\tLoss: 202.017029\n",
      "Train Epoch: 293 [8960/32031 (28%)]\tLoss: 192.505508\n",
      "Train Epoch: 293 [10240/32031 (32%)]\tLoss: 194.063171\n",
      "Train Epoch: 293 [11520/32031 (36%)]\tLoss: 200.311859\n",
      "Train Epoch: 293 [12800/32031 (40%)]\tLoss: 205.353729\n",
      "Train Epoch: 293 [14080/32031 (44%)]\tLoss: 214.367111\n",
      "Train Epoch: 293 [15360/32031 (48%)]\tLoss: 205.340912\n",
      "Train Epoch: 293 [16640/32031 (52%)]\tLoss: 207.016922\n",
      "Train Epoch: 293 [17920/32031 (56%)]\tLoss: 212.127686\n",
      "Train Epoch: 293 [19200/32031 (60%)]\tLoss: 212.262085\n",
      "Train Epoch: 293 [20480/32031 (64%)]\tLoss: 208.846954\n",
      "Train Epoch: 293 [21760/32031 (68%)]\tLoss: 206.635513\n",
      "Train Epoch: 293 [23040/32031 (72%)]\tLoss: 195.609680\n",
      "Train Epoch: 293 [24320/32031 (76%)]\tLoss: 208.810211\n",
      "Train Epoch: 293 [25600/32031 (80%)]\tLoss: 217.803207\n",
      "Train Epoch: 293 [26880/32031 (84%)]\tLoss: 199.242279\n",
      "Train Epoch: 293 [28160/32031 (88%)]\tLoss: 197.726288\n",
      "Train Epoch: 293 [29440/32031 (92%)]\tLoss: 204.670624\n",
      "Train Epoch: 293 [30720/32031 (96%)]\tLoss: 214.810638\n",
      "Train Epoch: 293 [7750/32031 (100%)]\tLoss: 200.810956\n",
      "====> Epoch: 293 Average loss: 203.3666\n",
      "====> Test set loss: 197.1352\n",
      "Train Epoch: 294 [0/32031 (0%)]\tLoss: 205.376251\n",
      "Train Epoch: 294 [1280/32031 (4%)]\tLoss: 200.632858\n",
      "Train Epoch: 294 [2560/32031 (8%)]\tLoss: 206.031311\n",
      "Train Epoch: 294 [3840/32031 (12%)]\tLoss: 202.359589\n",
      "Train Epoch: 294 [5120/32031 (16%)]\tLoss: 205.224335\n",
      "Train Epoch: 294 [6400/32031 (20%)]\tLoss: 202.199646\n",
      "Train Epoch: 294 [7680/32031 (24%)]\tLoss: 205.058640\n",
      "Train Epoch: 294 [8960/32031 (28%)]\tLoss: 195.423981\n",
      "Train Epoch: 294 [10240/32031 (32%)]\tLoss: 215.197937\n",
      "Train Epoch: 294 [11520/32031 (36%)]\tLoss: 208.420395\n",
      "Train Epoch: 294 [12800/32031 (40%)]\tLoss: 204.670044\n",
      "Train Epoch: 294 [14080/32031 (44%)]\tLoss: 208.275436\n",
      "Train Epoch: 294 [15360/32031 (48%)]\tLoss: 200.319458\n",
      "Train Epoch: 294 [16640/32031 (52%)]\tLoss: 203.959747\n",
      "Train Epoch: 294 [17920/32031 (56%)]\tLoss: 204.775787\n",
      "Train Epoch: 294 [19200/32031 (60%)]\tLoss: 204.540970\n",
      "Train Epoch: 294 [20480/32031 (64%)]\tLoss: 194.164444\n",
      "Train Epoch: 294 [21760/32031 (68%)]\tLoss: 208.267883\n",
      "Train Epoch: 294 [23040/32031 (72%)]\tLoss: 194.354401\n",
      "Train Epoch: 294 [24320/32031 (76%)]\tLoss: 200.646774\n",
      "Train Epoch: 294 [25600/32031 (80%)]\tLoss: 210.092590\n",
      "Train Epoch: 294 [26880/32031 (84%)]\tLoss: 212.706024\n",
      "Train Epoch: 294 [28160/32031 (88%)]\tLoss: 209.088425\n",
      "Train Epoch: 294 [29440/32031 (92%)]\tLoss: 204.699966\n",
      "Train Epoch: 294 [30720/32031 (96%)]\tLoss: 210.799835\n",
      "Train Epoch: 294 [7750/32031 (100%)]\tLoss: 228.068438\n",
      "====> Epoch: 294 Average loss: 203.5073\n",
      "====> Test set loss: 197.8107\n",
      "Train Epoch: 295 [0/32031 (0%)]\tLoss: 204.776154\n",
      "Train Epoch: 295 [1280/32031 (4%)]\tLoss: 190.444046\n",
      "Train Epoch: 295 [2560/32031 (8%)]\tLoss: 205.999863\n",
      "Train Epoch: 295 [3840/32031 (12%)]\tLoss: 216.362091\n",
      "Train Epoch: 295 [5120/32031 (16%)]\tLoss: 218.210571\n",
      "Train Epoch: 295 [6400/32031 (20%)]\tLoss: 192.935669\n",
      "Train Epoch: 295 [7680/32031 (24%)]\tLoss: 205.530487\n",
      "Train Epoch: 295 [8960/32031 (28%)]\tLoss: 203.808640\n",
      "Train Epoch: 295 [10240/32031 (32%)]\tLoss: 206.571228\n",
      "Train Epoch: 295 [11520/32031 (36%)]\tLoss: 194.852097\n",
      "Train Epoch: 295 [12800/32031 (40%)]\tLoss: 207.587631\n",
      "Train Epoch: 295 [14080/32031 (44%)]\tLoss: 201.404404\n",
      "Train Epoch: 295 [15360/32031 (48%)]\tLoss: 195.747162\n",
      "Train Epoch: 295 [16640/32031 (52%)]\tLoss: 199.237427\n",
      "Train Epoch: 295 [17920/32031 (56%)]\tLoss: 216.428772\n",
      "Train Epoch: 295 [19200/32031 (60%)]\tLoss: 208.679886\n",
      "Train Epoch: 295 [20480/32031 (64%)]\tLoss: 214.556244\n",
      "Train Epoch: 295 [21760/32031 (68%)]\tLoss: 215.787842\n",
      "Train Epoch: 295 [23040/32031 (72%)]\tLoss: 206.773651\n",
      "Train Epoch: 295 [24320/32031 (76%)]\tLoss: 201.192963\n",
      "Train Epoch: 295 [25600/32031 (80%)]\tLoss: 197.193893\n",
      "Train Epoch: 295 [26880/32031 (84%)]\tLoss: 195.117706\n",
      "Train Epoch: 295 [28160/32031 (88%)]\tLoss: 199.690720\n",
      "Train Epoch: 295 [29440/32031 (92%)]\tLoss: 210.526184\n",
      "Train Epoch: 295 [30720/32031 (96%)]\tLoss: 200.232407\n",
      "Train Epoch: 295 [7750/32031 (100%)]\tLoss: 216.545457\n",
      "====> Epoch: 295 Average loss: 203.2222\n",
      "====> Test set loss: 197.0547\n",
      "Train Epoch: 296 [0/32031 (0%)]\tLoss: 204.026779\n",
      "Train Epoch: 296 [1280/32031 (4%)]\tLoss: 211.443832\n",
      "Train Epoch: 296 [2560/32031 (8%)]\tLoss: 194.594330\n",
      "Train Epoch: 296 [3840/32031 (12%)]\tLoss: 202.311264\n",
      "Train Epoch: 296 [5120/32031 (16%)]\tLoss: 203.764343\n",
      "Train Epoch: 296 [6400/32031 (20%)]\tLoss: 200.378571\n",
      "Train Epoch: 296 [7680/32031 (24%)]\tLoss: 199.587372\n",
      "Train Epoch: 296 [8960/32031 (28%)]\tLoss: 193.914825\n",
      "Train Epoch: 296 [10240/32031 (32%)]\tLoss: 200.619659\n",
      "Train Epoch: 296 [11520/32031 (36%)]\tLoss: 195.304489\n",
      "Train Epoch: 296 [12800/32031 (40%)]\tLoss: 197.359497\n",
      "Train Epoch: 296 [14080/32031 (44%)]\tLoss: 213.717056\n",
      "Train Epoch: 296 [15360/32031 (48%)]\tLoss: 208.903137\n",
      "Train Epoch: 296 [16640/32031 (52%)]\tLoss: 213.114090\n",
      "Train Epoch: 296 [17920/32031 (56%)]\tLoss: 209.430038\n",
      "Train Epoch: 296 [19200/32031 (60%)]\tLoss: 211.210815\n",
      "Train Epoch: 296 [20480/32031 (64%)]\tLoss: 207.747269\n",
      "Train Epoch: 296 [21760/32031 (68%)]\tLoss: 209.798126\n",
      "Train Epoch: 296 [23040/32031 (72%)]\tLoss: 207.195892\n",
      "Train Epoch: 296 [24320/32031 (76%)]\tLoss: 202.737000\n",
      "Train Epoch: 296 [25600/32031 (80%)]\tLoss: 205.723541\n",
      "Train Epoch: 296 [26880/32031 (84%)]\tLoss: 203.057297\n",
      "Train Epoch: 296 [28160/32031 (88%)]\tLoss: 212.523193\n",
      "Train Epoch: 296 [29440/32031 (92%)]\tLoss: 202.411926\n",
      "Train Epoch: 296 [30720/32031 (96%)]\tLoss: 199.201324\n",
      "Train Epoch: 296 [7750/32031 (100%)]\tLoss: 246.432003\n",
      "====> Epoch: 296 Average loss: 203.1878\n",
      "====> Test set loss: 198.4695\n",
      "Train Epoch: 297 [0/32031 (0%)]\tLoss: 197.977325\n",
      "Train Epoch: 297 [1280/32031 (4%)]\tLoss: 208.960709\n",
      "Train Epoch: 297 [2560/32031 (8%)]\tLoss: 203.744171\n",
      "Train Epoch: 297 [3840/32031 (12%)]\tLoss: 198.527664\n",
      "Train Epoch: 297 [5120/32031 (16%)]\tLoss: 205.160141\n",
      "Train Epoch: 297 [6400/32031 (20%)]\tLoss: 207.699951\n",
      "Train Epoch: 297 [7680/32031 (24%)]\tLoss: 214.409973\n",
      "Train Epoch: 297 [8960/32031 (28%)]\tLoss: 195.687897\n",
      "Train Epoch: 297 [10240/32031 (32%)]\tLoss: 194.168503\n",
      "Train Epoch: 297 [11520/32031 (36%)]\tLoss: 213.737946\n",
      "Train Epoch: 297 [12800/32031 (40%)]\tLoss: 204.277115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 297 [14080/32031 (44%)]\tLoss: 198.355927\n",
      "Train Epoch: 297 [15360/32031 (48%)]\tLoss: 209.040146\n",
      "Train Epoch: 297 [16640/32031 (52%)]\tLoss: 202.992493\n",
      "Train Epoch: 297 [17920/32031 (56%)]\tLoss: 197.813599\n",
      "Train Epoch: 297 [19200/32031 (60%)]\tLoss: 194.789337\n",
      "Train Epoch: 297 [20480/32031 (64%)]\tLoss: 219.915375\n",
      "Train Epoch: 297 [21760/32031 (68%)]\tLoss: 219.292267\n",
      "Train Epoch: 297 [23040/32031 (72%)]\tLoss: 196.769104\n",
      "Train Epoch: 297 [24320/32031 (76%)]\tLoss: 215.277832\n",
      "Train Epoch: 297 [25600/32031 (80%)]\tLoss: 203.356506\n",
      "Train Epoch: 297 [26880/32031 (84%)]\tLoss: 204.659119\n",
      "Train Epoch: 297 [28160/32031 (88%)]\tLoss: 198.984924\n",
      "Train Epoch: 297 [29440/32031 (92%)]\tLoss: 202.547531\n",
      "Train Epoch: 297 [30720/32031 (96%)]\tLoss: 192.711960\n",
      "Train Epoch: 297 [7750/32031 (100%)]\tLoss: 207.253749\n",
      "====> Epoch: 297 Average loss: 203.0388\n",
      "====> Test set loss: 196.6735\n",
      "Train Epoch: 298 [0/32031 (0%)]\tLoss: 208.745453\n",
      "Train Epoch: 298 [1280/32031 (4%)]\tLoss: 195.361633\n",
      "Train Epoch: 298 [2560/32031 (8%)]\tLoss: 206.929993\n",
      "Train Epoch: 298 [3840/32031 (12%)]\tLoss: 196.394211\n",
      "Train Epoch: 298 [5120/32031 (16%)]\tLoss: 210.023346\n",
      "Train Epoch: 298 [6400/32031 (20%)]\tLoss: 186.252197\n",
      "Train Epoch: 298 [7680/32031 (24%)]\tLoss: 206.988617\n",
      "Train Epoch: 298 [8960/32031 (28%)]\tLoss: 197.923645\n",
      "Train Epoch: 298 [10240/32031 (32%)]\tLoss: 190.904297\n",
      "Train Epoch: 298 [11520/32031 (36%)]\tLoss: 208.435989\n",
      "Train Epoch: 298 [12800/32031 (40%)]\tLoss: 201.751190\n",
      "Train Epoch: 298 [14080/32031 (44%)]\tLoss: 206.168610\n",
      "Train Epoch: 298 [15360/32031 (48%)]\tLoss: 198.504837\n",
      "Train Epoch: 298 [16640/32031 (52%)]\tLoss: 190.781387\n",
      "Train Epoch: 298 [17920/32031 (56%)]\tLoss: 196.778671\n",
      "Train Epoch: 298 [19200/32031 (60%)]\tLoss: 205.503113\n",
      "Train Epoch: 298 [20480/32031 (64%)]\tLoss: 209.873627\n",
      "Train Epoch: 298 [21760/32031 (68%)]\tLoss: 200.535385\n",
      "Train Epoch: 298 [23040/32031 (72%)]\tLoss: 203.056595\n",
      "Train Epoch: 298 [24320/32031 (76%)]\tLoss: 197.309082\n",
      "Train Epoch: 298 [25600/32031 (80%)]\tLoss: 202.267303\n",
      "Train Epoch: 298 [26880/32031 (84%)]\tLoss: 206.622635\n",
      "Train Epoch: 298 [28160/32031 (88%)]\tLoss: 206.206085\n",
      "Train Epoch: 298 [29440/32031 (92%)]\tLoss: 208.570190\n",
      "Train Epoch: 298 [30720/32031 (96%)]\tLoss: 203.213089\n",
      "Train Epoch: 298 [7750/32031 (100%)]\tLoss: 196.504379\n",
      "====> Epoch: 298 Average loss: 202.9547\n",
      "====> Test set loss: 196.9222\n",
      "Train Epoch: 299 [0/32031 (0%)]\tLoss: 200.614029\n",
      "Train Epoch: 299 [1280/32031 (4%)]\tLoss: 203.181747\n",
      "Train Epoch: 299 [2560/32031 (8%)]\tLoss: 205.572235\n",
      "Train Epoch: 299 [3840/32031 (12%)]\tLoss: 203.246033\n",
      "Train Epoch: 299 [5120/32031 (16%)]\tLoss: 209.728928\n",
      "Train Epoch: 299 [6400/32031 (20%)]\tLoss: 198.293182\n",
      "Train Epoch: 299 [7680/32031 (24%)]\tLoss: 208.599716\n",
      "Train Epoch: 299 [8960/32031 (28%)]\tLoss: 198.131744\n",
      "Train Epoch: 299 [10240/32031 (32%)]\tLoss: 211.656952\n",
      "Train Epoch: 299 [11520/32031 (36%)]\tLoss: 199.031464\n",
      "Train Epoch: 299 [12800/32031 (40%)]\tLoss: 212.975479\n",
      "Train Epoch: 299 [14080/32031 (44%)]\tLoss: 206.104721\n",
      "Train Epoch: 299 [15360/32031 (48%)]\tLoss: 208.577759\n",
      "Train Epoch: 299 [16640/32031 (52%)]\tLoss: 192.512939\n",
      "Train Epoch: 299 [17920/32031 (56%)]\tLoss: 202.211334\n",
      "Train Epoch: 299 [19200/32031 (60%)]\tLoss: 206.720016\n",
      "Train Epoch: 299 [20480/32031 (64%)]\tLoss: 203.004715\n",
      "Train Epoch: 299 [21760/32031 (68%)]\tLoss: 199.150040\n",
      "Train Epoch: 299 [23040/32031 (72%)]\tLoss: 200.634293\n",
      "Train Epoch: 299 [24320/32031 (76%)]\tLoss: 202.642075\n",
      "Train Epoch: 299 [25600/32031 (80%)]\tLoss: 195.205109\n",
      "Train Epoch: 299 [26880/32031 (84%)]\tLoss: 203.165649\n",
      "Train Epoch: 299 [28160/32031 (88%)]\tLoss: 206.460602\n",
      "Train Epoch: 299 [29440/32031 (92%)]\tLoss: 208.473328\n",
      "Train Epoch: 299 [30720/32031 (96%)]\tLoss: 204.140625\n",
      "Train Epoch: 299 [7750/32031 (100%)]\tLoss: 208.415543\n",
      "====> Epoch: 299 Average loss: 203.1005\n",
      "====> Test set loss: 198.0530\n",
      "Train Epoch: 300 [0/32031 (0%)]\tLoss: 202.721466\n",
      "Train Epoch: 300 [1280/32031 (4%)]\tLoss: 202.509033\n",
      "Train Epoch: 300 [2560/32031 (8%)]\tLoss: 198.334534\n",
      "Train Epoch: 300 [3840/32031 (12%)]\tLoss: 197.114532\n",
      "Train Epoch: 300 [5120/32031 (16%)]\tLoss: 200.282349\n",
      "Train Epoch: 300 [6400/32031 (20%)]\tLoss: 206.147736\n",
      "Train Epoch: 300 [7680/32031 (24%)]\tLoss: 197.399536\n",
      "Train Epoch: 300 [8960/32031 (28%)]\tLoss: 211.270432\n",
      "Train Epoch: 300 [10240/32031 (32%)]\tLoss: 205.854782\n",
      "Train Epoch: 300 [11520/32031 (36%)]\tLoss: 208.245712\n",
      "Train Epoch: 300 [12800/32031 (40%)]\tLoss: 207.881134\n",
      "Train Epoch: 300 [14080/32031 (44%)]\tLoss: 205.283295\n",
      "Train Epoch: 300 [15360/32031 (48%)]\tLoss: 201.998947\n",
      "Train Epoch: 300 [16640/32031 (52%)]\tLoss: 203.250488\n",
      "Train Epoch: 300 [17920/32031 (56%)]\tLoss: 202.227478\n",
      "Train Epoch: 300 [19200/32031 (60%)]\tLoss: 187.796371\n",
      "Train Epoch: 300 [20480/32031 (64%)]\tLoss: 206.168228\n",
      "Train Epoch: 300 [21760/32031 (68%)]\tLoss: 213.711227\n",
      "Train Epoch: 300 [23040/32031 (72%)]\tLoss: 204.943787\n",
      "Train Epoch: 300 [24320/32031 (76%)]\tLoss: 202.785583\n",
      "Train Epoch: 300 [25600/32031 (80%)]\tLoss: 210.385529\n",
      "Train Epoch: 300 [26880/32031 (84%)]\tLoss: 214.820389\n",
      "Train Epoch: 300 [28160/32031 (88%)]\tLoss: 192.320282\n",
      "Train Epoch: 300 [29440/32031 (92%)]\tLoss: 201.350677\n",
      "Train Epoch: 300 [30720/32031 (96%)]\tLoss: 200.325119\n",
      "Train Epoch: 300 [7750/32031 (100%)]\tLoss: 193.444714\n",
      "====> Epoch: 300 Average loss: 203.1673\n",
      "====> Test set loss: 201.2162\n",
      "Train Epoch: 301 [0/32031 (0%)]\tLoss: 195.303253\n",
      "Train Epoch: 301 [1280/32031 (4%)]\tLoss: 185.473190\n",
      "Train Epoch: 301 [2560/32031 (8%)]\tLoss: 193.744553\n",
      "Train Epoch: 301 [3840/32031 (12%)]\tLoss: 195.252945\n",
      "Train Epoch: 301 [5120/32031 (16%)]\tLoss: 201.139648\n",
      "Train Epoch: 301 [6400/32031 (20%)]\tLoss: 207.895554\n",
      "Train Epoch: 301 [7680/32031 (24%)]\tLoss: 194.643021\n",
      "Train Epoch: 301 [8960/32031 (28%)]\tLoss: 207.133408\n",
      "Train Epoch: 301 [10240/32031 (32%)]\tLoss: 191.302261\n",
      "Train Epoch: 301 [11520/32031 (36%)]\tLoss: 195.471207\n",
      "Train Epoch: 301 [12800/32031 (40%)]\tLoss: 201.255081\n",
      "Train Epoch: 301 [14080/32031 (44%)]\tLoss: 194.895416\n",
      "Train Epoch: 301 [15360/32031 (48%)]\tLoss: 199.961929\n",
      "Train Epoch: 301 [16640/32031 (52%)]\tLoss: 191.686722\n",
      "Train Epoch: 301 [17920/32031 (56%)]\tLoss: 198.227402\n",
      "Train Epoch: 301 [19200/32031 (60%)]\tLoss: 210.264969\n",
      "Train Epoch: 301 [20480/32031 (64%)]\tLoss: 197.481415\n",
      "Train Epoch: 301 [21760/32031 (68%)]\tLoss: 208.375504\n",
      "Train Epoch: 301 [23040/32031 (72%)]\tLoss: 203.803299\n",
      "Train Epoch: 301 [24320/32031 (76%)]\tLoss: 199.268448\n",
      "Train Epoch: 301 [25600/32031 (80%)]\tLoss: 202.376907\n",
      "Train Epoch: 301 [26880/32031 (84%)]\tLoss: 205.969559\n",
      "Train Epoch: 301 [28160/32031 (88%)]\tLoss: 200.181580\n",
      "Train Epoch: 301 [29440/32031 (92%)]\tLoss: 210.612991\n",
      "Train Epoch: 301 [30720/32031 (96%)]\tLoss: 200.153641\n",
      "Train Epoch: 301 [7750/32031 (100%)]\tLoss: 230.940745\n",
      "====> Epoch: 301 Average loss: 202.7548\n",
      "====> Test set loss: 196.5969\n",
      "Train Epoch: 302 [0/32031 (0%)]\tLoss: 191.299377\n",
      "Train Epoch: 302 [1280/32031 (4%)]\tLoss: 202.822937\n",
      "Train Epoch: 302 [2560/32031 (8%)]\tLoss: 216.890503\n",
      "Train Epoch: 302 [3840/32031 (12%)]\tLoss: 197.586945\n",
      "Train Epoch: 302 [5120/32031 (16%)]\tLoss: 199.200607\n",
      "Train Epoch: 302 [6400/32031 (20%)]\tLoss: 203.058807\n",
      "Train Epoch: 302 [7680/32031 (24%)]\tLoss: 195.416260\n",
      "Train Epoch: 302 [8960/32031 (28%)]\tLoss: 219.604111\n",
      "Train Epoch: 302 [10240/32031 (32%)]\tLoss: 201.191971\n",
      "Train Epoch: 302 [11520/32031 (36%)]\tLoss: 214.601974\n",
      "Train Epoch: 302 [12800/32031 (40%)]\tLoss: 194.382004\n",
      "Train Epoch: 302 [14080/32031 (44%)]\tLoss: 198.719574\n",
      "Train Epoch: 302 [15360/32031 (48%)]\tLoss: 190.553619\n",
      "Train Epoch: 302 [16640/32031 (52%)]\tLoss: 199.294357\n",
      "Train Epoch: 302 [17920/32031 (56%)]\tLoss: 193.153168\n",
      "Train Epoch: 302 [19200/32031 (60%)]\tLoss: 206.786682\n",
      "Train Epoch: 302 [20480/32031 (64%)]\tLoss: 203.821869\n",
      "Train Epoch: 302 [21760/32031 (68%)]\tLoss: 198.315903\n",
      "Train Epoch: 302 [23040/32031 (72%)]\tLoss: 196.609161\n",
      "Train Epoch: 302 [24320/32031 (76%)]\tLoss: 202.646164\n",
      "Train Epoch: 302 [25600/32031 (80%)]\tLoss: 210.514679\n",
      "Train Epoch: 302 [26880/32031 (84%)]\tLoss: 203.352112\n",
      "Train Epoch: 302 [28160/32031 (88%)]\tLoss: 217.153122\n",
      "Train Epoch: 302 [29440/32031 (92%)]\tLoss: 206.014526\n",
      "Train Epoch: 302 [30720/32031 (96%)]\tLoss: 206.846420\n",
      "Train Epoch: 302 [7750/32031 (100%)]\tLoss: 207.195013\n",
      "====> Epoch: 302 Average loss: 202.9621\n",
      "====> Test set loss: 194.9736\n",
      "Train Epoch: 303 [0/32031 (0%)]\tLoss: 204.503159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 303 [1280/32031 (4%)]\tLoss: 192.636139\n",
      "Train Epoch: 303 [2560/32031 (8%)]\tLoss: 192.816010\n",
      "Train Epoch: 303 [3840/32031 (12%)]\tLoss: 208.710693\n",
      "Train Epoch: 303 [5120/32031 (16%)]\tLoss: 200.303894\n",
      "Train Epoch: 303 [6400/32031 (20%)]\tLoss: 202.110229\n",
      "Train Epoch: 303 [7680/32031 (24%)]\tLoss: 213.558487\n",
      "Train Epoch: 303 [8960/32031 (28%)]\tLoss: 202.417099\n",
      "Train Epoch: 303 [10240/32031 (32%)]\tLoss: 205.669296\n",
      "Train Epoch: 303 [11520/32031 (36%)]\tLoss: 203.399078\n",
      "Train Epoch: 303 [12800/32031 (40%)]\tLoss: 213.634872\n",
      "Train Epoch: 303 [14080/32031 (44%)]\tLoss: 203.557663\n",
      "Train Epoch: 303 [15360/32031 (48%)]\tLoss: 210.183655\n",
      "Train Epoch: 303 [16640/32031 (52%)]\tLoss: 206.515076\n",
      "Train Epoch: 303 [17920/32031 (56%)]\tLoss: 202.611389\n",
      "Train Epoch: 303 [19200/32031 (60%)]\tLoss: 203.554947\n",
      "Train Epoch: 303 [20480/32031 (64%)]\tLoss: 193.543808\n",
      "Train Epoch: 303 [21760/32031 (68%)]\tLoss: 194.199799\n",
      "Train Epoch: 303 [23040/32031 (72%)]\tLoss: 195.423630\n",
      "Train Epoch: 303 [24320/32031 (76%)]\tLoss: 203.682480\n",
      "Train Epoch: 303 [25600/32031 (80%)]\tLoss: 205.198975\n",
      "Train Epoch: 303 [26880/32031 (84%)]\tLoss: 207.436203\n",
      "Train Epoch: 303 [28160/32031 (88%)]\tLoss: 207.483612\n",
      "Train Epoch: 303 [29440/32031 (92%)]\tLoss: 204.644119\n",
      "Train Epoch: 303 [30720/32031 (96%)]\tLoss: 212.239258\n",
      "Train Epoch: 303 [7750/32031 (100%)]\tLoss: 214.937579\n",
      "====> Epoch: 303 Average loss: 202.5770\n",
      "====> Test set loss: 199.5712\n",
      "Train Epoch: 304 [0/32031 (0%)]\tLoss: 202.542709\n",
      "Train Epoch: 304 [1280/32031 (4%)]\tLoss: 197.225861\n",
      "Train Epoch: 304 [2560/32031 (8%)]\tLoss: 203.184540\n",
      "Train Epoch: 304 [3840/32031 (12%)]\tLoss: 209.139847\n",
      "Train Epoch: 304 [5120/32031 (16%)]\tLoss: 212.901367\n",
      "Train Epoch: 304 [6400/32031 (20%)]\tLoss: 203.569077\n",
      "Train Epoch: 304 [7680/32031 (24%)]\tLoss: 203.217346\n",
      "Train Epoch: 304 [8960/32031 (28%)]\tLoss: 194.948563\n",
      "Train Epoch: 304 [10240/32031 (32%)]\tLoss: 202.038528\n",
      "Train Epoch: 304 [11520/32031 (36%)]\tLoss: 200.146164\n",
      "Train Epoch: 304 [12800/32031 (40%)]\tLoss: 210.451385\n",
      "Train Epoch: 304 [14080/32031 (44%)]\tLoss: 215.637100\n",
      "Train Epoch: 304 [15360/32031 (48%)]\tLoss: 201.158646\n",
      "Train Epoch: 304 [16640/32031 (52%)]\tLoss: 202.348129\n",
      "Train Epoch: 304 [17920/32031 (56%)]\tLoss: 212.327637\n",
      "Train Epoch: 304 [19200/32031 (60%)]\tLoss: 207.272598\n",
      "Train Epoch: 304 [20480/32031 (64%)]\tLoss: 205.175110\n",
      "Train Epoch: 304 [21760/32031 (68%)]\tLoss: 192.565689\n",
      "Train Epoch: 304 [23040/32031 (72%)]\tLoss: 207.371017\n",
      "Train Epoch: 304 [24320/32031 (76%)]\tLoss: 195.927628\n",
      "Train Epoch: 304 [25600/32031 (80%)]\tLoss: 203.927795\n",
      "Train Epoch: 304 [26880/32031 (84%)]\tLoss: 207.129395\n",
      "Train Epoch: 304 [28160/32031 (88%)]\tLoss: 201.611282\n",
      "Train Epoch: 304 [29440/32031 (92%)]\tLoss: 204.710922\n",
      "Train Epoch: 304 [30720/32031 (96%)]\tLoss: 201.914093\n",
      "Train Epoch: 304 [7750/32031 (100%)]\tLoss: 214.411574\n",
      "====> Epoch: 304 Average loss: 203.3870\n",
      "====> Test set loss: 196.1829\n",
      "Train Epoch: 305 [0/32031 (0%)]\tLoss: 204.237717\n",
      "Train Epoch: 305 [1280/32031 (4%)]\tLoss: 208.392105\n",
      "Train Epoch: 305 [2560/32031 (8%)]\tLoss: 219.083313\n",
      "Train Epoch: 305 [3840/32031 (12%)]\tLoss: 211.170959\n",
      "Train Epoch: 305 [5120/32031 (16%)]\tLoss: 197.875824\n",
      "Train Epoch: 305 [6400/32031 (20%)]\tLoss: 200.080978\n",
      "Train Epoch: 305 [7680/32031 (24%)]\tLoss: 205.951569\n",
      "Train Epoch: 305 [8960/32031 (28%)]\tLoss: 209.495850\n",
      "Train Epoch: 305 [10240/32031 (32%)]\tLoss: 196.671890\n",
      "Train Epoch: 305 [11520/32031 (36%)]\tLoss: 205.566650\n",
      "Train Epoch: 305 [12800/32031 (40%)]\tLoss: 197.342194\n",
      "Train Epoch: 305 [14080/32031 (44%)]\tLoss: 203.228943\n",
      "Train Epoch: 305 [15360/32031 (48%)]\tLoss: 210.629776\n",
      "Train Epoch: 305 [16640/32031 (52%)]\tLoss: 199.460236\n",
      "Train Epoch: 305 [17920/32031 (56%)]\tLoss: 200.168076\n",
      "Train Epoch: 305 [19200/32031 (60%)]\tLoss: 198.906555\n",
      "Train Epoch: 305 [20480/32031 (64%)]\tLoss: 196.609268\n",
      "Train Epoch: 305 [21760/32031 (68%)]\tLoss: 207.887146\n",
      "Train Epoch: 305 [23040/32031 (72%)]\tLoss: 200.832764\n",
      "Train Epoch: 305 [24320/32031 (76%)]\tLoss: 204.566360\n",
      "Train Epoch: 305 [25600/32031 (80%)]\tLoss: 195.063705\n",
      "Train Epoch: 305 [26880/32031 (84%)]\tLoss: 205.266693\n",
      "Train Epoch: 305 [28160/32031 (88%)]\tLoss: 199.417160\n",
      "Train Epoch: 305 [29440/32031 (92%)]\tLoss: 204.773727\n",
      "Train Epoch: 305 [30720/32031 (96%)]\tLoss: 205.056061\n",
      "Train Epoch: 305 [7750/32031 (100%)]\tLoss: 195.908109\n",
      "====> Epoch: 305 Average loss: 202.8210\n",
      "====> Test set loss: 196.8751\n",
      "Train Epoch: 306 [0/32031 (0%)]\tLoss: 189.140121\n",
      "Train Epoch: 306 [1280/32031 (4%)]\tLoss: 196.431366\n",
      "Train Epoch: 306 [2560/32031 (8%)]\tLoss: 203.936157\n",
      "Train Epoch: 306 [3840/32031 (12%)]\tLoss: 205.051941\n",
      "Train Epoch: 306 [5120/32031 (16%)]\tLoss: 190.378952\n",
      "Train Epoch: 306 [6400/32031 (20%)]\tLoss: 205.667938\n",
      "Train Epoch: 306 [7680/32031 (24%)]\tLoss: 203.847427\n",
      "Train Epoch: 306 [8960/32031 (28%)]\tLoss: 194.035568\n",
      "Train Epoch: 306 [10240/32031 (32%)]\tLoss: 204.732864\n",
      "Train Epoch: 306 [11520/32031 (36%)]\tLoss: 199.435516\n",
      "Train Epoch: 306 [12800/32031 (40%)]\tLoss: 198.388458\n",
      "Train Epoch: 306 [14080/32031 (44%)]\tLoss: 214.126816\n",
      "Train Epoch: 306 [15360/32031 (48%)]\tLoss: 203.455627\n",
      "Train Epoch: 306 [16640/32031 (52%)]\tLoss: 195.624313\n",
      "Train Epoch: 306 [17920/32031 (56%)]\tLoss: 196.863907\n",
      "Train Epoch: 306 [19200/32031 (60%)]\tLoss: 203.992905\n",
      "Train Epoch: 306 [20480/32031 (64%)]\tLoss: 224.184845\n",
      "Train Epoch: 306 [21760/32031 (68%)]\tLoss: 215.945496\n",
      "Train Epoch: 306 [23040/32031 (72%)]\tLoss: 203.812973\n",
      "Train Epoch: 306 [24320/32031 (76%)]\tLoss: 197.270935\n",
      "Train Epoch: 306 [25600/32031 (80%)]\tLoss: 192.589081\n",
      "Train Epoch: 306 [26880/32031 (84%)]\tLoss: 190.755249\n",
      "Train Epoch: 306 [28160/32031 (88%)]\tLoss: 195.218109\n",
      "Train Epoch: 306 [29440/32031 (92%)]\tLoss: 193.523148\n",
      "Train Epoch: 306 [30720/32031 (96%)]\tLoss: 195.346741\n",
      "Train Epoch: 306 [7750/32031 (100%)]\tLoss: 216.832646\n",
      "====> Epoch: 306 Average loss: 203.1806\n",
      "====> Test set loss: 196.1509\n",
      "Train Epoch: 307 [0/32031 (0%)]\tLoss: 206.171753\n",
      "Train Epoch: 307 [1280/32031 (4%)]\tLoss: 196.657211\n",
      "Train Epoch: 307 [2560/32031 (8%)]\tLoss: 208.638351\n",
      "Train Epoch: 307 [3840/32031 (12%)]\tLoss: 205.180115\n",
      "Train Epoch: 307 [5120/32031 (16%)]\tLoss: 193.870789\n",
      "Train Epoch: 307 [6400/32031 (20%)]\tLoss: 204.835648\n",
      "Train Epoch: 307 [7680/32031 (24%)]\tLoss: 200.930573\n",
      "Train Epoch: 307 [8960/32031 (28%)]\tLoss: 206.187622\n",
      "Train Epoch: 307 [10240/32031 (32%)]\tLoss: 197.086594\n",
      "Train Epoch: 307 [11520/32031 (36%)]\tLoss: 200.611191\n",
      "Train Epoch: 307 [12800/32031 (40%)]\tLoss: 198.838074\n",
      "Train Epoch: 307 [14080/32031 (44%)]\tLoss: 206.144287\n",
      "Train Epoch: 307 [15360/32031 (48%)]\tLoss: 196.916626\n",
      "Train Epoch: 307 [16640/32031 (52%)]\tLoss: 201.661987\n",
      "Train Epoch: 307 [17920/32031 (56%)]\tLoss: 212.737656\n",
      "Train Epoch: 307 [19200/32031 (60%)]\tLoss: 191.323059\n",
      "Train Epoch: 307 [20480/32031 (64%)]\tLoss: 211.191956\n",
      "Train Epoch: 307 [21760/32031 (68%)]\tLoss: 196.343048\n",
      "Train Epoch: 307 [23040/32031 (72%)]\tLoss: 190.072433\n",
      "Train Epoch: 307 [24320/32031 (76%)]\tLoss: 201.267090\n",
      "Train Epoch: 307 [25600/32031 (80%)]\tLoss: 201.404190\n",
      "Train Epoch: 307 [26880/32031 (84%)]\tLoss: 206.268280\n",
      "Train Epoch: 307 [28160/32031 (88%)]\tLoss: 207.187347\n",
      "Train Epoch: 307 [29440/32031 (92%)]\tLoss: 205.937897\n",
      "Train Epoch: 307 [30720/32031 (96%)]\tLoss: 204.002289\n",
      "Train Epoch: 307 [7750/32031 (100%)]\tLoss: 200.547017\n",
      "====> Epoch: 307 Average loss: 202.5711\n",
      "====> Test set loss: 197.5439\n",
      "Train Epoch: 308 [0/32031 (0%)]\tLoss: 199.231766\n",
      "Train Epoch: 308 [1280/32031 (4%)]\tLoss: 197.754196\n",
      "Train Epoch: 308 [2560/32031 (8%)]\tLoss: 195.706543\n",
      "Train Epoch: 308 [3840/32031 (12%)]\tLoss: 213.632278\n",
      "Train Epoch: 308 [5120/32031 (16%)]\tLoss: 199.128662\n",
      "Train Epoch: 308 [6400/32031 (20%)]\tLoss: 195.738922\n",
      "Train Epoch: 308 [7680/32031 (24%)]\tLoss: 207.911255\n",
      "Train Epoch: 308 [8960/32031 (28%)]\tLoss: 210.498428\n",
      "Train Epoch: 308 [10240/32031 (32%)]\tLoss: 209.258102\n",
      "Train Epoch: 308 [11520/32031 (36%)]\tLoss: 197.639526\n",
      "Train Epoch: 308 [12800/32031 (40%)]\tLoss: 200.273682\n",
      "Train Epoch: 308 [14080/32031 (44%)]\tLoss: 196.446777\n",
      "Train Epoch: 308 [15360/32031 (48%)]\tLoss: 199.414352\n",
      "Train Epoch: 308 [16640/32031 (52%)]\tLoss: 206.304581\n",
      "Train Epoch: 308 [17920/32031 (56%)]\tLoss: 203.669540\n",
      "Train Epoch: 308 [19200/32031 (60%)]\tLoss: 206.898117\n",
      "Train Epoch: 308 [20480/32031 (64%)]\tLoss: 192.771545\n",
      "Train Epoch: 308 [21760/32031 (68%)]\tLoss: 192.789520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 308 [23040/32031 (72%)]\tLoss: 218.851349\n",
      "Train Epoch: 308 [24320/32031 (76%)]\tLoss: 199.715668\n",
      "Train Epoch: 308 [25600/32031 (80%)]\tLoss: 193.684677\n",
      "Train Epoch: 308 [26880/32031 (84%)]\tLoss: 201.293365\n",
      "Train Epoch: 308 [28160/32031 (88%)]\tLoss: 226.140884\n",
      "Train Epoch: 308 [29440/32031 (92%)]\tLoss: 199.081207\n",
      "Train Epoch: 308 [30720/32031 (96%)]\tLoss: 190.093933\n",
      "Train Epoch: 308 [7750/32031 (100%)]\tLoss: 199.053191\n",
      "====> Epoch: 308 Average loss: 202.8203\n",
      "====> Test set loss: 198.6254\n",
      "Train Epoch: 309 [0/32031 (0%)]\tLoss: 197.535599\n",
      "Train Epoch: 309 [1280/32031 (4%)]\tLoss: 196.315216\n",
      "Train Epoch: 309 [2560/32031 (8%)]\tLoss: 190.542770\n",
      "Train Epoch: 309 [3840/32031 (12%)]\tLoss: 215.176193\n",
      "Train Epoch: 309 [5120/32031 (16%)]\tLoss: 202.287430\n",
      "Train Epoch: 309 [6400/32031 (20%)]\tLoss: 200.629913\n",
      "Train Epoch: 309 [7680/32031 (24%)]\tLoss: 203.908890\n",
      "Train Epoch: 309 [8960/32031 (28%)]\tLoss: 208.308823\n",
      "Train Epoch: 309 [10240/32031 (32%)]\tLoss: 205.509521\n",
      "Train Epoch: 309 [11520/32031 (36%)]\tLoss: 211.539124\n",
      "Train Epoch: 309 [12800/32031 (40%)]\tLoss: 204.693604\n",
      "Train Epoch: 309 [14080/32031 (44%)]\tLoss: 200.230865\n",
      "Train Epoch: 309 [15360/32031 (48%)]\tLoss: 211.196457\n",
      "Train Epoch: 309 [16640/32031 (52%)]\tLoss: 193.481155\n",
      "Train Epoch: 309 [17920/32031 (56%)]\tLoss: 192.482285\n",
      "Train Epoch: 309 [19200/32031 (60%)]\tLoss: 204.106232\n",
      "Train Epoch: 309 [20480/32031 (64%)]\tLoss: 205.226944\n",
      "Train Epoch: 309 [21760/32031 (68%)]\tLoss: 206.490707\n",
      "Train Epoch: 309 [23040/32031 (72%)]\tLoss: 200.382629\n",
      "Train Epoch: 309 [24320/32031 (76%)]\tLoss: 203.861191\n",
      "Train Epoch: 309 [25600/32031 (80%)]\tLoss: 192.850800\n",
      "Train Epoch: 309 [26880/32031 (84%)]\tLoss: 218.887009\n",
      "Train Epoch: 309 [28160/32031 (88%)]\tLoss: 210.985428\n",
      "Train Epoch: 309 [29440/32031 (92%)]\tLoss: 196.770523\n",
      "Train Epoch: 309 [30720/32031 (96%)]\tLoss: 199.255554\n",
      "Train Epoch: 309 [7750/32031 (100%)]\tLoss: 201.460449\n",
      "====> Epoch: 309 Average loss: 203.0935\n",
      "====> Test set loss: 199.4469\n",
      "Train Epoch: 310 [0/32031 (0%)]\tLoss: 208.785568\n",
      "Train Epoch: 310 [1280/32031 (4%)]\tLoss: 203.401123\n",
      "Train Epoch: 310 [2560/32031 (8%)]\tLoss: 192.836044\n",
      "Train Epoch: 310 [3840/32031 (12%)]\tLoss: 190.111267\n",
      "Train Epoch: 310 [5120/32031 (16%)]\tLoss: 206.984543\n",
      "Train Epoch: 310 [6400/32031 (20%)]\tLoss: 206.151566\n",
      "Train Epoch: 310 [7680/32031 (24%)]\tLoss: 194.204193\n",
      "Train Epoch: 310 [8960/32031 (28%)]\tLoss: 206.399689\n",
      "Train Epoch: 310 [10240/32031 (32%)]\tLoss: 196.396545\n",
      "Train Epoch: 310 [11520/32031 (36%)]\tLoss: 214.891373\n",
      "Train Epoch: 310 [12800/32031 (40%)]\tLoss: 212.356766\n",
      "Train Epoch: 310 [14080/32031 (44%)]\tLoss: 202.439056\n",
      "Train Epoch: 310 [15360/32031 (48%)]\tLoss: 195.123672\n",
      "Train Epoch: 310 [16640/32031 (52%)]\tLoss: 190.641357\n",
      "Train Epoch: 310 [17920/32031 (56%)]\tLoss: 206.952942\n",
      "Train Epoch: 310 [19200/32031 (60%)]\tLoss: 202.434067\n",
      "Train Epoch: 310 [20480/32031 (64%)]\tLoss: 204.838562\n",
      "Train Epoch: 310 [21760/32031 (68%)]\tLoss: 199.767441\n",
      "Train Epoch: 310 [23040/32031 (72%)]\tLoss: 208.332886\n",
      "Train Epoch: 310 [24320/32031 (76%)]\tLoss: 201.205170\n",
      "Train Epoch: 310 [25600/32031 (80%)]\tLoss: 193.200226\n",
      "Train Epoch: 310 [26880/32031 (84%)]\tLoss: 195.368637\n",
      "Train Epoch: 310 [28160/32031 (88%)]\tLoss: 212.393753\n",
      "Train Epoch: 310 [29440/32031 (92%)]\tLoss: 194.123230\n",
      "Train Epoch: 310 [30720/32031 (96%)]\tLoss: 199.867035\n",
      "Train Epoch: 310 [7750/32031 (100%)]\tLoss: 204.919544\n",
      "====> Epoch: 310 Average loss: 202.7018\n",
      "====> Test set loss: 195.7507\n",
      "Train Epoch: 311 [0/32031 (0%)]\tLoss: 191.456451\n",
      "Train Epoch: 311 [1280/32031 (4%)]\tLoss: 205.431702\n",
      "Train Epoch: 311 [2560/32031 (8%)]\tLoss: 199.840149\n",
      "Train Epoch: 311 [3840/32031 (12%)]\tLoss: 200.690826\n",
      "Train Epoch: 311 [5120/32031 (16%)]\tLoss: 202.817230\n",
      "Train Epoch: 311 [6400/32031 (20%)]\tLoss: 204.455170\n",
      "Train Epoch: 311 [7680/32031 (24%)]\tLoss: 201.324646\n",
      "Train Epoch: 311 [8960/32031 (28%)]\tLoss: 209.677124\n",
      "Train Epoch: 311 [10240/32031 (32%)]\tLoss: 204.014374\n",
      "Train Epoch: 311 [11520/32031 (36%)]\tLoss: 199.320068\n",
      "Train Epoch: 311 [12800/32031 (40%)]\tLoss: 194.529846\n",
      "Train Epoch: 311 [14080/32031 (44%)]\tLoss: 198.323380\n",
      "Train Epoch: 311 [15360/32031 (48%)]\tLoss: 194.838440\n",
      "Train Epoch: 311 [16640/32031 (52%)]\tLoss: 197.704910\n",
      "Train Epoch: 311 [17920/32031 (56%)]\tLoss: 197.172928\n",
      "Train Epoch: 311 [19200/32031 (60%)]\tLoss: 199.235336\n",
      "Train Epoch: 311 [20480/32031 (64%)]\tLoss: 199.378799\n",
      "Train Epoch: 311 [21760/32031 (68%)]\tLoss: 201.385254\n",
      "Train Epoch: 311 [23040/32031 (72%)]\tLoss: 207.449326\n",
      "Train Epoch: 311 [24320/32031 (76%)]\tLoss: 202.621979\n",
      "Train Epoch: 311 [25600/32031 (80%)]\tLoss: 208.755371\n",
      "Train Epoch: 311 [26880/32031 (84%)]\tLoss: 201.394257\n",
      "Train Epoch: 311 [28160/32031 (88%)]\tLoss: 208.184860\n",
      "Train Epoch: 311 [29440/32031 (92%)]\tLoss: 205.355347\n",
      "Train Epoch: 311 [30720/32031 (96%)]\tLoss: 197.159317\n",
      "Train Epoch: 311 [7750/32031 (100%)]\tLoss: 203.587072\n",
      "====> Epoch: 311 Average loss: 203.0906\n",
      "====> Test set loss: 199.0162\n",
      "Train Epoch: 312 [0/32031 (0%)]\tLoss: 217.559235\n",
      "Train Epoch: 312 [1280/32031 (4%)]\tLoss: 197.473862\n",
      "Train Epoch: 312 [2560/32031 (8%)]\tLoss: 199.678375\n",
      "Train Epoch: 312 [3840/32031 (12%)]\tLoss: 201.539276\n",
      "Train Epoch: 312 [5120/32031 (16%)]\tLoss: 192.319794\n",
      "Train Epoch: 312 [6400/32031 (20%)]\tLoss: 202.115112\n",
      "Train Epoch: 312 [7680/32031 (24%)]\tLoss: 194.022369\n",
      "Train Epoch: 312 [8960/32031 (28%)]\tLoss: 206.887924\n",
      "Train Epoch: 312 [10240/32031 (32%)]\tLoss: 202.395340\n",
      "Train Epoch: 312 [11520/32031 (36%)]\tLoss: 200.394440\n",
      "Train Epoch: 312 [12800/32031 (40%)]\tLoss: 224.480042\n",
      "Train Epoch: 312 [14080/32031 (44%)]\tLoss: 218.640045\n",
      "Train Epoch: 312 [15360/32031 (48%)]\tLoss: 193.722168\n",
      "Train Epoch: 312 [16640/32031 (52%)]\tLoss: 213.294952\n",
      "Train Epoch: 312 [17920/32031 (56%)]\tLoss: 207.140488\n",
      "Train Epoch: 312 [19200/32031 (60%)]\tLoss: 187.927490\n",
      "Train Epoch: 312 [20480/32031 (64%)]\tLoss: 197.838760\n",
      "Train Epoch: 312 [21760/32031 (68%)]\tLoss: 190.810699\n",
      "Train Epoch: 312 [23040/32031 (72%)]\tLoss: 201.173294\n",
      "Train Epoch: 312 [24320/32031 (76%)]\tLoss: 200.550323\n",
      "Train Epoch: 312 [25600/32031 (80%)]\tLoss: 201.185898\n",
      "Train Epoch: 312 [26880/32031 (84%)]\tLoss: 204.491150\n",
      "Train Epoch: 312 [28160/32031 (88%)]\tLoss: 211.823257\n",
      "Train Epoch: 312 [29440/32031 (92%)]\tLoss: 213.559555\n",
      "Train Epoch: 312 [30720/32031 (96%)]\tLoss: 201.418198\n",
      "Train Epoch: 312 [7750/32031 (100%)]\tLoss: 202.612872\n",
      "====> Epoch: 312 Average loss: 202.7601\n",
      "====> Test set loss: 198.6202\n",
      "Train Epoch: 313 [0/32031 (0%)]\tLoss: 202.105789\n",
      "Train Epoch: 313 [1280/32031 (4%)]\tLoss: 214.315842\n",
      "Train Epoch: 313 [2560/32031 (8%)]\tLoss: 197.632629\n",
      "Train Epoch: 313 [3840/32031 (12%)]\tLoss: 204.640732\n",
      "Train Epoch: 313 [5120/32031 (16%)]\tLoss: 195.291153\n",
      "Train Epoch: 313 [6400/32031 (20%)]\tLoss: 206.416046\n",
      "Train Epoch: 313 [7680/32031 (24%)]\tLoss: 199.369141\n",
      "Train Epoch: 313 [8960/32031 (28%)]\tLoss: 215.834976\n",
      "Train Epoch: 313 [10240/32031 (32%)]\tLoss: 199.728256\n",
      "Train Epoch: 313 [11520/32031 (36%)]\tLoss: 203.511047\n",
      "Train Epoch: 313 [12800/32031 (40%)]\tLoss: 210.191498\n",
      "Train Epoch: 313 [14080/32031 (44%)]\tLoss: 209.123978\n",
      "Train Epoch: 313 [15360/32031 (48%)]\tLoss: 204.109879\n",
      "Train Epoch: 313 [16640/32031 (52%)]\tLoss: 202.397446\n",
      "Train Epoch: 313 [17920/32031 (56%)]\tLoss: 203.567963\n",
      "Train Epoch: 313 [19200/32031 (60%)]\tLoss: 200.245514\n",
      "Train Epoch: 313 [20480/32031 (64%)]\tLoss: 197.818542\n",
      "Train Epoch: 313 [21760/32031 (68%)]\tLoss: 208.484695\n",
      "Train Epoch: 313 [23040/32031 (72%)]\tLoss: 206.283859\n",
      "Train Epoch: 313 [24320/32031 (76%)]\tLoss: 209.634216\n",
      "Train Epoch: 313 [25600/32031 (80%)]\tLoss: 202.964493\n",
      "Train Epoch: 313 [26880/32031 (84%)]\tLoss: 222.838440\n",
      "Train Epoch: 313 [28160/32031 (88%)]\tLoss: 198.568253\n",
      "Train Epoch: 313 [29440/32031 (92%)]\tLoss: 192.510818\n",
      "Train Epoch: 313 [30720/32031 (96%)]\tLoss: 190.897614\n",
      "Train Epoch: 313 [7750/32031 (100%)]\tLoss: 190.993526\n",
      "====> Epoch: 313 Average loss: 202.6122\n",
      "====> Test set loss: 197.9669\n",
      "Train Epoch: 314 [0/32031 (0%)]\tLoss: 222.261017\n",
      "Train Epoch: 314 [1280/32031 (4%)]\tLoss: 192.121552\n",
      "Train Epoch: 314 [2560/32031 (8%)]\tLoss: 200.531647\n",
      "Train Epoch: 314 [3840/32031 (12%)]\tLoss: 201.928024\n",
      "Train Epoch: 314 [5120/32031 (16%)]\tLoss: 193.263763\n",
      "Train Epoch: 314 [6400/32031 (20%)]\tLoss: 202.403397\n",
      "Train Epoch: 314 [7680/32031 (24%)]\tLoss: 212.688522\n",
      "Train Epoch: 314 [8960/32031 (28%)]\tLoss: 204.183197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 314 [10240/32031 (32%)]\tLoss: 199.888641\n",
      "Train Epoch: 314 [11520/32031 (36%)]\tLoss: 195.161285\n",
      "Train Epoch: 314 [12800/32031 (40%)]\tLoss: 199.770737\n",
      "Train Epoch: 314 [14080/32031 (44%)]\tLoss: 211.784485\n",
      "Train Epoch: 314 [15360/32031 (48%)]\tLoss: 199.460876\n",
      "Train Epoch: 314 [16640/32031 (52%)]\tLoss: 197.929657\n",
      "Train Epoch: 314 [17920/32031 (56%)]\tLoss: 192.951660\n",
      "Train Epoch: 314 [19200/32031 (60%)]\tLoss: 208.504120\n",
      "Train Epoch: 314 [20480/32031 (64%)]\tLoss: 189.610626\n",
      "Train Epoch: 314 [21760/32031 (68%)]\tLoss: 201.023163\n",
      "Train Epoch: 314 [23040/32031 (72%)]\tLoss: 212.773315\n",
      "Train Epoch: 314 [24320/32031 (76%)]\tLoss: 215.992630\n",
      "Train Epoch: 314 [25600/32031 (80%)]\tLoss: 204.544373\n",
      "Train Epoch: 314 [26880/32031 (84%)]\tLoss: 199.210464\n",
      "Train Epoch: 314 [28160/32031 (88%)]\tLoss: 201.345413\n",
      "Train Epoch: 314 [29440/32031 (92%)]\tLoss: 190.168640\n",
      "Train Epoch: 314 [30720/32031 (96%)]\tLoss: 217.041016\n",
      "Train Epoch: 314 [7750/32031 (100%)]\tLoss: 196.297017\n",
      "====> Epoch: 314 Average loss: 202.8200\n",
      "====> Test set loss: 201.0357\n",
      "Train Epoch: 315 [0/32031 (0%)]\tLoss: 205.928635\n",
      "Train Epoch: 315 [1280/32031 (4%)]\tLoss: 204.870987\n",
      "Train Epoch: 315 [2560/32031 (8%)]\tLoss: 208.178528\n",
      "Train Epoch: 315 [3840/32031 (12%)]\tLoss: 203.574890\n",
      "Train Epoch: 315 [5120/32031 (16%)]\tLoss: 206.466614\n",
      "Train Epoch: 315 [6400/32031 (20%)]\tLoss: 199.179031\n",
      "Train Epoch: 315 [7680/32031 (24%)]\tLoss: 195.214417\n",
      "Train Epoch: 315 [8960/32031 (28%)]\tLoss: 203.323654\n",
      "Train Epoch: 315 [10240/32031 (32%)]\tLoss: 209.015900\n",
      "Train Epoch: 315 [11520/32031 (36%)]\tLoss: 200.203903\n",
      "Train Epoch: 315 [12800/32031 (40%)]\tLoss: 200.043213\n",
      "Train Epoch: 315 [14080/32031 (44%)]\tLoss: 213.386108\n",
      "Train Epoch: 315 [15360/32031 (48%)]\tLoss: 202.201996\n",
      "Train Epoch: 315 [16640/32031 (52%)]\tLoss: 202.576569\n",
      "Train Epoch: 315 [17920/32031 (56%)]\tLoss: 229.098251\n",
      "Train Epoch: 315 [19200/32031 (60%)]\tLoss: 207.560684\n",
      "Train Epoch: 315 [20480/32031 (64%)]\tLoss: 206.505371\n",
      "Train Epoch: 315 [21760/32031 (68%)]\tLoss: 197.100357\n",
      "Train Epoch: 315 [23040/32031 (72%)]\tLoss: 209.404633\n",
      "Train Epoch: 315 [24320/32031 (76%)]\tLoss: 192.877884\n",
      "Train Epoch: 315 [25600/32031 (80%)]\tLoss: 206.891541\n",
      "Train Epoch: 315 [26880/32031 (84%)]\tLoss: 196.431778\n",
      "Train Epoch: 315 [28160/32031 (88%)]\tLoss: 209.932755\n",
      "Train Epoch: 315 [29440/32031 (92%)]\tLoss: 206.076202\n",
      "Train Epoch: 315 [30720/32031 (96%)]\tLoss: 202.049377\n",
      "Train Epoch: 315 [7750/32031 (100%)]\tLoss: 213.658376\n",
      "====> Epoch: 315 Average loss: 202.8447\n",
      "====> Test set loss: 196.7811\n",
      "Train Epoch: 316 [0/32031 (0%)]\tLoss: 201.393372\n",
      "Train Epoch: 316 [1280/32031 (4%)]\tLoss: 203.239410\n",
      "Train Epoch: 316 [2560/32031 (8%)]\tLoss: 209.518555\n",
      "Train Epoch: 316 [3840/32031 (12%)]\tLoss: 206.362656\n",
      "Train Epoch: 316 [5120/32031 (16%)]\tLoss: 198.581726\n",
      "Train Epoch: 316 [6400/32031 (20%)]\tLoss: 196.277542\n",
      "Train Epoch: 316 [7680/32031 (24%)]\tLoss: 200.004532\n",
      "Train Epoch: 316 [8960/32031 (28%)]\tLoss: 197.056808\n",
      "Train Epoch: 316 [10240/32031 (32%)]\tLoss: 206.184982\n",
      "Train Epoch: 316 [11520/32031 (36%)]\tLoss: 193.947922\n",
      "Train Epoch: 316 [12800/32031 (40%)]\tLoss: 194.040863\n",
      "Train Epoch: 316 [14080/32031 (44%)]\tLoss: 204.823074\n",
      "Train Epoch: 316 [15360/32031 (48%)]\tLoss: 219.320892\n",
      "Train Epoch: 316 [16640/32031 (52%)]\tLoss: 204.203751\n",
      "Train Epoch: 316 [17920/32031 (56%)]\tLoss: 207.707214\n",
      "Train Epoch: 316 [19200/32031 (60%)]\tLoss: 209.157532\n",
      "Train Epoch: 316 [20480/32031 (64%)]\tLoss: 203.844177\n",
      "Train Epoch: 316 [21760/32031 (68%)]\tLoss: 201.341187\n",
      "Train Epoch: 316 [23040/32031 (72%)]\tLoss: 220.869720\n",
      "Train Epoch: 316 [24320/32031 (76%)]\tLoss: 196.613602\n",
      "Train Epoch: 316 [25600/32031 (80%)]\tLoss: 192.107269\n",
      "Train Epoch: 316 [26880/32031 (84%)]\tLoss: 205.036179\n",
      "Train Epoch: 316 [28160/32031 (88%)]\tLoss: 211.976013\n",
      "Train Epoch: 316 [29440/32031 (92%)]\tLoss: 214.532684\n",
      "Train Epoch: 316 [30720/32031 (96%)]\tLoss: 209.629700\n",
      "Train Epoch: 316 [7750/32031 (100%)]\tLoss: 196.976027\n",
      "====> Epoch: 316 Average loss: 202.6301\n",
      "====> Test set loss: 196.9065\n",
      "Train Epoch: 317 [0/32031 (0%)]\tLoss: 210.617859\n",
      "Train Epoch: 317 [1280/32031 (4%)]\tLoss: 207.788666\n",
      "Train Epoch: 317 [2560/32031 (8%)]\tLoss: 196.741913\n",
      "Train Epoch: 317 [3840/32031 (12%)]\tLoss: 209.169739\n",
      "Train Epoch: 317 [5120/32031 (16%)]\tLoss: 215.427109\n",
      "Train Epoch: 317 [6400/32031 (20%)]\tLoss: 198.881973\n",
      "Train Epoch: 317 [7680/32031 (24%)]\tLoss: 195.663620\n",
      "Train Epoch: 317 [8960/32031 (28%)]\tLoss: 189.229645\n",
      "Train Epoch: 317 [10240/32031 (32%)]\tLoss: 196.562332\n",
      "Train Epoch: 317 [11520/32031 (36%)]\tLoss: 210.438477\n",
      "Train Epoch: 317 [12800/32031 (40%)]\tLoss: 203.388443\n",
      "Train Epoch: 317 [14080/32031 (44%)]\tLoss: 193.224060\n",
      "Train Epoch: 317 [15360/32031 (48%)]\tLoss: 207.626785\n",
      "Train Epoch: 317 [16640/32031 (52%)]\tLoss: 218.398849\n",
      "Train Epoch: 317 [17920/32031 (56%)]\tLoss: 200.851654\n",
      "Train Epoch: 317 [19200/32031 (60%)]\tLoss: 209.481506\n",
      "Train Epoch: 317 [20480/32031 (64%)]\tLoss: 203.210159\n",
      "Train Epoch: 317 [21760/32031 (68%)]\tLoss: 206.269043\n",
      "Train Epoch: 317 [23040/32031 (72%)]\tLoss: 202.793671\n",
      "Train Epoch: 317 [24320/32031 (76%)]\tLoss: 211.977280\n",
      "Train Epoch: 317 [25600/32031 (80%)]\tLoss: 214.243759\n",
      "Train Epoch: 317 [26880/32031 (84%)]\tLoss: 203.007111\n",
      "Train Epoch: 317 [28160/32031 (88%)]\tLoss: 201.202454\n",
      "Train Epoch: 317 [29440/32031 (92%)]\tLoss: 209.857544\n",
      "Train Epoch: 317 [30720/32031 (96%)]\tLoss: 202.104126\n",
      "Train Epoch: 317 [7750/32031 (100%)]\tLoss: 211.787865\n",
      "====> Epoch: 317 Average loss: 202.4970\n",
      "====> Test set loss: 196.9852\n",
      "Train Epoch: 318 [0/32031 (0%)]\tLoss: 206.772308\n",
      "Train Epoch: 318 [1280/32031 (4%)]\tLoss: 199.595032\n",
      "Train Epoch: 318 [2560/32031 (8%)]\tLoss: 196.813614\n",
      "Train Epoch: 318 [3840/32031 (12%)]\tLoss: 211.995422\n",
      "Train Epoch: 318 [5120/32031 (16%)]\tLoss: 203.858154\n",
      "Train Epoch: 318 [6400/32031 (20%)]\tLoss: 198.424408\n",
      "Train Epoch: 318 [7680/32031 (24%)]\tLoss: 207.622147\n",
      "Train Epoch: 318 [8960/32031 (28%)]\tLoss: 208.124939\n",
      "Train Epoch: 318 [10240/32031 (32%)]\tLoss: 190.308334\n",
      "Train Epoch: 318 [11520/32031 (36%)]\tLoss: 200.205551\n",
      "Train Epoch: 318 [12800/32031 (40%)]\tLoss: 201.242752\n",
      "Train Epoch: 318 [14080/32031 (44%)]\tLoss: 193.823776\n",
      "Train Epoch: 318 [15360/32031 (48%)]\tLoss: 192.615112\n",
      "Train Epoch: 318 [16640/32031 (52%)]\tLoss: 195.293564\n",
      "Train Epoch: 318 [17920/32031 (56%)]\tLoss: 193.190552\n",
      "Train Epoch: 318 [19200/32031 (60%)]\tLoss: 213.875000\n",
      "Train Epoch: 318 [20480/32031 (64%)]\tLoss: 194.153854\n",
      "Train Epoch: 318 [21760/32031 (68%)]\tLoss: 215.871109\n",
      "Train Epoch: 318 [23040/32031 (72%)]\tLoss: 207.990616\n",
      "Train Epoch: 318 [24320/32031 (76%)]\tLoss: 197.277481\n",
      "Train Epoch: 318 [25600/32031 (80%)]\tLoss: 200.077194\n",
      "Train Epoch: 318 [26880/32031 (84%)]\tLoss: 193.251648\n",
      "Train Epoch: 318 [28160/32031 (88%)]\tLoss: 216.559952\n",
      "Train Epoch: 318 [29440/32031 (92%)]\tLoss: 202.507233\n",
      "Train Epoch: 318 [30720/32031 (96%)]\tLoss: 197.745026\n",
      "Train Epoch: 318 [7750/32031 (100%)]\tLoss: 208.234375\n",
      "====> Epoch: 318 Average loss: 202.8495\n",
      "====> Test set loss: 195.7923\n",
      "Train Epoch: 319 [0/32031 (0%)]\tLoss: 206.580933\n",
      "Train Epoch: 319 [1280/32031 (4%)]\tLoss: 191.303391\n",
      "Train Epoch: 319 [2560/32031 (8%)]\tLoss: 205.126984\n",
      "Train Epoch: 319 [3840/32031 (12%)]\tLoss: 191.097488\n",
      "Train Epoch: 319 [5120/32031 (16%)]\tLoss: 208.708328\n",
      "Train Epoch: 319 [6400/32031 (20%)]\tLoss: 202.716049\n",
      "Train Epoch: 319 [7680/32031 (24%)]\tLoss: 189.741730\n",
      "Train Epoch: 319 [8960/32031 (28%)]\tLoss: 193.851669\n",
      "Train Epoch: 319 [10240/32031 (32%)]\tLoss: 199.849564\n",
      "Train Epoch: 319 [11520/32031 (36%)]\tLoss: 196.438507\n",
      "Train Epoch: 319 [12800/32031 (40%)]\tLoss: 194.682007\n",
      "Train Epoch: 319 [14080/32031 (44%)]\tLoss: 191.266052\n",
      "Train Epoch: 319 [15360/32031 (48%)]\tLoss: 194.089569\n",
      "Train Epoch: 319 [16640/32031 (52%)]\tLoss: 208.817627\n",
      "Train Epoch: 319 [17920/32031 (56%)]\tLoss: 205.610077\n",
      "Train Epoch: 319 [19200/32031 (60%)]\tLoss: 207.327301\n",
      "Train Epoch: 319 [20480/32031 (64%)]\tLoss: 200.640869\n",
      "Train Epoch: 319 [21760/32031 (68%)]\tLoss: 206.694016\n",
      "Train Epoch: 319 [23040/32031 (72%)]\tLoss: 196.880173\n",
      "Train Epoch: 319 [24320/32031 (76%)]\tLoss: 205.677887\n",
      "Train Epoch: 319 [25600/32031 (80%)]\tLoss: 200.898560\n",
      "Train Epoch: 319 [26880/32031 (84%)]\tLoss: 201.900482\n",
      "Train Epoch: 319 [28160/32031 (88%)]\tLoss: 198.905090\n",
      "Train Epoch: 319 [29440/32031 (92%)]\tLoss: 198.344040\n",
      "Train Epoch: 319 [30720/32031 (96%)]\tLoss: 209.574646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 319 [7750/32031 (100%)]\tLoss: 195.172600\n",
      "====> Epoch: 319 Average loss: 202.6939\n",
      "====> Test set loss: 198.5510\n",
      "Train Epoch: 320 [0/32031 (0%)]\tLoss: 200.344177\n",
      "Train Epoch: 320 [1280/32031 (4%)]\tLoss: 204.701721\n",
      "Train Epoch: 320 [2560/32031 (8%)]\tLoss: 193.339569\n",
      "Train Epoch: 320 [3840/32031 (12%)]\tLoss: 191.059082\n",
      "Train Epoch: 320 [5120/32031 (16%)]\tLoss: 207.221024\n",
      "Train Epoch: 320 [6400/32031 (20%)]\tLoss: 196.677246\n",
      "Train Epoch: 320 [7680/32031 (24%)]\tLoss: 194.749863\n",
      "Train Epoch: 320 [8960/32031 (28%)]\tLoss: 204.909485\n",
      "Train Epoch: 320 [10240/32031 (32%)]\tLoss: 193.374069\n",
      "Train Epoch: 320 [11520/32031 (36%)]\tLoss: 196.032822\n",
      "Train Epoch: 320 [12800/32031 (40%)]\tLoss: 205.701645\n",
      "Train Epoch: 320 [14080/32031 (44%)]\tLoss: 199.990570\n",
      "Train Epoch: 320 [15360/32031 (48%)]\tLoss: 200.399887\n",
      "Train Epoch: 320 [16640/32031 (52%)]\tLoss: 222.477188\n",
      "Train Epoch: 320 [17920/32031 (56%)]\tLoss: 201.999512\n",
      "Train Epoch: 320 [19200/32031 (60%)]\tLoss: 205.707428\n",
      "Train Epoch: 320 [20480/32031 (64%)]\tLoss: 202.312515\n",
      "Train Epoch: 320 [21760/32031 (68%)]\tLoss: 197.633163\n",
      "Train Epoch: 320 [23040/32031 (72%)]\tLoss: 201.556000\n",
      "Train Epoch: 320 [24320/32031 (76%)]\tLoss: 210.126709\n",
      "Train Epoch: 320 [25600/32031 (80%)]\tLoss: 195.235077\n",
      "Train Epoch: 320 [26880/32031 (84%)]\tLoss: 199.319275\n",
      "Train Epoch: 320 [28160/32031 (88%)]\tLoss: 196.935196\n",
      "Train Epoch: 320 [29440/32031 (92%)]\tLoss: 193.638397\n",
      "Train Epoch: 320 [30720/32031 (96%)]\tLoss: 203.238876\n",
      "Train Epoch: 320 [7750/32031 (100%)]\tLoss: 202.626544\n",
      "====> Epoch: 320 Average loss: 202.3139\n",
      "====> Test set loss: 195.6029\n",
      "Train Epoch: 321 [0/32031 (0%)]\tLoss: 206.923645\n",
      "Train Epoch: 321 [1280/32031 (4%)]\tLoss: 192.130829\n",
      "Train Epoch: 321 [2560/32031 (8%)]\tLoss: 201.619797\n",
      "Train Epoch: 321 [3840/32031 (12%)]\tLoss: 202.075912\n",
      "Train Epoch: 321 [5120/32031 (16%)]\tLoss: 194.731415\n",
      "Train Epoch: 321 [6400/32031 (20%)]\tLoss: 201.453537\n",
      "Train Epoch: 321 [7680/32031 (24%)]\tLoss: 204.729507\n",
      "Train Epoch: 321 [8960/32031 (28%)]\tLoss: 202.011551\n",
      "Train Epoch: 321 [10240/32031 (32%)]\tLoss: 193.336044\n",
      "Train Epoch: 321 [11520/32031 (36%)]\tLoss: 201.938354\n",
      "Train Epoch: 321 [12800/32031 (40%)]\tLoss: 197.018112\n",
      "Train Epoch: 321 [14080/32031 (44%)]\tLoss: 204.700180\n",
      "Train Epoch: 321 [15360/32031 (48%)]\tLoss: 210.227615\n",
      "Train Epoch: 321 [16640/32031 (52%)]\tLoss: 198.267258\n",
      "Train Epoch: 321 [17920/32031 (56%)]\tLoss: 193.907913\n",
      "Train Epoch: 321 [19200/32031 (60%)]\tLoss: 219.716858\n",
      "Train Epoch: 321 [20480/32031 (64%)]\tLoss: 211.962158\n",
      "Train Epoch: 321 [21760/32031 (68%)]\tLoss: 214.677933\n",
      "Train Epoch: 321 [23040/32031 (72%)]\tLoss: 196.079620\n",
      "Train Epoch: 321 [24320/32031 (76%)]\tLoss: 208.429916\n",
      "Train Epoch: 321 [25600/32031 (80%)]\tLoss: 195.036255\n",
      "Train Epoch: 321 [26880/32031 (84%)]\tLoss: 207.422989\n",
      "Train Epoch: 321 [28160/32031 (88%)]\tLoss: 208.333099\n",
      "Train Epoch: 321 [29440/32031 (92%)]\tLoss: 201.561508\n",
      "Train Epoch: 321 [30720/32031 (96%)]\tLoss: 187.206055\n",
      "Train Epoch: 321 [7750/32031 (100%)]\tLoss: 220.661605\n",
      "====> Epoch: 321 Average loss: 202.5506\n",
      "====> Test set loss: 197.7145\n",
      "Train Epoch: 322 [0/32031 (0%)]\tLoss: 202.495911\n",
      "Train Epoch: 322 [1280/32031 (4%)]\tLoss: 199.367462\n",
      "Train Epoch: 322 [2560/32031 (8%)]\tLoss: 208.959503\n",
      "Train Epoch: 322 [3840/32031 (12%)]\tLoss: 205.764038\n",
      "Train Epoch: 322 [5120/32031 (16%)]\tLoss: 200.088577\n",
      "Train Epoch: 322 [6400/32031 (20%)]\tLoss: 206.954666\n",
      "Train Epoch: 322 [7680/32031 (24%)]\tLoss: 199.460541\n",
      "Train Epoch: 322 [8960/32031 (28%)]\tLoss: 201.659607\n",
      "Train Epoch: 322 [10240/32031 (32%)]\tLoss: 217.375610\n",
      "Train Epoch: 322 [11520/32031 (36%)]\tLoss: 201.553024\n",
      "Train Epoch: 322 [12800/32031 (40%)]\tLoss: 201.566483\n",
      "Train Epoch: 322 [14080/32031 (44%)]\tLoss: 201.464310\n",
      "Train Epoch: 322 [15360/32031 (48%)]\tLoss: 203.175095\n",
      "Train Epoch: 322 [16640/32031 (52%)]\tLoss: 211.887009\n",
      "Train Epoch: 322 [17920/32031 (56%)]\tLoss: 196.753098\n",
      "Train Epoch: 322 [19200/32031 (60%)]\tLoss: 200.611511\n",
      "Train Epoch: 322 [20480/32031 (64%)]\tLoss: 197.268661\n",
      "Train Epoch: 322 [21760/32031 (68%)]\tLoss: 210.803375\n",
      "Train Epoch: 322 [23040/32031 (72%)]\tLoss: 215.984070\n",
      "Train Epoch: 322 [24320/32031 (76%)]\tLoss: 204.156158\n",
      "Train Epoch: 322 [25600/32031 (80%)]\tLoss: 206.914780\n",
      "Train Epoch: 322 [26880/32031 (84%)]\tLoss: 199.936737\n",
      "Train Epoch: 322 [28160/32031 (88%)]\tLoss: 210.769226\n",
      "Train Epoch: 322 [29440/32031 (92%)]\tLoss: 203.624237\n",
      "Train Epoch: 322 [30720/32031 (96%)]\tLoss: 197.432587\n",
      "Train Epoch: 322 [7750/32031 (100%)]\tLoss: 186.314563\n",
      "====> Epoch: 322 Average loss: 202.6477\n",
      "====> Test set loss: 198.5246\n",
      "Train Epoch: 323 [0/32031 (0%)]\tLoss: 212.397293\n",
      "Train Epoch: 323 [1280/32031 (4%)]\tLoss: 202.000031\n",
      "Train Epoch: 323 [2560/32031 (8%)]\tLoss: 205.646545\n",
      "Train Epoch: 323 [3840/32031 (12%)]\tLoss: 196.397598\n",
      "Train Epoch: 323 [5120/32031 (16%)]\tLoss: 203.891678\n",
      "Train Epoch: 323 [6400/32031 (20%)]\tLoss: 210.619461\n",
      "Train Epoch: 323 [7680/32031 (24%)]\tLoss: 208.814651\n",
      "Train Epoch: 323 [8960/32031 (28%)]\tLoss: 204.972870\n",
      "Train Epoch: 323 [10240/32031 (32%)]\tLoss: 202.698364\n",
      "Train Epoch: 323 [11520/32031 (36%)]\tLoss: 202.144958\n",
      "Train Epoch: 323 [12800/32031 (40%)]\tLoss: 205.778580\n",
      "Train Epoch: 323 [14080/32031 (44%)]\tLoss: 193.431061\n",
      "Train Epoch: 323 [15360/32031 (48%)]\tLoss: 210.194534\n",
      "Train Epoch: 323 [16640/32031 (52%)]\tLoss: 207.236099\n",
      "Train Epoch: 323 [17920/32031 (56%)]\tLoss: 207.939514\n",
      "Train Epoch: 323 [19200/32031 (60%)]\tLoss: 196.993408\n",
      "Train Epoch: 323 [20480/32031 (64%)]\tLoss: 205.382858\n",
      "Train Epoch: 323 [21760/32031 (68%)]\tLoss: 204.456848\n",
      "Train Epoch: 323 [23040/32031 (72%)]\tLoss: 202.144669\n",
      "Train Epoch: 323 [24320/32031 (76%)]\tLoss: 207.036850\n",
      "Train Epoch: 323 [25600/32031 (80%)]\tLoss: 206.759003\n",
      "Train Epoch: 323 [26880/32031 (84%)]\tLoss: 204.288345\n",
      "Train Epoch: 323 [28160/32031 (88%)]\tLoss: 202.975586\n",
      "Train Epoch: 323 [29440/32031 (92%)]\tLoss: 190.911636\n",
      "Train Epoch: 323 [30720/32031 (96%)]\tLoss: 192.082092\n",
      "Train Epoch: 323 [7750/32031 (100%)]\tLoss: 241.824943\n",
      "====> Epoch: 323 Average loss: 202.5648\n",
      "====> Test set loss: 196.2910\n",
      "Train Epoch: 324 [0/32031 (0%)]\tLoss: 199.560257\n",
      "Train Epoch: 324 [1280/32031 (4%)]\tLoss: 194.625656\n",
      "Train Epoch: 324 [2560/32031 (8%)]\tLoss: 210.598602\n",
      "Train Epoch: 324 [3840/32031 (12%)]\tLoss: 208.934875\n",
      "Train Epoch: 324 [5120/32031 (16%)]\tLoss: 203.976685\n",
      "Train Epoch: 324 [6400/32031 (20%)]\tLoss: 207.709702\n",
      "Train Epoch: 324 [7680/32031 (24%)]\tLoss: 216.175507\n",
      "Train Epoch: 324 [8960/32031 (28%)]\tLoss: 204.220490\n",
      "Train Epoch: 324 [10240/32031 (32%)]\tLoss: 206.728546\n",
      "Train Epoch: 324 [11520/32031 (36%)]\tLoss: 190.740814\n",
      "Train Epoch: 324 [12800/32031 (40%)]\tLoss: 199.987579\n",
      "Train Epoch: 324 [14080/32031 (44%)]\tLoss: 199.813614\n",
      "Train Epoch: 324 [15360/32031 (48%)]\tLoss: 208.547699\n",
      "Train Epoch: 324 [16640/32031 (52%)]\tLoss: 205.585602\n",
      "Train Epoch: 324 [17920/32031 (56%)]\tLoss: 212.122849\n",
      "Train Epoch: 324 [19200/32031 (60%)]\tLoss: 209.879944\n",
      "Train Epoch: 324 [20480/32031 (64%)]\tLoss: 200.249725\n",
      "Train Epoch: 324 [21760/32031 (68%)]\tLoss: 193.137482\n",
      "Train Epoch: 324 [23040/32031 (72%)]\tLoss: 199.233887\n",
      "Train Epoch: 324 [24320/32031 (76%)]\tLoss: 205.181061\n",
      "Train Epoch: 324 [25600/32031 (80%)]\tLoss: 196.576797\n",
      "Train Epoch: 324 [26880/32031 (84%)]\tLoss: 203.695404\n",
      "Train Epoch: 324 [28160/32031 (88%)]\tLoss: 189.918045\n",
      "Train Epoch: 324 [29440/32031 (92%)]\tLoss: 199.706146\n",
      "Train Epoch: 324 [30720/32031 (96%)]\tLoss: 210.314865\n",
      "Train Epoch: 324 [7750/32031 (100%)]\tLoss: 188.955283\n",
      "====> Epoch: 324 Average loss: 202.4297\n",
      "====> Test set loss: 194.5816\n",
      "Train Epoch: 325 [0/32031 (0%)]\tLoss: 193.466064\n",
      "Train Epoch: 325 [1280/32031 (4%)]\tLoss: 197.809814\n",
      "Train Epoch: 325 [2560/32031 (8%)]\tLoss: 203.198929\n",
      "Train Epoch: 325 [3840/32031 (12%)]\tLoss: 193.091019\n",
      "Train Epoch: 325 [5120/32031 (16%)]\tLoss: 199.934357\n",
      "Train Epoch: 325 [6400/32031 (20%)]\tLoss: 193.790314\n",
      "Train Epoch: 325 [7680/32031 (24%)]\tLoss: 205.840393\n",
      "Train Epoch: 325 [8960/32031 (28%)]\tLoss: 205.248627\n",
      "Train Epoch: 325 [10240/32031 (32%)]\tLoss: 194.817383\n",
      "Train Epoch: 325 [11520/32031 (36%)]\tLoss: 192.623535\n",
      "Train Epoch: 325 [12800/32031 (40%)]\tLoss: 201.820831\n",
      "Train Epoch: 325 [14080/32031 (44%)]\tLoss: 207.002274\n",
      "Train Epoch: 325 [15360/32031 (48%)]\tLoss: 202.328751\n",
      "Train Epoch: 325 [16640/32031 (52%)]\tLoss: 203.704407\n",
      "Train Epoch: 325 [17920/32031 (56%)]\tLoss: 193.454086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 325 [19200/32031 (60%)]\tLoss: 213.623199\n",
      "Train Epoch: 325 [20480/32031 (64%)]\tLoss: 190.731720\n",
      "Train Epoch: 325 [21760/32031 (68%)]\tLoss: 215.461472\n",
      "Train Epoch: 325 [23040/32031 (72%)]\tLoss: 201.354355\n",
      "Train Epoch: 325 [24320/32031 (76%)]\tLoss: 215.120651\n",
      "Train Epoch: 325 [25600/32031 (80%)]\tLoss: 197.484879\n",
      "Train Epoch: 325 [26880/32031 (84%)]\tLoss: 201.607010\n",
      "Train Epoch: 325 [28160/32031 (88%)]\tLoss: 214.247772\n",
      "Train Epoch: 325 [29440/32031 (92%)]\tLoss: 207.213882\n",
      "Train Epoch: 325 [30720/32031 (96%)]\tLoss: 207.173782\n",
      "Train Epoch: 325 [7750/32031 (100%)]\tLoss: 196.208102\n",
      "====> Epoch: 325 Average loss: 202.9940\n",
      "====> Test set loss: 196.5480\n",
      "Train Epoch: 326 [0/32031 (0%)]\tLoss: 197.516907\n",
      "Train Epoch: 326 [1280/32031 (4%)]\tLoss: 197.260498\n",
      "Train Epoch: 326 [2560/32031 (8%)]\tLoss: 196.861465\n",
      "Train Epoch: 326 [3840/32031 (12%)]\tLoss: 197.247772\n",
      "Train Epoch: 326 [5120/32031 (16%)]\tLoss: 205.167313\n",
      "Train Epoch: 326 [6400/32031 (20%)]\tLoss: 196.195190\n",
      "Train Epoch: 326 [7680/32031 (24%)]\tLoss: 199.654724\n",
      "Train Epoch: 326 [8960/32031 (28%)]\tLoss: 203.648056\n",
      "Train Epoch: 326 [10240/32031 (32%)]\tLoss: 197.867157\n",
      "Train Epoch: 326 [11520/32031 (36%)]\tLoss: 212.058151\n",
      "Train Epoch: 326 [12800/32031 (40%)]\tLoss: 211.033035\n",
      "Train Epoch: 326 [14080/32031 (44%)]\tLoss: 209.540070\n",
      "Train Epoch: 326 [15360/32031 (48%)]\tLoss: 211.307129\n",
      "Train Epoch: 326 [16640/32031 (52%)]\tLoss: 208.870728\n",
      "Train Epoch: 326 [17920/32031 (56%)]\tLoss: 206.912384\n",
      "Train Epoch: 326 [19200/32031 (60%)]\tLoss: 197.669189\n",
      "Train Epoch: 326 [20480/32031 (64%)]\tLoss: 211.295807\n",
      "Train Epoch: 326 [21760/32031 (68%)]\tLoss: 201.546860\n",
      "Train Epoch: 326 [23040/32031 (72%)]\tLoss: 204.857086\n",
      "Train Epoch: 326 [24320/32031 (76%)]\tLoss: 203.908157\n",
      "Train Epoch: 326 [25600/32031 (80%)]\tLoss: 203.267120\n",
      "Train Epoch: 326 [26880/32031 (84%)]\tLoss: 210.329788\n",
      "Train Epoch: 326 [28160/32031 (88%)]\tLoss: 199.181366\n",
      "Train Epoch: 326 [29440/32031 (92%)]\tLoss: 206.927246\n",
      "Train Epoch: 326 [30720/32031 (96%)]\tLoss: 223.412659\n",
      "Train Epoch: 326 [7750/32031 (100%)]\tLoss: 203.589529\n",
      "====> Epoch: 326 Average loss: 202.5484\n",
      "====> Test set loss: 198.8304\n",
      "Train Epoch: 327 [0/32031 (0%)]\tLoss: 195.597321\n",
      "Train Epoch: 327 [1280/32031 (4%)]\tLoss: 195.232712\n",
      "Train Epoch: 327 [2560/32031 (8%)]\tLoss: 201.827118\n",
      "Train Epoch: 327 [3840/32031 (12%)]\tLoss: 193.409851\n",
      "Train Epoch: 327 [5120/32031 (16%)]\tLoss: 204.334091\n",
      "Train Epoch: 327 [6400/32031 (20%)]\tLoss: 203.268204\n",
      "Train Epoch: 327 [7680/32031 (24%)]\tLoss: 189.187073\n",
      "Train Epoch: 327 [8960/32031 (28%)]\tLoss: 197.980392\n",
      "Train Epoch: 327 [10240/32031 (32%)]\tLoss: 221.734970\n",
      "Train Epoch: 327 [11520/32031 (36%)]\tLoss: 205.733093\n",
      "Train Epoch: 327 [12800/32031 (40%)]\tLoss: 189.895309\n",
      "Train Epoch: 327 [14080/32031 (44%)]\tLoss: 192.010223\n",
      "Train Epoch: 327 [15360/32031 (48%)]\tLoss: 197.681122\n",
      "Train Epoch: 327 [16640/32031 (52%)]\tLoss: 216.992294\n",
      "Train Epoch: 327 [17920/32031 (56%)]\tLoss: 202.184402\n",
      "Train Epoch: 327 [19200/32031 (60%)]\tLoss: 200.572113\n",
      "Train Epoch: 327 [20480/32031 (64%)]\tLoss: 205.213425\n",
      "Train Epoch: 327 [21760/32031 (68%)]\tLoss: 206.470306\n",
      "Train Epoch: 327 [23040/32031 (72%)]\tLoss: 207.552597\n",
      "Train Epoch: 327 [24320/32031 (76%)]\tLoss: 196.959488\n",
      "Train Epoch: 327 [25600/32031 (80%)]\tLoss: 208.540802\n",
      "Train Epoch: 327 [26880/32031 (84%)]\tLoss: 200.576614\n",
      "Train Epoch: 327 [28160/32031 (88%)]\tLoss: 216.108154\n",
      "Train Epoch: 327 [29440/32031 (92%)]\tLoss: 202.694244\n",
      "Train Epoch: 327 [30720/32031 (96%)]\tLoss: 215.718353\n",
      "Train Epoch: 327 [7750/32031 (100%)]\tLoss: 192.926411\n",
      "====> Epoch: 327 Average loss: 202.2378\n",
      "====> Test set loss: 194.8911\n",
      "Train Epoch: 328 [0/32031 (0%)]\tLoss: 206.581924\n",
      "Train Epoch: 328 [1280/32031 (4%)]\tLoss: 201.649475\n",
      "Train Epoch: 328 [2560/32031 (8%)]\tLoss: 200.757401\n",
      "Train Epoch: 328 [3840/32031 (12%)]\tLoss: 205.009888\n",
      "Train Epoch: 328 [5120/32031 (16%)]\tLoss: 201.874054\n",
      "Train Epoch: 328 [6400/32031 (20%)]\tLoss: 208.581665\n",
      "Train Epoch: 328 [7680/32031 (24%)]\tLoss: 203.928574\n",
      "Train Epoch: 328 [8960/32031 (28%)]\tLoss: 200.559113\n",
      "Train Epoch: 328 [10240/32031 (32%)]\tLoss: 191.338593\n",
      "Train Epoch: 328 [11520/32031 (36%)]\tLoss: 200.110352\n",
      "Train Epoch: 328 [12800/32031 (40%)]\tLoss: 215.068939\n",
      "Train Epoch: 328 [14080/32031 (44%)]\tLoss: 201.319031\n",
      "Train Epoch: 328 [15360/32031 (48%)]\tLoss: 209.400085\n",
      "Train Epoch: 328 [16640/32031 (52%)]\tLoss: 200.465286\n",
      "Train Epoch: 328 [17920/32031 (56%)]\tLoss: 202.383972\n",
      "Train Epoch: 328 [19200/32031 (60%)]\tLoss: 192.972702\n",
      "Train Epoch: 328 [20480/32031 (64%)]\tLoss: 202.911240\n",
      "Train Epoch: 328 [21760/32031 (68%)]\tLoss: 221.547760\n",
      "Train Epoch: 328 [23040/32031 (72%)]\tLoss: 192.073685\n",
      "Train Epoch: 328 [24320/32031 (76%)]\tLoss: 197.435043\n",
      "Train Epoch: 328 [25600/32031 (80%)]\tLoss: 205.844482\n",
      "Train Epoch: 328 [26880/32031 (84%)]\tLoss: 206.902451\n",
      "Train Epoch: 328 [28160/32031 (88%)]\tLoss: 198.271164\n",
      "Train Epoch: 328 [29440/32031 (92%)]\tLoss: 196.656433\n",
      "Train Epoch: 328 [30720/32031 (96%)]\tLoss: 200.851151\n",
      "Train Epoch: 328 [7750/32031 (100%)]\tLoss: 190.815130\n",
      "====> Epoch: 328 Average loss: 202.4386\n",
      "====> Test set loss: 197.0796\n",
      "Train Epoch: 329 [0/32031 (0%)]\tLoss: 209.737259\n",
      "Train Epoch: 329 [1280/32031 (4%)]\tLoss: 193.523880\n",
      "Train Epoch: 329 [2560/32031 (8%)]\tLoss: 200.504395\n",
      "Train Epoch: 329 [3840/32031 (12%)]\tLoss: 195.563492\n",
      "Train Epoch: 329 [5120/32031 (16%)]\tLoss: 198.098724\n",
      "Train Epoch: 329 [6400/32031 (20%)]\tLoss: 194.783478\n",
      "Train Epoch: 329 [7680/32031 (24%)]\tLoss: 203.449768\n",
      "Train Epoch: 329 [8960/32031 (28%)]\tLoss: 210.863953\n",
      "Train Epoch: 329 [10240/32031 (32%)]\tLoss: 203.398621\n",
      "Train Epoch: 329 [11520/32031 (36%)]\tLoss: 200.640961\n",
      "Train Epoch: 329 [12800/32031 (40%)]\tLoss: 196.351562\n",
      "Train Epoch: 329 [14080/32031 (44%)]\tLoss: 205.162216\n",
      "Train Epoch: 329 [15360/32031 (48%)]\tLoss: 192.907318\n",
      "Train Epoch: 329 [16640/32031 (52%)]\tLoss: 194.447052\n",
      "Train Epoch: 329 [17920/32031 (56%)]\tLoss: 202.665405\n",
      "Train Epoch: 329 [19200/32031 (60%)]\tLoss: 190.648636\n",
      "Train Epoch: 329 [20480/32031 (64%)]\tLoss: 211.243668\n",
      "Train Epoch: 329 [21760/32031 (68%)]\tLoss: 205.298355\n",
      "Train Epoch: 329 [23040/32031 (72%)]\tLoss: 212.098984\n",
      "Train Epoch: 329 [24320/32031 (76%)]\tLoss: 189.420441\n",
      "Train Epoch: 329 [25600/32031 (80%)]\tLoss: 199.829056\n",
      "Train Epoch: 329 [26880/32031 (84%)]\tLoss: 197.908936\n",
      "Train Epoch: 329 [28160/32031 (88%)]\tLoss: 194.189636\n",
      "Train Epoch: 329 [29440/32031 (92%)]\tLoss: 204.401016\n",
      "Train Epoch: 329 [30720/32031 (96%)]\tLoss: 212.008575\n",
      "Train Epoch: 329 [7750/32031 (100%)]\tLoss: 224.579511\n",
      "====> Epoch: 329 Average loss: 202.2293\n",
      "====> Test set loss: 196.0821\n",
      "Train Epoch: 330 [0/32031 (0%)]\tLoss: 206.071655\n",
      "Train Epoch: 330 [1280/32031 (4%)]\tLoss: 205.678802\n",
      "Train Epoch: 330 [2560/32031 (8%)]\tLoss: 204.638657\n",
      "Train Epoch: 330 [3840/32031 (12%)]\tLoss: 206.958710\n",
      "Train Epoch: 330 [5120/32031 (16%)]\tLoss: 203.803421\n",
      "Train Epoch: 330 [6400/32031 (20%)]\tLoss: 199.126526\n",
      "Train Epoch: 330 [7680/32031 (24%)]\tLoss: 204.451035\n",
      "Train Epoch: 330 [8960/32031 (28%)]\tLoss: 192.773041\n",
      "Train Epoch: 330 [10240/32031 (32%)]\tLoss: 191.739502\n",
      "Train Epoch: 330 [11520/32031 (36%)]\tLoss: 197.084442\n",
      "Train Epoch: 330 [12800/32031 (40%)]\tLoss: 197.358505\n",
      "Train Epoch: 330 [14080/32031 (44%)]\tLoss: 201.766602\n",
      "Train Epoch: 330 [15360/32031 (48%)]\tLoss: 205.178253\n",
      "Train Epoch: 330 [16640/32031 (52%)]\tLoss: 202.302277\n",
      "Train Epoch: 330 [17920/32031 (56%)]\tLoss: 214.782623\n",
      "Train Epoch: 330 [19200/32031 (60%)]\tLoss: 206.906174\n",
      "Train Epoch: 330 [20480/32031 (64%)]\tLoss: 197.016739\n",
      "Train Epoch: 330 [21760/32031 (68%)]\tLoss: 202.436325\n",
      "Train Epoch: 330 [23040/32031 (72%)]\tLoss: 195.337433\n",
      "Train Epoch: 330 [24320/32031 (76%)]\tLoss: 201.688751\n",
      "Train Epoch: 330 [25600/32031 (80%)]\tLoss: 201.274200\n",
      "Train Epoch: 330 [26880/32031 (84%)]\tLoss: 207.482681\n",
      "Train Epoch: 330 [28160/32031 (88%)]\tLoss: 202.786087\n",
      "Train Epoch: 330 [29440/32031 (92%)]\tLoss: 198.916000\n",
      "Train Epoch: 330 [30720/32031 (96%)]\tLoss: 215.421875\n",
      "Train Epoch: 330 [7750/32031 (100%)]\tLoss: 221.021374\n",
      "====> Epoch: 330 Average loss: 202.2537\n",
      "====> Test set loss: 195.9781\n",
      "Train Epoch: 331 [0/32031 (0%)]\tLoss: 202.953186\n",
      "Train Epoch: 331 [1280/32031 (4%)]\tLoss: 196.214951\n",
      "Train Epoch: 331 [2560/32031 (8%)]\tLoss: 202.512787\n",
      "Train Epoch: 331 [3840/32031 (12%)]\tLoss: 203.023636\n",
      "Train Epoch: 331 [5120/32031 (16%)]\tLoss: 209.128738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 331 [6400/32031 (20%)]\tLoss: 200.316864\n",
      "Train Epoch: 331 [7680/32031 (24%)]\tLoss: 200.264191\n",
      "Train Epoch: 331 [8960/32031 (28%)]\tLoss: 195.147583\n",
      "Train Epoch: 331 [10240/32031 (32%)]\tLoss: 212.236145\n",
      "Train Epoch: 331 [11520/32031 (36%)]\tLoss: 203.718185\n",
      "Train Epoch: 331 [12800/32031 (40%)]\tLoss: 196.110962\n",
      "Train Epoch: 331 [14080/32031 (44%)]\tLoss: 187.902237\n",
      "Train Epoch: 331 [15360/32031 (48%)]\tLoss: 203.706284\n",
      "Train Epoch: 331 [16640/32031 (52%)]\tLoss: 203.514862\n",
      "Train Epoch: 331 [17920/32031 (56%)]\tLoss: 209.958588\n",
      "Train Epoch: 331 [19200/32031 (60%)]\tLoss: 205.883163\n",
      "Train Epoch: 331 [20480/32031 (64%)]\tLoss: 206.486374\n",
      "Train Epoch: 331 [21760/32031 (68%)]\tLoss: 213.391174\n",
      "Train Epoch: 331 [23040/32031 (72%)]\tLoss: 199.476135\n",
      "Train Epoch: 331 [24320/32031 (76%)]\tLoss: 206.265152\n",
      "Train Epoch: 331 [25600/32031 (80%)]\tLoss: 206.428070\n",
      "Train Epoch: 331 [26880/32031 (84%)]\tLoss: 202.960587\n",
      "Train Epoch: 331 [28160/32031 (88%)]\tLoss: 201.507248\n",
      "Train Epoch: 331 [29440/32031 (92%)]\tLoss: 194.202911\n",
      "Train Epoch: 331 [30720/32031 (96%)]\tLoss: 210.682404\n",
      "Train Epoch: 331 [7750/32031 (100%)]\tLoss: 178.710922\n",
      "====> Epoch: 331 Average loss: 202.5389\n",
      "====> Test set loss: 197.8848\n",
      "Train Epoch: 332 [0/32031 (0%)]\tLoss: 195.182312\n",
      "Train Epoch: 332 [1280/32031 (4%)]\tLoss: 205.447418\n",
      "Train Epoch: 332 [2560/32031 (8%)]\tLoss: 201.431992\n",
      "Train Epoch: 332 [3840/32031 (12%)]\tLoss: 201.104218\n",
      "Train Epoch: 332 [5120/32031 (16%)]\tLoss: 195.533951\n",
      "Train Epoch: 332 [6400/32031 (20%)]\tLoss: 214.768906\n",
      "Train Epoch: 332 [7680/32031 (24%)]\tLoss: 194.385315\n",
      "Train Epoch: 332 [8960/32031 (28%)]\tLoss: 202.205368\n",
      "Train Epoch: 332 [10240/32031 (32%)]\tLoss: 214.085251\n",
      "Train Epoch: 332 [11520/32031 (36%)]\tLoss: 205.222519\n",
      "Train Epoch: 332 [12800/32031 (40%)]\tLoss: 194.506439\n",
      "Train Epoch: 332 [14080/32031 (44%)]\tLoss: 199.471130\n",
      "Train Epoch: 332 [15360/32031 (48%)]\tLoss: 198.883026\n",
      "Train Epoch: 332 [16640/32031 (52%)]\tLoss: 197.020996\n",
      "Train Epoch: 332 [17920/32031 (56%)]\tLoss: 195.943512\n",
      "Train Epoch: 332 [19200/32031 (60%)]\tLoss: 201.643082\n",
      "Train Epoch: 332 [20480/32031 (64%)]\tLoss: 195.580017\n",
      "Train Epoch: 332 [21760/32031 (68%)]\tLoss: 206.716400\n",
      "Train Epoch: 332 [23040/32031 (72%)]\tLoss: 199.658279\n",
      "Train Epoch: 332 [24320/32031 (76%)]\tLoss: 191.378220\n",
      "Train Epoch: 332 [25600/32031 (80%)]\tLoss: 212.550140\n",
      "Train Epoch: 332 [26880/32031 (84%)]\tLoss: 190.180786\n",
      "Train Epoch: 332 [28160/32031 (88%)]\tLoss: 207.334198\n",
      "Train Epoch: 332 [29440/32031 (92%)]\tLoss: 203.248505\n",
      "Train Epoch: 332 [30720/32031 (96%)]\tLoss: 199.546768\n",
      "Train Epoch: 332 [7750/32031 (100%)]\tLoss: 194.400265\n",
      "====> Epoch: 332 Average loss: 202.2311\n",
      "====> Test set loss: 197.1828\n",
      "Train Epoch: 333 [0/32031 (0%)]\tLoss: 200.807617\n",
      "Train Epoch: 333 [1280/32031 (4%)]\tLoss: 195.185135\n",
      "Train Epoch: 333 [2560/32031 (8%)]\tLoss: 198.231979\n",
      "Train Epoch: 333 [3840/32031 (12%)]\tLoss: 199.902145\n",
      "Train Epoch: 333 [5120/32031 (16%)]\tLoss: 204.276474\n",
      "Train Epoch: 333 [6400/32031 (20%)]\tLoss: 211.874710\n",
      "Train Epoch: 333 [7680/32031 (24%)]\tLoss: 204.673767\n",
      "Train Epoch: 333 [8960/32031 (28%)]\tLoss: 201.242554\n",
      "Train Epoch: 333 [10240/32031 (32%)]\tLoss: 205.808121\n",
      "Train Epoch: 333 [11520/32031 (36%)]\tLoss: 213.944260\n",
      "Train Epoch: 333 [12800/32031 (40%)]\tLoss: 207.028244\n",
      "Train Epoch: 333 [14080/32031 (44%)]\tLoss: 201.507675\n",
      "Train Epoch: 333 [15360/32031 (48%)]\tLoss: 215.203156\n",
      "Train Epoch: 333 [16640/32031 (52%)]\tLoss: 208.818787\n",
      "Train Epoch: 333 [17920/32031 (56%)]\tLoss: 196.513046\n",
      "Train Epoch: 333 [19200/32031 (60%)]\tLoss: 198.083603\n",
      "Train Epoch: 333 [20480/32031 (64%)]\tLoss: 195.469559\n",
      "Train Epoch: 333 [21760/32031 (68%)]\tLoss: 200.604752\n",
      "Train Epoch: 333 [23040/32031 (72%)]\tLoss: 190.733124\n",
      "Train Epoch: 333 [24320/32031 (76%)]\tLoss: 207.560745\n",
      "Train Epoch: 333 [25600/32031 (80%)]\tLoss: 209.237289\n",
      "Train Epoch: 333 [26880/32031 (84%)]\tLoss: 198.988220\n",
      "Train Epoch: 333 [28160/32031 (88%)]\tLoss: 194.451538\n",
      "Train Epoch: 333 [29440/32031 (92%)]\tLoss: 206.864929\n",
      "Train Epoch: 333 [30720/32031 (96%)]\tLoss: 203.020996\n",
      "Train Epoch: 333 [7750/32031 (100%)]\tLoss: 202.259970\n",
      "====> Epoch: 333 Average loss: 202.6309\n",
      "====> Test set loss: 195.6359\n",
      "Train Epoch: 334 [0/32031 (0%)]\tLoss: 191.589478\n",
      "Train Epoch: 334 [1280/32031 (4%)]\tLoss: 213.814117\n",
      "Train Epoch: 334 [2560/32031 (8%)]\tLoss: 200.908310\n",
      "Train Epoch: 334 [3840/32031 (12%)]\tLoss: 209.247070\n",
      "Train Epoch: 334 [5120/32031 (16%)]\tLoss: 208.201385\n",
      "Train Epoch: 334 [6400/32031 (20%)]\tLoss: 208.699768\n",
      "Train Epoch: 334 [7680/32031 (24%)]\tLoss: 210.034592\n",
      "Train Epoch: 334 [8960/32031 (28%)]\tLoss: 202.747604\n",
      "Train Epoch: 334 [10240/32031 (32%)]\tLoss: 210.449417\n",
      "Train Epoch: 334 [11520/32031 (36%)]\tLoss: 210.368042\n",
      "Train Epoch: 334 [12800/32031 (40%)]\tLoss: 199.204712\n",
      "Train Epoch: 334 [14080/32031 (44%)]\tLoss: 201.342865\n",
      "Train Epoch: 334 [15360/32031 (48%)]\tLoss: 194.490097\n",
      "Train Epoch: 334 [16640/32031 (52%)]\tLoss: 209.397766\n",
      "Train Epoch: 334 [17920/32031 (56%)]\tLoss: 202.123474\n",
      "Train Epoch: 334 [19200/32031 (60%)]\tLoss: 206.140900\n",
      "Train Epoch: 334 [20480/32031 (64%)]\tLoss: 207.643784\n",
      "Train Epoch: 334 [21760/32031 (68%)]\tLoss: 200.483856\n",
      "Train Epoch: 334 [23040/32031 (72%)]\tLoss: 210.877960\n",
      "Train Epoch: 334 [24320/32031 (76%)]\tLoss: 214.532166\n",
      "Train Epoch: 334 [25600/32031 (80%)]\tLoss: 196.970413\n",
      "Train Epoch: 334 [26880/32031 (84%)]\tLoss: 206.322403\n",
      "Train Epoch: 334 [28160/32031 (88%)]\tLoss: 198.495575\n",
      "Train Epoch: 334 [29440/32031 (92%)]\tLoss: 213.968979\n",
      "Train Epoch: 334 [30720/32031 (96%)]\tLoss: 211.298706\n",
      "Train Epoch: 334 [7750/32031 (100%)]\tLoss: 206.826392\n",
      "====> Epoch: 334 Average loss: 202.4229\n",
      "====> Test set loss: 196.8601\n",
      "Train Epoch: 335 [0/32031 (0%)]\tLoss: 196.244049\n",
      "Train Epoch: 335 [1280/32031 (4%)]\tLoss: 204.652512\n",
      "Train Epoch: 335 [2560/32031 (8%)]\tLoss: 212.007568\n",
      "Train Epoch: 335 [3840/32031 (12%)]\tLoss: 183.893677\n",
      "Train Epoch: 335 [5120/32031 (16%)]\tLoss: 197.737610\n",
      "Train Epoch: 335 [6400/32031 (20%)]\tLoss: 201.698120\n",
      "Train Epoch: 335 [7680/32031 (24%)]\tLoss: 195.415146\n",
      "Train Epoch: 335 [8960/32031 (28%)]\tLoss: 193.072464\n",
      "Train Epoch: 335 [10240/32031 (32%)]\tLoss: 196.876221\n",
      "Train Epoch: 335 [11520/32031 (36%)]\tLoss: 206.236862\n",
      "Train Epoch: 335 [12800/32031 (40%)]\tLoss: 202.042892\n",
      "Train Epoch: 335 [14080/32031 (44%)]\tLoss: 203.119476\n",
      "Train Epoch: 335 [15360/32031 (48%)]\tLoss: 203.781845\n",
      "Train Epoch: 335 [16640/32031 (52%)]\tLoss: 209.787201\n",
      "Train Epoch: 335 [17920/32031 (56%)]\tLoss: 203.519211\n",
      "Train Epoch: 335 [19200/32031 (60%)]\tLoss: 208.003021\n",
      "Train Epoch: 335 [20480/32031 (64%)]\tLoss: 200.788651\n",
      "Train Epoch: 335 [21760/32031 (68%)]\tLoss: 194.148087\n",
      "Train Epoch: 335 [23040/32031 (72%)]\tLoss: 204.872284\n",
      "Train Epoch: 335 [24320/32031 (76%)]\tLoss: 194.013947\n",
      "Train Epoch: 335 [25600/32031 (80%)]\tLoss: 207.289398\n",
      "Train Epoch: 335 [26880/32031 (84%)]\tLoss: 198.772888\n",
      "Train Epoch: 335 [28160/32031 (88%)]\tLoss: 196.280182\n",
      "Train Epoch: 335 [29440/32031 (92%)]\tLoss: 204.712967\n",
      "Train Epoch: 335 [30720/32031 (96%)]\tLoss: 199.708267\n",
      "Train Epoch: 335 [7750/32031 (100%)]\tLoss: 227.086142\n",
      "====> Epoch: 335 Average loss: 202.0768\n",
      "====> Test set loss: 196.8953\n",
      "Train Epoch: 336 [0/32031 (0%)]\tLoss: 197.432404\n",
      "Train Epoch: 336 [1280/32031 (4%)]\tLoss: 202.610641\n",
      "Train Epoch: 336 [2560/32031 (8%)]\tLoss: 209.164276\n",
      "Train Epoch: 336 [3840/32031 (12%)]\tLoss: 202.822739\n",
      "Train Epoch: 336 [5120/32031 (16%)]\tLoss: 211.523087\n",
      "Train Epoch: 336 [6400/32031 (20%)]\tLoss: 195.784317\n",
      "Train Epoch: 336 [7680/32031 (24%)]\tLoss: 207.783752\n",
      "Train Epoch: 336 [8960/32031 (28%)]\tLoss: 201.888260\n",
      "Train Epoch: 336 [10240/32031 (32%)]\tLoss: 216.223083\n",
      "Train Epoch: 336 [11520/32031 (36%)]\tLoss: 205.355759\n",
      "Train Epoch: 336 [12800/32031 (40%)]\tLoss: 208.114853\n",
      "Train Epoch: 336 [14080/32031 (44%)]\tLoss: 197.111557\n",
      "Train Epoch: 336 [15360/32031 (48%)]\tLoss: 205.374893\n",
      "Train Epoch: 336 [16640/32031 (52%)]\tLoss: 201.588638\n",
      "Train Epoch: 336 [17920/32031 (56%)]\tLoss: 206.101257\n",
      "Train Epoch: 336 [19200/32031 (60%)]\tLoss: 200.299088\n",
      "Train Epoch: 336 [20480/32031 (64%)]\tLoss: 195.042984\n",
      "Train Epoch: 336 [21760/32031 (68%)]\tLoss: 205.200714\n",
      "Train Epoch: 336 [23040/32031 (72%)]\tLoss: 202.293427\n",
      "Train Epoch: 336 [24320/32031 (76%)]\tLoss: 195.616272\n",
      "Train Epoch: 336 [25600/32031 (80%)]\tLoss: 201.444672\n",
      "Train Epoch: 336 [26880/32031 (84%)]\tLoss: 187.153580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 336 [28160/32031 (88%)]\tLoss: 202.528702\n",
      "Train Epoch: 336 [29440/32031 (92%)]\tLoss: 196.937408\n",
      "Train Epoch: 336 [30720/32031 (96%)]\tLoss: 201.389145\n",
      "Train Epoch: 336 [7750/32031 (100%)]\tLoss: 201.309271\n",
      "====> Epoch: 336 Average loss: 202.6811\n",
      "====> Test set loss: 196.1925\n",
      "Train Epoch: 337 [0/32031 (0%)]\tLoss: 222.414551\n",
      "Train Epoch: 337 [1280/32031 (4%)]\tLoss: 201.523483\n",
      "Train Epoch: 337 [2560/32031 (8%)]\tLoss: 212.207977\n",
      "Train Epoch: 337 [3840/32031 (12%)]\tLoss: 187.410339\n",
      "Train Epoch: 337 [5120/32031 (16%)]\tLoss: 205.375275\n",
      "Train Epoch: 337 [6400/32031 (20%)]\tLoss: 188.407074\n",
      "Train Epoch: 337 [7680/32031 (24%)]\tLoss: 204.438492\n",
      "Train Epoch: 337 [8960/32031 (28%)]\tLoss: 213.985352\n",
      "Train Epoch: 337 [10240/32031 (32%)]\tLoss: 194.221725\n",
      "Train Epoch: 337 [11520/32031 (36%)]\tLoss: 206.610855\n",
      "Train Epoch: 337 [12800/32031 (40%)]\tLoss: 206.196030\n",
      "Train Epoch: 337 [14080/32031 (44%)]\tLoss: 198.500549\n",
      "Train Epoch: 337 [15360/32031 (48%)]\tLoss: 197.367493\n",
      "Train Epoch: 337 [16640/32031 (52%)]\tLoss: 209.191711\n",
      "Train Epoch: 337 [17920/32031 (56%)]\tLoss: 208.942520\n",
      "Train Epoch: 337 [19200/32031 (60%)]\tLoss: 204.636719\n",
      "Train Epoch: 337 [20480/32031 (64%)]\tLoss: 208.342072\n",
      "Train Epoch: 337 [21760/32031 (68%)]\tLoss: 203.936859\n",
      "Train Epoch: 337 [23040/32031 (72%)]\tLoss: 204.953079\n",
      "Train Epoch: 337 [24320/32031 (76%)]\tLoss: 200.807907\n",
      "Train Epoch: 337 [25600/32031 (80%)]\tLoss: 203.143646\n",
      "Train Epoch: 337 [26880/32031 (84%)]\tLoss: 204.252640\n",
      "Train Epoch: 337 [28160/32031 (88%)]\tLoss: 206.297638\n",
      "Train Epoch: 337 [29440/32031 (92%)]\tLoss: 202.192993\n",
      "Train Epoch: 337 [30720/32031 (96%)]\tLoss: 199.830139\n",
      "Train Epoch: 337 [7750/32031 (100%)]\tLoss: 201.472719\n",
      "====> Epoch: 337 Average loss: 202.2517\n",
      "====> Test set loss: 196.0592\n",
      "Train Epoch: 338 [0/32031 (0%)]\tLoss: 198.253220\n",
      "Train Epoch: 338 [1280/32031 (4%)]\tLoss: 201.752426\n",
      "Train Epoch: 338 [2560/32031 (8%)]\tLoss: 198.173859\n",
      "Train Epoch: 338 [3840/32031 (12%)]\tLoss: 200.041122\n",
      "Train Epoch: 338 [5120/32031 (16%)]\tLoss: 212.078186\n",
      "Train Epoch: 338 [6400/32031 (20%)]\tLoss: 192.540207\n",
      "Train Epoch: 338 [7680/32031 (24%)]\tLoss: 199.039291\n",
      "Train Epoch: 338 [8960/32031 (28%)]\tLoss: 208.168427\n",
      "Train Epoch: 338 [10240/32031 (32%)]\tLoss: 191.476181\n",
      "Train Epoch: 338 [11520/32031 (36%)]\tLoss: 202.003036\n",
      "Train Epoch: 338 [12800/32031 (40%)]\tLoss: 200.930740\n",
      "Train Epoch: 338 [14080/32031 (44%)]\tLoss: 201.906036\n",
      "Train Epoch: 338 [15360/32031 (48%)]\tLoss: 203.087845\n",
      "Train Epoch: 338 [16640/32031 (52%)]\tLoss: 206.307480\n",
      "Train Epoch: 338 [17920/32031 (56%)]\tLoss: 205.499344\n",
      "Train Epoch: 338 [19200/32031 (60%)]\tLoss: 211.202682\n",
      "Train Epoch: 338 [20480/32031 (64%)]\tLoss: 200.910767\n",
      "Train Epoch: 338 [21760/32031 (68%)]\tLoss: 204.096588\n",
      "Train Epoch: 338 [23040/32031 (72%)]\tLoss: 199.738998\n",
      "Train Epoch: 338 [24320/32031 (76%)]\tLoss: 204.415329\n",
      "Train Epoch: 338 [25600/32031 (80%)]\tLoss: 214.005676\n",
      "Train Epoch: 338 [26880/32031 (84%)]\tLoss: 201.029327\n",
      "Train Epoch: 338 [28160/32031 (88%)]\tLoss: 202.560974\n",
      "Train Epoch: 338 [29440/32031 (92%)]\tLoss: 216.924576\n",
      "Train Epoch: 338 [30720/32031 (96%)]\tLoss: 206.563416\n",
      "Train Epoch: 338 [7750/32031 (100%)]\tLoss: 208.318564\n",
      "====> Epoch: 338 Average loss: 201.9840\n",
      "====> Test set loss: 195.2859\n",
      "Train Epoch: 339 [0/32031 (0%)]\tLoss: 196.152344\n",
      "Train Epoch: 339 [1280/32031 (4%)]\tLoss: 186.706299\n",
      "Train Epoch: 339 [2560/32031 (8%)]\tLoss: 207.862442\n",
      "Train Epoch: 339 [3840/32031 (12%)]\tLoss: 207.463211\n",
      "Train Epoch: 339 [5120/32031 (16%)]\tLoss: 197.395416\n",
      "Train Epoch: 339 [6400/32031 (20%)]\tLoss: 209.372864\n",
      "Train Epoch: 339 [7680/32031 (24%)]\tLoss: 202.827393\n",
      "Train Epoch: 339 [8960/32031 (28%)]\tLoss: 208.214462\n",
      "Train Epoch: 339 [10240/32031 (32%)]\tLoss: 207.738281\n",
      "Train Epoch: 339 [11520/32031 (36%)]\tLoss: 196.664001\n",
      "Train Epoch: 339 [12800/32031 (40%)]\tLoss: 211.453140\n",
      "Train Epoch: 339 [14080/32031 (44%)]\tLoss: 201.865845\n",
      "Train Epoch: 339 [15360/32031 (48%)]\tLoss: 200.148834\n",
      "Train Epoch: 339 [16640/32031 (52%)]\tLoss: 203.681152\n",
      "Train Epoch: 339 [17920/32031 (56%)]\tLoss: 209.392731\n",
      "Train Epoch: 339 [19200/32031 (60%)]\tLoss: 199.783798\n",
      "Train Epoch: 339 [20480/32031 (64%)]\tLoss: 200.940994\n",
      "Train Epoch: 339 [21760/32031 (68%)]\tLoss: 199.803009\n",
      "Train Epoch: 339 [23040/32031 (72%)]\tLoss: 200.407043\n",
      "Train Epoch: 339 [24320/32031 (76%)]\tLoss: 203.258896\n",
      "Train Epoch: 339 [25600/32031 (80%)]\tLoss: 207.113815\n",
      "Train Epoch: 339 [26880/32031 (84%)]\tLoss: 200.246338\n",
      "Train Epoch: 339 [28160/32031 (88%)]\tLoss: 208.732544\n",
      "Train Epoch: 339 [29440/32031 (92%)]\tLoss: 208.713669\n",
      "Train Epoch: 339 [30720/32031 (96%)]\tLoss: 215.561859\n",
      "Train Epoch: 339 [7750/32031 (100%)]\tLoss: 196.029234\n",
      "====> Epoch: 339 Average loss: 202.3600\n",
      "====> Test set loss: 195.2525\n",
      "Train Epoch: 340 [0/32031 (0%)]\tLoss: 198.748505\n",
      "Train Epoch: 340 [1280/32031 (4%)]\tLoss: 193.142792\n",
      "Train Epoch: 340 [2560/32031 (8%)]\tLoss: 205.741821\n",
      "Train Epoch: 340 [3840/32031 (12%)]\tLoss: 185.638687\n",
      "Train Epoch: 340 [5120/32031 (16%)]\tLoss: 197.217056\n",
      "Train Epoch: 340 [6400/32031 (20%)]\tLoss: 219.436630\n",
      "Train Epoch: 340 [7680/32031 (24%)]\tLoss: 198.281586\n",
      "Train Epoch: 340 [8960/32031 (28%)]\tLoss: 199.621811\n",
      "Train Epoch: 340 [10240/32031 (32%)]\tLoss: 197.661728\n",
      "Train Epoch: 340 [11520/32031 (36%)]\tLoss: 200.730682\n",
      "Train Epoch: 340 [12800/32031 (40%)]\tLoss: 207.507309\n",
      "Train Epoch: 340 [14080/32031 (44%)]\tLoss: 205.875214\n",
      "Train Epoch: 340 [15360/32031 (48%)]\tLoss: 196.448395\n",
      "Train Epoch: 340 [16640/32031 (52%)]\tLoss: 199.460159\n",
      "Train Epoch: 340 [17920/32031 (56%)]\tLoss: 198.446243\n",
      "Train Epoch: 340 [19200/32031 (60%)]\tLoss: 213.328354\n",
      "Train Epoch: 340 [20480/32031 (64%)]\tLoss: 196.288132\n",
      "Train Epoch: 340 [21760/32031 (68%)]\tLoss: 203.946045\n",
      "Train Epoch: 340 [23040/32031 (72%)]\tLoss: 199.910538\n",
      "Train Epoch: 340 [24320/32031 (76%)]\tLoss: 201.114716\n",
      "Train Epoch: 340 [25600/32031 (80%)]\tLoss: 197.218246\n",
      "Train Epoch: 340 [26880/32031 (84%)]\tLoss: 210.845871\n",
      "Train Epoch: 340 [28160/32031 (88%)]\tLoss: 208.367310\n",
      "Train Epoch: 340 [29440/32031 (92%)]\tLoss: 210.465530\n",
      "Train Epoch: 340 [30720/32031 (96%)]\tLoss: 191.225433\n",
      "Train Epoch: 340 [7750/32031 (100%)]\tLoss: 199.125504\n",
      "====> Epoch: 340 Average loss: 202.4517\n",
      "====> Test set loss: 194.6867\n",
      "Train Epoch: 341 [0/32031 (0%)]\tLoss: 194.371979\n",
      "Train Epoch: 341 [1280/32031 (4%)]\tLoss: 218.749222\n",
      "Train Epoch: 341 [2560/32031 (8%)]\tLoss: 203.092743\n",
      "Train Epoch: 341 [3840/32031 (12%)]\tLoss: 198.545654\n",
      "Train Epoch: 341 [5120/32031 (16%)]\tLoss: 200.964050\n",
      "Train Epoch: 341 [6400/32031 (20%)]\tLoss: 205.327194\n",
      "Train Epoch: 341 [7680/32031 (24%)]\tLoss: 207.408905\n",
      "Train Epoch: 341 [8960/32031 (28%)]\tLoss: 204.326218\n",
      "Train Epoch: 341 [10240/32031 (32%)]\tLoss: 201.269226\n",
      "Train Epoch: 341 [11520/32031 (36%)]\tLoss: 200.474121\n",
      "Train Epoch: 341 [12800/32031 (40%)]\tLoss: 196.901993\n",
      "Train Epoch: 341 [14080/32031 (44%)]\tLoss: 205.798584\n",
      "Train Epoch: 341 [15360/32031 (48%)]\tLoss: 208.398834\n",
      "Train Epoch: 341 [16640/32031 (52%)]\tLoss: 210.002914\n",
      "Train Epoch: 341 [17920/32031 (56%)]\tLoss: 215.946182\n",
      "Train Epoch: 341 [19200/32031 (60%)]\tLoss: 204.499191\n",
      "Train Epoch: 341 [20480/32031 (64%)]\tLoss: 193.216949\n",
      "Train Epoch: 341 [21760/32031 (68%)]\tLoss: 197.690308\n",
      "Train Epoch: 341 [23040/32031 (72%)]\tLoss: 205.767670\n",
      "Train Epoch: 341 [24320/32031 (76%)]\tLoss: 201.332809\n",
      "Train Epoch: 341 [25600/32031 (80%)]\tLoss: 204.240189\n",
      "Train Epoch: 341 [26880/32031 (84%)]\tLoss: 201.432816\n",
      "Train Epoch: 341 [28160/32031 (88%)]\tLoss: 209.361603\n",
      "Train Epoch: 341 [29440/32031 (92%)]\tLoss: 198.952805\n",
      "Train Epoch: 341 [30720/32031 (96%)]\tLoss: 200.577194\n",
      "Train Epoch: 341 [7750/32031 (100%)]\tLoss: 193.711694\n",
      "====> Epoch: 341 Average loss: 202.0606\n",
      "====> Test set loss: 196.9772\n",
      "Train Epoch: 342 [0/32031 (0%)]\tLoss: 212.481415\n",
      "Train Epoch: 342 [1280/32031 (4%)]\tLoss: 202.776245\n",
      "Train Epoch: 342 [2560/32031 (8%)]\tLoss: 198.884155\n",
      "Train Epoch: 342 [3840/32031 (12%)]\tLoss: 209.185394\n",
      "Train Epoch: 342 [5120/32031 (16%)]\tLoss: 204.520920\n",
      "Train Epoch: 342 [6400/32031 (20%)]\tLoss: 199.895676\n",
      "Train Epoch: 342 [7680/32031 (24%)]\tLoss: 195.220993\n",
      "Train Epoch: 342 [8960/32031 (28%)]\tLoss: 195.916214\n",
      "Train Epoch: 342 [10240/32031 (32%)]\tLoss: 206.165039\n",
      "Train Epoch: 342 [11520/32031 (36%)]\tLoss: 201.146881\n",
      "Train Epoch: 342 [12800/32031 (40%)]\tLoss: 201.286469\n",
      "Train Epoch: 342 [14080/32031 (44%)]\tLoss: 208.045609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 342 [15360/32031 (48%)]\tLoss: 207.850479\n",
      "Train Epoch: 342 [16640/32031 (52%)]\tLoss: 208.396515\n",
      "Train Epoch: 342 [17920/32031 (56%)]\tLoss: 202.994431\n",
      "Train Epoch: 342 [19200/32031 (60%)]\tLoss: 210.142136\n",
      "Train Epoch: 342 [20480/32031 (64%)]\tLoss: 208.357727\n",
      "Train Epoch: 342 [21760/32031 (68%)]\tLoss: 194.002472\n",
      "Train Epoch: 342 [23040/32031 (72%)]\tLoss: 200.524841\n",
      "Train Epoch: 342 [24320/32031 (76%)]\tLoss: 197.117874\n",
      "Train Epoch: 342 [25600/32031 (80%)]\tLoss: 213.413498\n",
      "Train Epoch: 342 [26880/32031 (84%)]\tLoss: 213.996735\n",
      "Train Epoch: 342 [28160/32031 (88%)]\tLoss: 201.619873\n",
      "Train Epoch: 342 [29440/32031 (92%)]\tLoss: 197.597580\n",
      "Train Epoch: 342 [30720/32031 (96%)]\tLoss: 200.128525\n",
      "Train Epoch: 342 [7750/32031 (100%)]\tLoss: 180.784936\n",
      "====> Epoch: 342 Average loss: 202.1822\n",
      "====> Test set loss: 196.6707\n",
      "Train Epoch: 343 [0/32031 (0%)]\tLoss: 196.757141\n",
      "Train Epoch: 343 [1280/32031 (4%)]\tLoss: 193.390137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 417 [19200/32031 (60%)]\tLoss: 207.053635\n",
      "Train Epoch: 417 [20480/32031 (64%)]\tLoss: 195.341232\n",
      "Train Epoch: 417 [21760/32031 (68%)]\tLoss: 200.186127\n",
      "Train Epoch: 417 [23040/32031 (72%)]\tLoss: 200.091629\n",
      "Train Epoch: 417 [24320/32031 (76%)]\tLoss: 200.838333\n",
      "Train Epoch: 417 [25600/32031 (80%)]\tLoss: 191.484009\n",
      "Train Epoch: 417 [26880/32031 (84%)]\tLoss: 204.110794\n",
      "Train Epoch: 417 [28160/32031 (88%)]\tLoss: 201.935791\n",
      "Train Epoch: 417 [29440/32031 (92%)]\tLoss: 206.825760\n",
      "Train Epoch: 417 [30720/32031 (96%)]\tLoss: 213.134583\n",
      "Train Epoch: 417 [7750/32031 (100%)]\tLoss: 194.095388\n",
      "====> Epoch: 417 Average loss: 200.6700\n",
      "====> Test set loss: 195.1790\n",
      "Train Epoch: 418 [0/32031 (0%)]\tLoss: 201.209732\n",
      "Train Epoch: 418 [1280/32031 (4%)]\tLoss: 197.052200\n",
      "Train Epoch: 418 [2560/32031 (8%)]\tLoss: 189.314819\n",
      "Train Epoch: 418 [3840/32031 (12%)]\tLoss: 194.710419\n",
      "Train Epoch: 418 [5120/32031 (16%)]\tLoss: 206.868134\n",
      "Train Epoch: 418 [6400/32031 (20%)]\tLoss: 202.506516\n",
      "Train Epoch: 418 [7680/32031 (24%)]\tLoss: 199.200363\n",
      "Train Epoch: 418 [8960/32031 (28%)]\tLoss: 188.652420\n",
      "Train Epoch: 418 [10240/32031 (32%)]\tLoss: 199.968094\n",
      "Train Epoch: 418 [11520/32031 (36%)]\tLoss: 201.513107\n",
      "Train Epoch: 418 [12800/32031 (40%)]\tLoss: 185.853760\n",
      "Train Epoch: 418 [14080/32031 (44%)]\tLoss: 194.923218\n",
      "Train Epoch: 418 [15360/32031 (48%)]\tLoss: 193.839661\n",
      "Train Epoch: 418 [16640/32031 (52%)]\tLoss: 199.416946\n",
      "Train Epoch: 418 [17920/32031 (56%)]\tLoss: 204.234512\n",
      "Train Epoch: 418 [19200/32031 (60%)]\tLoss: 205.761948\n",
      "Train Epoch: 418 [20480/32031 (64%)]\tLoss: 193.431793\n",
      "Train Epoch: 418 [21760/32031 (68%)]\tLoss: 189.707047\n",
      "Train Epoch: 418 [23040/32031 (72%)]\tLoss: 202.886200\n",
      "Train Epoch: 418 [24320/32031 (76%)]\tLoss: 203.522217\n",
      "Train Epoch: 418 [25600/32031 (80%)]\tLoss: 205.017715\n",
      "Train Epoch: 418 [26880/32031 (84%)]\tLoss: 206.319748\n",
      "Train Epoch: 418 [28160/32031 (88%)]\tLoss: 199.621597\n",
      "Train Epoch: 418 [29440/32031 (92%)]\tLoss: 199.816132\n",
      "Train Epoch: 418 [30720/32031 (96%)]\tLoss: 205.973038\n",
      "Train Epoch: 418 [7750/32031 (100%)]\tLoss: 188.455125\n",
      "====> Epoch: 418 Average loss: 200.6613\n",
      "====> Test set loss: 196.2136\n",
      "Train Epoch: 419 [0/32031 (0%)]\tLoss: 211.133347\n",
      "Train Epoch: 419 [1280/32031 (4%)]\tLoss: 204.321472\n",
      "Train Epoch: 419 [2560/32031 (8%)]\tLoss: 197.080933\n",
      "Train Epoch: 419 [3840/32031 (12%)]\tLoss: 208.444565\n",
      "Train Epoch: 419 [5120/32031 (16%)]\tLoss: 205.228012\n",
      "Train Epoch: 419 [6400/32031 (20%)]\tLoss: 197.635452\n",
      "Train Epoch: 419 [7680/32031 (24%)]\tLoss: 206.031769\n",
      "Train Epoch: 419 [8960/32031 (28%)]\tLoss: 197.472717\n",
      "Train Epoch: 419 [10240/32031 (32%)]\tLoss: 201.726044\n",
      "Train Epoch: 419 [11520/32031 (36%)]\tLoss: 207.408157\n",
      "Train Epoch: 419 [12800/32031 (40%)]\tLoss: 203.098083\n",
      "Train Epoch: 419 [14080/32031 (44%)]\tLoss: 200.378479\n",
      "Train Epoch: 419 [15360/32031 (48%)]\tLoss: 207.940643\n",
      "Train Epoch: 419 [16640/32031 (52%)]\tLoss: 204.924240\n",
      "Train Epoch: 419 [17920/32031 (56%)]\tLoss: 202.936340\n",
      "Train Epoch: 419 [19200/32031 (60%)]\tLoss: 206.506546\n",
      "Train Epoch: 419 [20480/32031 (64%)]\tLoss: 196.462799\n",
      "Train Epoch: 419 [21760/32031 (68%)]\tLoss: 196.896515\n",
      "Train Epoch: 419 [23040/32031 (72%)]\tLoss: 197.728165\n",
      "Train Epoch: 419 [24320/32031 (76%)]\tLoss: 212.643036\n",
      "Train Epoch: 419 [25600/32031 (80%)]\tLoss: 191.783875\n",
      "Train Epoch: 419 [26880/32031 (84%)]\tLoss: 205.127396\n",
      "Train Epoch: 419 [28160/32031 (88%)]\tLoss: 201.497375\n",
      "Train Epoch: 419 [29440/32031 (92%)]\tLoss: 193.462616\n",
      "Train Epoch: 419 [30720/32031 (96%)]\tLoss: 198.977859\n",
      "Train Epoch: 419 [7750/32031 (100%)]\tLoss: 197.052577\n",
      "====> Epoch: 419 Average loss: 200.6839\n",
      "====> Test set loss: 193.6550\n",
      "Train Epoch: 420 [0/32031 (0%)]\tLoss: 201.589478\n",
      "Train Epoch: 420 [1280/32031 (4%)]\tLoss: 193.389786\n",
      "Train Epoch: 420 [2560/32031 (8%)]\tLoss: 197.116272\n",
      "Train Epoch: 420 [3840/32031 (12%)]\tLoss: 197.495575\n",
      "Train Epoch: 420 [5120/32031 (16%)]\tLoss: 205.896057\n",
      "Train Epoch: 420 [6400/32031 (20%)]\tLoss: 195.108917\n",
      "Train Epoch: 420 [7680/32031 (24%)]\tLoss: 186.048904\n",
      "Train Epoch: 420 [8960/32031 (28%)]\tLoss: 202.907074\n",
      "Train Epoch: 420 [10240/32031 (32%)]\tLoss: 191.666031\n",
      "Train Epoch: 420 [11520/32031 (36%)]\tLoss: 192.278168\n",
      "Train Epoch: 420 [12800/32031 (40%)]\tLoss: 200.960892\n",
      "Train Epoch: 420 [14080/32031 (44%)]\tLoss: 209.429871\n",
      "Train Epoch: 420 [15360/32031 (48%)]\tLoss: 199.416153\n",
      "Train Epoch: 420 [16640/32031 (52%)]\tLoss: 213.411667\n",
      "Train Epoch: 420 [17920/32031 (56%)]\tLoss: 197.358063\n",
      "Train Epoch: 420 [19200/32031 (60%)]\tLoss: 200.922623\n",
      "Train Epoch: 420 [20480/32031 (64%)]\tLoss: 206.867828\n",
      "Train Epoch: 420 [21760/32031 (68%)]\tLoss: 203.684433\n",
      "Train Epoch: 420 [23040/32031 (72%)]\tLoss: 199.517380\n",
      "Train Epoch: 420 [24320/32031 (76%)]\tLoss: 208.435089\n",
      "Train Epoch: 420 [25600/32031 (80%)]\tLoss: 201.125534\n",
      "Train Epoch: 420 [26880/32031 (84%)]\tLoss: 204.157974\n",
      "Train Epoch: 420 [28160/32031 (88%)]\tLoss: 184.479813\n",
      "Train Epoch: 420 [29440/32031 (92%)]\tLoss: 195.506882\n",
      "Train Epoch: 420 [30720/32031 (96%)]\tLoss: 211.506317\n",
      "Train Epoch: 420 [7750/32031 (100%)]\tLoss: 227.242912\n",
      "====> Epoch: 420 Average loss: 201.2488\n",
      "====> Test set loss: 197.7774\n",
      "Train Epoch: 421 [0/32031 (0%)]\tLoss: 197.328110\n",
      "Train Epoch: 421 [1280/32031 (4%)]\tLoss: 190.054718\n",
      "Train Epoch: 421 [2560/32031 (8%)]\tLoss: 201.719055\n",
      "Train Epoch: 421 [3840/32031 (12%)]\tLoss: 198.583374\n",
      "Train Epoch: 421 [5120/32031 (16%)]\tLoss: 204.240967\n",
      "Train Epoch: 421 [6400/32031 (20%)]\tLoss: 203.381943\n",
      "Train Epoch: 421 [7680/32031 (24%)]\tLoss: 199.957245\n",
      "Train Epoch: 421 [8960/32031 (28%)]\tLoss: 208.992813\n",
      "Train Epoch: 421 [10240/32031 (32%)]\tLoss: 195.602036\n",
      "Train Epoch: 421 [11520/32031 (36%)]\tLoss: 200.583191\n",
      "Train Epoch: 421 [12800/32031 (40%)]\tLoss: 206.089447\n",
      "Train Epoch: 421 [14080/32031 (44%)]\tLoss: 193.597748\n",
      "Train Epoch: 421 [15360/32031 (48%)]\tLoss: 197.225311\n",
      "Train Epoch: 421 [16640/32031 (52%)]\tLoss: 189.687668\n",
      "Train Epoch: 421 [17920/32031 (56%)]\tLoss: 205.584473\n",
      "Train Epoch: 421 [19200/32031 (60%)]\tLoss: 204.201096\n",
      "Train Epoch: 421 [20480/32031 (64%)]\tLoss: 213.911667\n",
      "Train Epoch: 421 [21760/32031 (68%)]\tLoss: 211.138687\n",
      "Train Epoch: 421 [23040/32031 (72%)]\tLoss: 200.450821\n",
      "Train Epoch: 421 [24320/32031 (76%)]\tLoss: 198.083328\n",
      "Train Epoch: 421 [25600/32031 (80%)]\tLoss: 208.899078\n",
      "Train Epoch: 421 [26880/32031 (84%)]\tLoss: 192.720978\n",
      "Train Epoch: 421 [28160/32031 (88%)]\tLoss: 200.734360\n",
      "Train Epoch: 421 [29440/32031 (92%)]\tLoss: 200.552917\n",
      "Train Epoch: 421 [30720/32031 (96%)]\tLoss: 206.983734\n",
      "Train Epoch: 421 [7750/32031 (100%)]\tLoss: 195.706149\n",
      "====> Epoch: 421 Average loss: 201.0406\n",
      "====> Test set loss: 193.7495\n",
      "Train Epoch: 422 [0/32031 (0%)]\tLoss: 199.018616\n",
      "Train Epoch: 422 [1280/32031 (4%)]\tLoss: 211.051941\n",
      "Train Epoch: 422 [2560/32031 (8%)]\tLoss: 194.641785\n",
      "Train Epoch: 422 [3840/32031 (12%)]\tLoss: 205.596512\n",
      "Train Epoch: 422 [5120/32031 (16%)]\tLoss: 211.464386\n",
      "Train Epoch: 422 [6400/32031 (20%)]\tLoss: 189.339203\n",
      "Train Epoch: 422 [7680/32031 (24%)]\tLoss: 192.926895\n",
      "Train Epoch: 422 [8960/32031 (28%)]\tLoss: 186.496368\n",
      "Train Epoch: 422 [10240/32031 (32%)]\tLoss: 202.111252\n",
      "Train Epoch: 422 [11520/32031 (36%)]\tLoss: 191.493042\n",
      "Train Epoch: 422 [12800/32031 (40%)]\tLoss: 202.084473\n",
      "Train Epoch: 422 [14080/32031 (44%)]\tLoss: 206.136551\n",
      "Train Epoch: 422 [15360/32031 (48%)]\tLoss: 209.660538\n",
      "Train Epoch: 422 [16640/32031 (52%)]\tLoss: 203.774612\n",
      "Train Epoch: 422 [17920/32031 (56%)]\tLoss: 189.192932\n",
      "Train Epoch: 422 [19200/32031 (60%)]\tLoss: 200.132172\n",
      "Train Epoch: 422 [20480/32031 (64%)]\tLoss: 201.363647\n",
      "Train Epoch: 422 [21760/32031 (68%)]\tLoss: 201.232788\n",
      "Train Epoch: 422 [23040/32031 (72%)]\tLoss: 203.589890\n",
      "Train Epoch: 422 [24320/32031 (76%)]\tLoss: 199.926605\n",
      "Train Epoch: 422 [25600/32031 (80%)]\tLoss: 198.707397\n",
      "Train Epoch: 422 [26880/32031 (84%)]\tLoss: 208.079651\n",
      "Train Epoch: 422 [28160/32031 (88%)]\tLoss: 205.416153\n",
      "Train Epoch: 422 [29440/32031 (92%)]\tLoss: 205.828033\n",
      "Train Epoch: 422 [30720/32031 (96%)]\tLoss: 200.822083\n",
      "Train Epoch: 422 [7750/32031 (100%)]\tLoss: 201.691107\n",
      "====> Epoch: 422 Average loss: 200.7593\n",
      "====> Test set loss: 195.9652\n",
      "Train Epoch: 423 [0/32031 (0%)]\tLoss: 200.549850\n",
      "Train Epoch: 423 [1280/32031 (4%)]\tLoss: 190.118073\n",
      "Train Epoch: 423 [2560/32031 (8%)]\tLoss: 190.955078\n",
      "Train Epoch: 423 [3840/32031 (12%)]\tLoss: 204.614288\n",
      "Train Epoch: 423 [5120/32031 (16%)]\tLoss: 205.241501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 423 [6400/32031 (20%)]\tLoss: 197.642914\n",
      "Train Epoch: 423 [7680/32031 (24%)]\tLoss: 191.740219\n",
      "Train Epoch: 423 [8960/32031 (28%)]\tLoss: 189.932663\n",
      "Train Epoch: 423 [10240/32031 (32%)]\tLoss: 199.767090\n",
      "Train Epoch: 423 [11520/32031 (36%)]\tLoss: 197.365479\n",
      "Train Epoch: 423 [12800/32031 (40%)]\tLoss: 195.910919\n",
      "Train Epoch: 423 [14080/32031 (44%)]\tLoss: 208.192932\n",
      "Train Epoch: 423 [15360/32031 (48%)]\tLoss: 206.866837\n",
      "Train Epoch: 423 [16640/32031 (52%)]\tLoss: 198.375168\n",
      "Train Epoch: 423 [17920/32031 (56%)]\tLoss: 193.457581\n",
      "Train Epoch: 423 [19200/32031 (60%)]\tLoss: 199.531372\n",
      "Train Epoch: 423 [20480/32031 (64%)]\tLoss: 194.508621\n",
      "Train Epoch: 423 [21760/32031 (68%)]\tLoss: 198.022629\n",
      "Train Epoch: 423 [23040/32031 (72%)]\tLoss: 212.640045\n",
      "Train Epoch: 423 [24320/32031 (76%)]\tLoss: 206.384430\n",
      "Train Epoch: 423 [25600/32031 (80%)]\tLoss: 218.287170\n",
      "Train Epoch: 423 [26880/32031 (84%)]\tLoss: 199.696487\n",
      "Train Epoch: 423 [28160/32031 (88%)]\tLoss: 199.046951\n",
      "Train Epoch: 423 [29440/32031 (92%)]\tLoss: 195.623627\n",
      "Train Epoch: 423 [30720/32031 (96%)]\tLoss: 190.178055\n",
      "Train Epoch: 423 [7750/32031 (100%)]\tLoss: 200.400170\n",
      "====> Epoch: 423 Average loss: 201.0499\n",
      "====> Test set loss: 197.0907\n",
      "Train Epoch: 424 [0/32031 (0%)]\tLoss: 199.625275\n",
      "Train Epoch: 424 [1280/32031 (4%)]\tLoss: 193.142685\n",
      "Train Epoch: 424 [2560/32031 (8%)]\tLoss: 199.541687\n",
      "Train Epoch: 424 [3840/32031 (12%)]\tLoss: 200.629929\n",
      "Train Epoch: 424 [5120/32031 (16%)]\tLoss: 212.678543\n",
      "Train Epoch: 424 [6400/32031 (20%)]\tLoss: 200.433487\n",
      "Train Epoch: 424 [7680/32031 (24%)]\tLoss: 185.936310\n",
      "Train Epoch: 424 [8960/32031 (28%)]\tLoss: 198.853821\n",
      "Train Epoch: 424 [10240/32031 (32%)]\tLoss: 212.425232\n",
      "Train Epoch: 424 [11520/32031 (36%)]\tLoss: 201.395828\n",
      "Train Epoch: 424 [12800/32031 (40%)]\tLoss: 212.201019\n",
      "Train Epoch: 424 [14080/32031 (44%)]\tLoss: 195.431366\n",
      "Train Epoch: 424 [15360/32031 (48%)]\tLoss: 202.706223\n",
      "Train Epoch: 424 [16640/32031 (52%)]\tLoss: 200.032150\n",
      "Train Epoch: 424 [17920/32031 (56%)]\tLoss: 195.951355\n",
      "Train Epoch: 424 [19200/32031 (60%)]\tLoss: 209.676117\n",
      "Train Epoch: 424 [20480/32031 (64%)]\tLoss: 202.006714\n",
      "Train Epoch: 424 [21760/32031 (68%)]\tLoss: 209.644638\n",
      "Train Epoch: 424 [23040/32031 (72%)]\tLoss: 200.619675\n",
      "Train Epoch: 424 [24320/32031 (76%)]\tLoss: 206.383118\n",
      "Train Epoch: 424 [25600/32031 (80%)]\tLoss: 212.652756\n",
      "Train Epoch: 424 [26880/32031 (84%)]\tLoss: 204.156952\n",
      "Train Epoch: 424 [28160/32031 (88%)]\tLoss: 210.170135\n",
      "Train Epoch: 424 [29440/32031 (92%)]\tLoss: 204.737152\n",
      "Train Epoch: 424 [30720/32031 (96%)]\tLoss: 196.462585\n",
      "Train Epoch: 424 [7750/32031 (100%)]\tLoss: 214.103468\n",
      "====> Epoch: 424 Average loss: 201.0616\n",
      "====> Test set loss: 193.0602\n",
      "Train Epoch: 425 [0/32031 (0%)]\tLoss: 206.945892\n",
      "Train Epoch: 425 [1280/32031 (4%)]\tLoss: 195.162598\n",
      "Train Epoch: 425 [2560/32031 (8%)]\tLoss: 198.956177\n",
      "Train Epoch: 425 [3840/32031 (12%)]\tLoss: 202.426636\n",
      "Train Epoch: 425 [5120/32031 (16%)]\tLoss: 196.917923\n",
      "Train Epoch: 425 [6400/32031 (20%)]\tLoss: 197.419067\n",
      "Train Epoch: 425 [7680/32031 (24%)]\tLoss: 194.951599\n",
      "Train Epoch: 425 [8960/32031 (28%)]\tLoss: 205.465454\n",
      "Train Epoch: 425 [10240/32031 (32%)]\tLoss: 179.187378\n",
      "Train Epoch: 425 [11520/32031 (36%)]\tLoss: 206.907349\n",
      "Train Epoch: 425 [12800/32031 (40%)]\tLoss: 210.549896\n",
      "Train Epoch: 425 [14080/32031 (44%)]\tLoss: 196.437485\n",
      "Train Epoch: 425 [15360/32031 (48%)]\tLoss: 195.478226\n",
      "Train Epoch: 425 [16640/32031 (52%)]\tLoss: 205.690247\n",
      "Train Epoch: 425 [17920/32031 (56%)]\tLoss: 203.056625\n",
      "Train Epoch: 425 [19200/32031 (60%)]\tLoss: 199.737061\n",
      "Train Epoch: 425 [20480/32031 (64%)]\tLoss: 202.618790\n",
      "Train Epoch: 425 [21760/32031 (68%)]\tLoss: 194.405960\n",
      "Train Epoch: 425 [23040/32031 (72%)]\tLoss: 200.189545\n",
      "Train Epoch: 425 [24320/32031 (76%)]\tLoss: 200.586517\n",
      "Train Epoch: 425 [25600/32031 (80%)]\tLoss: 194.015427\n",
      "Train Epoch: 425 [26880/32031 (84%)]\tLoss: 210.332962\n",
      "Train Epoch: 425 [28160/32031 (88%)]\tLoss: 186.771835\n",
      "Train Epoch: 425 [29440/32031 (92%)]\tLoss: 199.895554\n",
      "Train Epoch: 425 [30720/32031 (96%)]\tLoss: 211.070496\n",
      "Train Epoch: 425 [7750/32031 (100%)]\tLoss: 224.776934\n",
      "====> Epoch: 425 Average loss: 200.6570\n",
      "====> Test set loss: 196.4750\n",
      "Train Epoch: 426 [0/32031 (0%)]\tLoss: 198.183243\n",
      "Train Epoch: 426 [1280/32031 (4%)]\tLoss: 208.103500\n",
      "Train Epoch: 426 [2560/32031 (8%)]\tLoss: 200.658691\n",
      "Train Epoch: 426 [3840/32031 (12%)]\tLoss: 196.713440\n",
      "Train Epoch: 426 [5120/32031 (16%)]\tLoss: 187.334412\n",
      "Train Epoch: 426 [6400/32031 (20%)]\tLoss: 203.031448\n",
      "Train Epoch: 426 [7680/32031 (24%)]\tLoss: 197.378174\n",
      "Train Epoch: 426 [8960/32031 (28%)]\tLoss: 207.883148\n",
      "Train Epoch: 426 [10240/32031 (32%)]\tLoss: 198.976517\n",
      "Train Epoch: 426 [11520/32031 (36%)]\tLoss: 208.824326\n",
      "Train Epoch: 426 [12800/32031 (40%)]\tLoss: 194.838837\n",
      "Train Epoch: 426 [14080/32031 (44%)]\tLoss: 195.989746\n",
      "Train Epoch: 426 [15360/32031 (48%)]\tLoss: 196.597412\n",
      "Train Epoch: 426 [16640/32031 (52%)]\tLoss: 206.074234\n",
      "Train Epoch: 426 [17920/32031 (56%)]\tLoss: 191.772415\n",
      "Train Epoch: 426 [19200/32031 (60%)]\tLoss: 202.022980\n",
      "Train Epoch: 426 [20480/32031 (64%)]\tLoss: 207.316254\n",
      "Train Epoch: 426 [21760/32031 (68%)]\tLoss: 213.861832\n",
      "Train Epoch: 426 [23040/32031 (72%)]\tLoss: 198.922913\n",
      "Train Epoch: 426 [24320/32031 (76%)]\tLoss: 202.186829\n",
      "Train Epoch: 426 [25600/32031 (80%)]\tLoss: 210.369843\n",
      "Train Epoch: 426 [26880/32031 (84%)]\tLoss: 200.370255\n",
      "Train Epoch: 426 [28160/32031 (88%)]\tLoss: 211.418854\n",
      "Train Epoch: 426 [29440/32031 (92%)]\tLoss: 204.028519\n",
      "Train Epoch: 426 [30720/32031 (96%)]\tLoss: 214.143707\n",
      "Train Epoch: 426 [7750/32031 (100%)]\tLoss: 199.768145\n",
      "====> Epoch: 426 Average loss: 200.7326\n",
      "====> Test set loss: 192.6299\n",
      "Train Epoch: 427 [0/32031 (0%)]\tLoss: 196.396500\n",
      "Train Epoch: 427 [1280/32031 (4%)]\tLoss: 192.575806\n",
      "Train Epoch: 427 [2560/32031 (8%)]\tLoss: 198.112228\n",
      "Train Epoch: 427 [3840/32031 (12%)]\tLoss: 193.188919\n",
      "Train Epoch: 427 [5120/32031 (16%)]\tLoss: 187.051636\n",
      "Train Epoch: 427 [6400/32031 (20%)]\tLoss: 205.022614\n",
      "Train Epoch: 427 [7680/32031 (24%)]\tLoss: 196.619522\n",
      "Train Epoch: 427 [8960/32031 (28%)]\tLoss: 201.812866\n",
      "Train Epoch: 427 [10240/32031 (32%)]\tLoss: 211.524460\n",
      "Train Epoch: 427 [11520/32031 (36%)]\tLoss: 201.998093\n",
      "Train Epoch: 427 [12800/32031 (40%)]\tLoss: 195.231720\n",
      "Train Epoch: 427 [14080/32031 (44%)]\tLoss: 201.324341\n",
      "Train Epoch: 427 [15360/32031 (48%)]\tLoss: 194.081482\n",
      "Train Epoch: 427 [16640/32031 (52%)]\tLoss: 202.993042\n",
      "Train Epoch: 427 [17920/32031 (56%)]\tLoss: 207.140976\n",
      "Train Epoch: 427 [19200/32031 (60%)]\tLoss: 196.217041\n",
      "Train Epoch: 427 [20480/32031 (64%)]\tLoss: 200.130890\n",
      "Train Epoch: 427 [21760/32031 (68%)]\tLoss: 215.673096\n",
      "Train Epoch: 427 [23040/32031 (72%)]\tLoss: 202.421249\n",
      "Train Epoch: 427 [24320/32031 (76%)]\tLoss: 196.844467\n",
      "Train Epoch: 427 [25600/32031 (80%)]\tLoss: 197.214615\n",
      "Train Epoch: 427 [26880/32031 (84%)]\tLoss: 200.873459\n",
      "Train Epoch: 427 [28160/32031 (88%)]\tLoss: 195.160431\n",
      "Train Epoch: 427 [29440/32031 (92%)]\tLoss: 202.869019\n",
      "Train Epoch: 427 [30720/32031 (96%)]\tLoss: 201.587479\n",
      "Train Epoch: 427 [7750/32031 (100%)]\tLoss: 201.615833\n",
      "====> Epoch: 427 Average loss: 200.5420\n",
      "====> Test set loss: 195.0120\n",
      "Train Epoch: 428 [0/32031 (0%)]\tLoss: 204.489304\n",
      "Train Epoch: 428 [1280/32031 (4%)]\tLoss: 197.206604\n",
      "Train Epoch: 428 [2560/32031 (8%)]\tLoss: 207.149734\n",
      "Train Epoch: 428 [3840/32031 (12%)]\tLoss: 212.844757\n",
      "Train Epoch: 428 [5120/32031 (16%)]\tLoss: 199.654358\n",
      "Train Epoch: 428 [6400/32031 (20%)]\tLoss: 200.118393\n",
      "Train Epoch: 428 [7680/32031 (24%)]\tLoss: 203.994354\n",
      "Train Epoch: 428 [8960/32031 (28%)]\tLoss: 199.992889\n",
      "Train Epoch: 428 [10240/32031 (32%)]\tLoss: 194.514160\n",
      "Train Epoch: 428 [11520/32031 (36%)]\tLoss: 201.613907\n",
      "Train Epoch: 428 [12800/32031 (40%)]\tLoss: 193.439270\n",
      "Train Epoch: 428 [14080/32031 (44%)]\tLoss: 200.543091\n",
      "Train Epoch: 428 [15360/32031 (48%)]\tLoss: 202.664185\n",
      "Train Epoch: 428 [16640/32031 (52%)]\tLoss: 197.640854\n",
      "Train Epoch: 428 [17920/32031 (56%)]\tLoss: 203.617218\n",
      "Train Epoch: 428 [19200/32031 (60%)]\tLoss: 202.953888\n",
      "Train Epoch: 428 [20480/32031 (64%)]\tLoss: 209.288055\n",
      "Train Epoch: 428 [21760/32031 (68%)]\tLoss: 193.075745\n",
      "Train Epoch: 428 [23040/32031 (72%)]\tLoss: 206.630524\n",
      "Train Epoch: 428 [24320/32031 (76%)]\tLoss: 204.326660\n",
      "Train Epoch: 428 [25600/32031 (80%)]\tLoss: 196.180161\n",
      "Train Epoch: 428 [26880/32031 (84%)]\tLoss: 208.724472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 428 [28160/32031 (88%)]\tLoss: 204.920288\n",
      "Train Epoch: 428 [29440/32031 (92%)]\tLoss: 203.620422\n",
      "Train Epoch: 428 [30720/32031 (96%)]\tLoss: 202.004898\n",
      "Train Epoch: 428 [7750/32031 (100%)]\tLoss: 186.258474\n",
      "====> Epoch: 428 Average loss: 201.5154\n",
      "====> Test set loss: 194.0026\n",
      "Train Epoch: 429 [0/32031 (0%)]\tLoss: 195.012939\n",
      "Train Epoch: 429 [1280/32031 (4%)]\tLoss: 194.498932\n",
      "Train Epoch: 429 [2560/32031 (8%)]\tLoss: 197.083420\n",
      "Train Epoch: 429 [3840/32031 (12%)]\tLoss: 202.567108\n",
      "Train Epoch: 429 [5120/32031 (16%)]\tLoss: 205.592117\n",
      "Train Epoch: 429 [6400/32031 (20%)]\tLoss: 197.008041\n",
      "Train Epoch: 429 [7680/32031 (24%)]\tLoss: 196.485291\n",
      "Train Epoch: 429 [8960/32031 (28%)]\tLoss: 200.464783\n",
      "Train Epoch: 429 [10240/32031 (32%)]\tLoss: 205.812469\n",
      "Train Epoch: 429 [11520/32031 (36%)]\tLoss: 201.505325\n",
      "Train Epoch: 429 [12800/32031 (40%)]\tLoss: 206.225128\n",
      "Train Epoch: 429 [14080/32031 (44%)]\tLoss: 201.497498\n",
      "Train Epoch: 429 [15360/32031 (48%)]\tLoss: 206.014114\n",
      "Train Epoch: 429 [16640/32031 (52%)]\tLoss: 193.766006\n",
      "Train Epoch: 429 [17920/32031 (56%)]\tLoss: 189.574127\n",
      "Train Epoch: 429 [19200/32031 (60%)]\tLoss: 195.036194\n",
      "Train Epoch: 429 [20480/32031 (64%)]\tLoss: 212.151215\n",
      "Train Epoch: 429 [21760/32031 (68%)]\tLoss: 202.883301\n",
      "Train Epoch: 429 [23040/32031 (72%)]\tLoss: 210.327209\n",
      "Train Epoch: 429 [24320/32031 (76%)]\tLoss: 207.160599\n",
      "Train Epoch: 429 [25600/32031 (80%)]\tLoss: 193.993759\n",
      "Train Epoch: 429 [26880/32031 (84%)]\tLoss: 206.456558\n",
      "Train Epoch: 429 [28160/32031 (88%)]\tLoss: 203.235916\n",
      "Train Epoch: 429 [29440/32031 (92%)]\tLoss: 195.659317\n",
      "Train Epoch: 429 [30720/32031 (96%)]\tLoss: 203.428925\n",
      "Train Epoch: 429 [7750/32031 (100%)]\tLoss: 185.288117\n",
      "====> Epoch: 429 Average loss: 200.5837\n",
      "====> Test set loss: 192.8054\n",
      "Train Epoch: 430 [0/32031 (0%)]\tLoss: 198.006378\n",
      "Train Epoch: 430 [1280/32031 (4%)]\tLoss: 201.236755\n",
      "Train Epoch: 430 [2560/32031 (8%)]\tLoss: 201.697922\n",
      "Train Epoch: 430 [3840/32031 (12%)]\tLoss: 200.066910\n",
      "Train Epoch: 430 [5120/32031 (16%)]\tLoss: 200.508133\n",
      "Train Epoch: 430 [6400/32031 (20%)]\tLoss: 198.944000\n",
      "Train Epoch: 430 [7680/32031 (24%)]\tLoss: 197.243271\n",
      "Train Epoch: 430 [8960/32031 (28%)]\tLoss: 209.630951\n",
      "Train Epoch: 430 [10240/32031 (32%)]\tLoss: 183.387665\n",
      "Train Epoch: 430 [11520/32031 (36%)]\tLoss: 197.260315\n",
      "Train Epoch: 430 [12800/32031 (40%)]\tLoss: 210.313812\n",
      "Train Epoch: 430 [14080/32031 (44%)]\tLoss: 201.288467\n",
      "Train Epoch: 430 [15360/32031 (48%)]\tLoss: 193.698334\n",
      "Train Epoch: 430 [16640/32031 (52%)]\tLoss: 200.688324\n",
      "Train Epoch: 430 [17920/32031 (56%)]\tLoss: 202.284210\n",
      "Train Epoch: 430 [19200/32031 (60%)]\tLoss: 206.853745\n",
      "Train Epoch: 430 [20480/32031 (64%)]\tLoss: 193.078568\n",
      "Train Epoch: 430 [21760/32031 (68%)]\tLoss: 201.618195\n",
      "Train Epoch: 430 [23040/32031 (72%)]\tLoss: 199.546921\n",
      "Train Epoch: 430 [24320/32031 (76%)]\tLoss: 201.646545\n",
      "Train Epoch: 430 [25600/32031 (80%)]\tLoss: 191.209198\n",
      "Train Epoch: 430 [26880/32031 (84%)]\tLoss: 198.351471\n",
      "Train Epoch: 430 [28160/32031 (88%)]\tLoss: 192.741714\n",
      "Train Epoch: 430 [29440/32031 (92%)]\tLoss: 206.080765\n",
      "Train Epoch: 430 [30720/32031 (96%)]\tLoss: 195.712051\n",
      "Train Epoch: 430 [7750/32031 (100%)]\tLoss: 220.429940\n",
      "====> Epoch: 430 Average loss: 201.0561\n",
      "====> Test set loss: 193.2554\n",
      "Train Epoch: 431 [0/32031 (0%)]\tLoss: 200.667175\n",
      "Train Epoch: 431 [1280/32031 (4%)]\tLoss: 216.637497\n",
      "Train Epoch: 431 [2560/32031 (8%)]\tLoss: 198.844894\n",
      "Train Epoch: 431 [3840/32031 (12%)]\tLoss: 200.709412\n",
      "Train Epoch: 431 [5120/32031 (16%)]\tLoss: 188.781464\n",
      "Train Epoch: 431 [6400/32031 (20%)]\tLoss: 194.984207\n",
      "Train Epoch: 431 [7680/32031 (24%)]\tLoss: 202.659714\n",
      "Train Epoch: 431 [8960/32031 (28%)]\tLoss: 201.550568\n",
      "Train Epoch: 431 [10240/32031 (32%)]\tLoss: 208.736435\n",
      "Train Epoch: 431 [11520/32031 (36%)]\tLoss: 207.371887\n",
      "Train Epoch: 431 [12800/32031 (40%)]\tLoss: 192.264389\n",
      "Train Epoch: 431 [14080/32031 (44%)]\tLoss: 204.440048\n",
      "Train Epoch: 431 [15360/32031 (48%)]\tLoss: 200.537033\n",
      "Train Epoch: 431 [16640/32031 (52%)]\tLoss: 201.331558\n",
      "Train Epoch: 431 [17920/32031 (56%)]\tLoss: 191.692886\n",
      "Train Epoch: 431 [19200/32031 (60%)]\tLoss: 202.212296\n",
      "Train Epoch: 431 [20480/32031 (64%)]\tLoss: 190.997772\n",
      "Train Epoch: 431 [21760/32031 (68%)]\tLoss: 194.345810\n",
      "Train Epoch: 431 [23040/32031 (72%)]\tLoss: 204.043594\n",
      "Train Epoch: 431 [24320/32031 (76%)]\tLoss: 205.094727\n",
      "Train Epoch: 431 [25600/32031 (80%)]\tLoss: 198.230606\n",
      "Train Epoch: 431 [26880/32031 (84%)]\tLoss: 198.615585\n",
      "Train Epoch: 431 [28160/32031 (88%)]\tLoss: 197.756210\n",
      "Train Epoch: 431 [29440/32031 (92%)]\tLoss: 199.287827\n",
      "Train Epoch: 431 [30720/32031 (96%)]\tLoss: 200.611343\n",
      "Train Epoch: 431 [7750/32031 (100%)]\tLoss: 210.210166\n",
      "====> Epoch: 431 Average loss: 201.0456\n",
      "====> Test set loss: 195.1693\n",
      "Train Epoch: 432 [0/32031 (0%)]\tLoss: 199.600357\n",
      "Train Epoch: 432 [1280/32031 (4%)]\tLoss: 205.432678\n",
      "Train Epoch: 432 [2560/32031 (8%)]\tLoss: 198.410309\n",
      "Train Epoch: 432 [3840/32031 (12%)]\tLoss: 199.712402\n",
      "Train Epoch: 432 [5120/32031 (16%)]\tLoss: 194.182571\n",
      "Train Epoch: 432 [6400/32031 (20%)]\tLoss: 196.096283\n",
      "Train Epoch: 432 [7680/32031 (24%)]\tLoss: 200.136551\n",
      "Train Epoch: 432 [8960/32031 (28%)]\tLoss: 199.173782\n",
      "Train Epoch: 432 [10240/32031 (32%)]\tLoss: 194.200470\n",
      "Train Epoch: 432 [11520/32031 (36%)]\tLoss: 214.282013\n",
      "Train Epoch: 432 [12800/32031 (40%)]\tLoss: 197.467880\n",
      "Train Epoch: 432 [14080/32031 (44%)]\tLoss: 207.111267\n",
      "Train Epoch: 432 [15360/32031 (48%)]\tLoss: 191.248459\n",
      "Train Epoch: 432 [16640/32031 (52%)]\tLoss: 204.726532\n",
      "Train Epoch: 432 [17920/32031 (56%)]\tLoss: 204.171997\n",
      "Train Epoch: 432 [19200/32031 (60%)]\tLoss: 198.527252\n",
      "Train Epoch: 432 [20480/32031 (64%)]\tLoss: 204.890320\n",
      "Train Epoch: 432 [21760/32031 (68%)]\tLoss: 201.292847\n",
      "Train Epoch: 432 [23040/32031 (72%)]\tLoss: 212.329254\n",
      "Train Epoch: 432 [24320/32031 (76%)]\tLoss: 197.320465\n",
      "Train Epoch: 432 [25600/32031 (80%)]\tLoss: 209.421371\n",
      "Train Epoch: 432 [26880/32031 (84%)]\tLoss: 195.067871\n",
      "Train Epoch: 432 [28160/32031 (88%)]\tLoss: 210.709366\n",
      "Train Epoch: 432 [29440/32031 (92%)]\tLoss: 194.213211\n",
      "Train Epoch: 432 [30720/32031 (96%)]\tLoss: 198.358795\n",
      "Train Epoch: 432 [7750/32031 (100%)]\tLoss: 213.414976\n",
      "====> Epoch: 432 Average loss: 200.4225\n",
      "====> Test set loss: 194.5179\n",
      "Train Epoch: 433 [0/32031 (0%)]\tLoss: 205.517395\n",
      "Train Epoch: 433 [1280/32031 (4%)]\tLoss: 204.068451\n",
      "Train Epoch: 433 [2560/32031 (8%)]\tLoss: 189.140457\n",
      "Train Epoch: 433 [3840/32031 (12%)]\tLoss: 204.270355\n",
      "Train Epoch: 433 [5120/32031 (16%)]\tLoss: 186.335281\n",
      "Train Epoch: 433 [6400/32031 (20%)]\tLoss: 206.669342\n",
      "Train Epoch: 433 [7680/32031 (24%)]\tLoss: 203.055054\n",
      "Train Epoch: 433 [8960/32031 (28%)]\tLoss: 202.507858\n",
      "Train Epoch: 433 [10240/32031 (32%)]\tLoss: 193.782761\n",
      "Train Epoch: 433 [11520/32031 (36%)]\tLoss: 213.909714\n",
      "Train Epoch: 433 [12800/32031 (40%)]\tLoss: 203.955536\n",
      "Train Epoch: 433 [14080/32031 (44%)]\tLoss: 196.970535\n",
      "Train Epoch: 433 [15360/32031 (48%)]\tLoss: 196.869827\n",
      "Train Epoch: 433 [16640/32031 (52%)]\tLoss: 198.618240\n",
      "Train Epoch: 433 [17920/32031 (56%)]\tLoss: 201.337723\n",
      "Train Epoch: 433 [19200/32031 (60%)]\tLoss: 199.500854\n",
      "Train Epoch: 433 [20480/32031 (64%)]\tLoss: 189.682098\n",
      "Train Epoch: 433 [21760/32031 (68%)]\tLoss: 214.333984\n",
      "Train Epoch: 433 [23040/32031 (72%)]\tLoss: 203.881973\n",
      "Train Epoch: 433 [24320/32031 (76%)]\tLoss: 200.339706\n",
      "Train Epoch: 433 [25600/32031 (80%)]\tLoss: 207.982803\n",
      "Train Epoch: 433 [26880/32031 (84%)]\tLoss: 202.687515\n",
      "Train Epoch: 433 [28160/32031 (88%)]\tLoss: 200.511307\n",
      "Train Epoch: 433 [29440/32031 (92%)]\tLoss: 201.342575\n",
      "Train Epoch: 433 [30720/32031 (96%)]\tLoss: 209.891586\n",
      "Train Epoch: 433 [7750/32031 (100%)]\tLoss: 240.264097\n",
      "====> Epoch: 433 Average loss: 200.4027\n",
      "====> Test set loss: 195.4787\n",
      "Train Epoch: 434 [0/32031 (0%)]\tLoss: 201.573761\n",
      "Train Epoch: 434 [1280/32031 (4%)]\tLoss: 188.072784\n",
      "Train Epoch: 434 [2560/32031 (8%)]\tLoss: 193.079071\n",
      "Train Epoch: 434 [3840/32031 (12%)]\tLoss: 191.816177\n",
      "Train Epoch: 434 [5120/32031 (16%)]\tLoss: 198.990204\n",
      "Train Epoch: 434 [6400/32031 (20%)]\tLoss: 195.960953\n",
      "Train Epoch: 434 [7680/32031 (24%)]\tLoss: 191.796906\n",
      "Train Epoch: 434 [8960/32031 (28%)]\tLoss: 203.801865\n",
      "Train Epoch: 434 [10240/32031 (32%)]\tLoss: 207.265930\n",
      "Train Epoch: 434 [11520/32031 (36%)]\tLoss: 197.587372\n",
      "Train Epoch: 434 [12800/32031 (40%)]\tLoss: 197.727051\n",
      "Train Epoch: 434 [14080/32031 (44%)]\tLoss: 216.701523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 434 [15360/32031 (48%)]\tLoss: 193.389862\n",
      "Train Epoch: 434 [16640/32031 (52%)]\tLoss: 202.034058\n",
      "Train Epoch: 434 [17920/32031 (56%)]\tLoss: 190.683380\n",
      "Train Epoch: 434 [19200/32031 (60%)]\tLoss: 214.145752\n",
      "Train Epoch: 434 [20480/32031 (64%)]\tLoss: 211.395630\n",
      "Train Epoch: 434 [21760/32031 (68%)]\tLoss: 199.401123\n",
      "Train Epoch: 434 [23040/32031 (72%)]\tLoss: 206.153625\n",
      "Train Epoch: 434 [24320/32031 (76%)]\tLoss: 206.074173\n",
      "Train Epoch: 434 [25600/32031 (80%)]\tLoss: 202.254181\n",
      "Train Epoch: 434 [26880/32031 (84%)]\tLoss: 205.171356\n",
      "Train Epoch: 434 [28160/32031 (88%)]\tLoss: 188.426346\n",
      "Train Epoch: 434 [29440/32031 (92%)]\tLoss: 208.817444\n",
      "Train Epoch: 434 [30720/32031 (96%)]\tLoss: 216.371246\n",
      "Train Epoch: 434 [7750/32031 (100%)]\tLoss: 193.028415\n",
      "====> Epoch: 434 Average loss: 201.0636\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fc7014c2e262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5abfda2a05be>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if epoch%1 == 0:\n",
    "            sample = torch.randn(64, 60).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.view(64, 3, 64, 64),'results/sample_' + str(epoch) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
